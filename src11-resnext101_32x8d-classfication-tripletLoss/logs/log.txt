nohup: ignoring input
CUDA device count : 2
You have chosen to seed training with seed 2021.
backbone.conv1.weight True
backbone.bn1.weight True
backbone.bn1.bias True
backbone.layer1.0.conv1.weight True
backbone.layer1.0.bn1.weight True
backbone.layer1.0.bn1.bias True
backbone.layer1.0.conv2.weight True
backbone.layer1.0.bn2.weight True
backbone.layer1.0.bn2.bias True
backbone.layer1.0.conv3.weight True
backbone.layer1.0.bn3.weight True
backbone.layer1.0.bn3.bias True
backbone.layer1.0.downsample.0.weight True
backbone.layer1.0.downsample.1.weight True
backbone.layer1.0.downsample.1.bias True
backbone.layer1.1.conv1.weight True
backbone.layer1.1.bn1.weight True
backbone.layer1.1.bn1.bias True
backbone.layer1.1.conv2.weight True
backbone.layer1.1.bn2.weight True
backbone.layer1.1.bn2.bias True
backbone.layer1.1.conv3.weight True
backbone.layer1.1.bn3.weight True
backbone.layer1.1.bn3.bias True
backbone.layer1.2.conv1.weight True
backbone.layer1.2.bn1.weight True
backbone.layer1.2.bn1.bias True
backbone.layer1.2.conv2.weight True
backbone.layer1.2.bn2.weight True
backbone.layer1.2.bn2.bias True
backbone.layer1.2.conv3.weight True
backbone.layer1.2.bn3.weight True
backbone.layer1.2.bn3.bias True
backbone.layer2.0.conv1.weight True
backbone.layer2.0.bn1.weight True
backbone.layer2.0.bn1.bias True
backbone.layer2.0.conv2.weight True
backbone.layer2.0.bn2.weight True
backbone.layer2.0.bn2.bias True
backbone.layer2.0.conv3.weight True
backbone.layer2.0.bn3.weight True
backbone.layer2.0.bn3.bias True
backbone.layer2.0.downsample.0.weight True
backbone.layer2.0.downsample.1.weight True
backbone.layer2.0.downsample.1.bias True
backbone.layer2.1.conv1.weight True
backbone.layer2.1.bn1.weight True
backbone.layer2.1.bn1.bias True
backbone.layer2.1.conv2.weight True
backbone.layer2.1.bn2.weight True
backbone.layer2.1.bn2.bias True
backbone.layer2.1.conv3.weight True
backbone.layer2.1.bn3.weight True
backbone.layer2.1.bn3.bias True
backbone.layer2.2.conv1.weight True
backbone.layer2.2.bn1.weight True
backbone.layer2.2.bn1.bias True
backbone.layer2.2.conv2.weight True
backbone.layer2.2.bn2.weight True
backbone.layer2.2.bn2.bias True
backbone.layer2.2.conv3.weight True
backbone.layer2.2.bn3.weight True
backbone.layer2.2.bn3.bias True
backbone.layer2.3.conv1.weight True
backbone.layer2.3.bn1.weight True
backbone.layer2.3.bn1.bias True
backbone.layer2.3.conv2.weight True
backbone.layer2.3.bn2.weight True
backbone.layer2.3.bn2.bias True
backbone.layer2.3.conv3.weight True
backbone.layer2.3.bn3.weight True
backbone.layer2.3.bn3.bias True
backbone.layer3.0.conv1.weight True
backbone.layer3.0.bn1.weight True
backbone.layer3.0.bn1.bias True
backbone.layer3.0.conv2.weight True
backbone.layer3.0.bn2.weight True
backbone.layer3.0.bn2.bias True
backbone.layer3.0.conv3.weight True
backbone.layer3.0.bn3.weight True
backbone.layer3.0.bn3.bias True
backbone.layer3.0.downsample.0.weight True
backbone.layer3.0.downsample.1.weight True
backbone.layer3.0.downsample.1.bias True
backbone.layer3.1.conv1.weight True
backbone.layer3.1.bn1.weight True
backbone.layer3.1.bn1.bias True
backbone.layer3.1.conv2.weight True
backbone.layer3.1.bn2.weight True
backbone.layer3.1.bn2.bias True
backbone.layer3.1.conv3.weight True
backbone.layer3.1.bn3.weight True
backbone.layer3.1.bn3.bias True
backbone.layer3.2.conv1.weight True
backbone.layer3.2.bn1.weight True
backbone.layer3.2.bn1.bias True
backbone.layer3.2.conv2.weight True
backbone.layer3.2.bn2.weight True
backbone.layer3.2.bn2.bias True
backbone.layer3.2.conv3.weight True
backbone.layer3.2.bn3.weight True
backbone.layer3.2.bn3.bias True
backbone.layer3.3.conv1.weight True
backbone.layer3.3.bn1.weight True
backbone.layer3.3.bn1.bias True
backbone.layer3.3.conv2.weight True
backbone.layer3.3.bn2.weight True
backbone.layer3.3.bn2.bias True
backbone.layer3.3.conv3.weight True
backbone.layer3.3.bn3.weight True
backbone.layer3.3.bn3.bias True
backbone.layer3.4.conv1.weight True
backbone.layer3.4.bn1.weight True
backbone.layer3.4.bn1.bias True
backbone.layer3.4.conv2.weight True
backbone.layer3.4.bn2.weight True
backbone.layer3.4.bn2.bias True
backbone.layer3.4.conv3.weight True
backbone.layer3.4.bn3.weight True
backbone.layer3.4.bn3.bias True
backbone.layer3.5.conv1.weight True
backbone.layer3.5.bn1.weight True
backbone.layer3.5.bn1.bias True
backbone.layer3.5.conv2.weight True
backbone.layer3.5.bn2.weight True
backbone.layer3.5.bn2.bias True
backbone.layer3.5.conv3.weight True
backbone.layer3.5.bn3.weight True
backbone.layer3.5.bn3.bias True
backbone.layer3.6.conv1.weight True
backbone.layer3.6.bn1.weight True
backbone.layer3.6.bn1.bias True
backbone.layer3.6.conv2.weight True
backbone.layer3.6.bn2.weight True
backbone.layer3.6.bn2.bias True
backbone.layer3.6.conv3.weight True
backbone.layer3.6.bn3.weight True
backbone.layer3.6.bn3.bias True
backbone.layer3.7.conv1.weight True
backbone.layer3.7.bn1.weight True
backbone.layer3.7.bn1.bias True
backbone.layer3.7.conv2.weight True
backbone.layer3.7.bn2.weight True
backbone.layer3.7.bn2.bias True
backbone.layer3.7.conv3.weight True
backbone.layer3.7.bn3.weight True
backbone.layer3.7.bn3.bias True
backbone.layer3.8.conv1.weight True
backbone.layer3.8.bn1.weight True
backbone.layer3.8.bn1.bias True
backbone.layer3.8.conv2.weight True
backbone.layer3.8.bn2.weight True
backbone.layer3.8.bn2.bias True
backbone.layer3.8.conv3.weight True
backbone.layer3.8.bn3.weight True
backbone.layer3.8.bn3.bias True
backbone.layer3.9.conv1.weight True
backbone.layer3.9.bn1.weight True
backbone.layer3.9.bn1.bias True
backbone.layer3.9.conv2.weight True
backbone.layer3.9.bn2.weight True
backbone.layer3.9.bn2.bias True
backbone.layer3.9.conv3.weight True
backbone.layer3.9.bn3.weight True
backbone.layer3.9.bn3.bias True
backbone.layer3.10.conv1.weight True
backbone.layer3.10.bn1.weight True
backbone.layer3.10.bn1.bias True
backbone.layer3.10.conv2.weight True
backbone.layer3.10.bn2.weight True
backbone.layer3.10.bn2.bias True
backbone.layer3.10.conv3.weight True
backbone.layer3.10.bn3.weight True
backbone.layer3.10.bn3.bias True
backbone.layer3.11.conv1.weight True
backbone.layer3.11.bn1.weight True
backbone.layer3.11.bn1.bias True
backbone.layer3.11.conv2.weight True
backbone.layer3.11.bn2.weight True
backbone.layer3.11.bn2.bias True
backbone.layer3.11.conv3.weight True
backbone.layer3.11.bn3.weight True
backbone.layer3.11.bn3.bias True
backbone.layer3.12.conv1.weight True
backbone.layer3.12.bn1.weight True
backbone.layer3.12.bn1.bias True
backbone.layer3.12.conv2.weight True
backbone.layer3.12.bn2.weight True
backbone.layer3.12.bn2.bias True
backbone.layer3.12.conv3.weight True
backbone.layer3.12.bn3.weight True
backbone.layer3.12.bn3.bias True
backbone.layer3.13.conv1.weight True
backbone.layer3.13.bn1.weight True
backbone.layer3.13.bn1.bias True
backbone.layer3.13.conv2.weight True
backbone.layer3.13.bn2.weight True
backbone.layer3.13.bn2.bias True
backbone.layer3.13.conv3.weight True
backbone.layer3.13.bn3.weight True
backbone.layer3.13.bn3.bias True
backbone.layer3.14.conv1.weight True
backbone.layer3.14.bn1.weight True
backbone.layer3.14.bn1.bias True
backbone.layer3.14.conv2.weight True
backbone.layer3.14.bn2.weight True
backbone.layer3.14.bn2.bias True
backbone.layer3.14.conv3.weight True
backbone.layer3.14.bn3.weight True
backbone.layer3.14.bn3.bias True
backbone.layer3.15.conv1.weight True
backbone.layer3.15.bn1.weight True
backbone.layer3.15.bn1.bias True
backbone.layer3.15.conv2.weight True
backbone.layer3.15.bn2.weight True
backbone.layer3.15.bn2.bias True
backbone.layer3.15.conv3.weight True
backbone.layer3.15.bn3.weight True
backbone.layer3.15.bn3.bias True
backbone.layer3.16.conv1.weight True
backbone.layer3.16.bn1.weight True
backbone.layer3.16.bn1.bias True
backbone.layer3.16.conv2.weight True
backbone.layer3.16.bn2.weight True
backbone.layer3.16.bn2.bias True
backbone.layer3.16.conv3.weight True
backbone.layer3.16.bn3.weight True
backbone.layer3.16.bn3.bias True
backbone.layer3.17.conv1.weight True
backbone.layer3.17.bn1.weight True
backbone.layer3.17.bn1.bias True
backbone.layer3.17.conv2.weight True
backbone.layer3.17.bn2.weight True
backbone.layer3.17.bn2.bias True
backbone.layer3.17.conv3.weight True
backbone.layer3.17.bn3.weight True
backbone.layer3.17.bn3.bias True
backbone.layer3.18.conv1.weight True
backbone.layer3.18.bn1.weight True
backbone.layer3.18.bn1.bias True
backbone.layer3.18.conv2.weight True
backbone.layer3.18.bn2.weight True
backbone.layer3.18.bn2.bias True
backbone.layer3.18.conv3.weight True
backbone.layer3.18.bn3.weight True
backbone.layer3.18.bn3.bias True
backbone.layer3.19.conv1.weight True
backbone.layer3.19.bn1.weight True
backbone.layer3.19.bn1.bias True
backbone.layer3.19.conv2.weight True
backbone.layer3.19.bn2.weight True
backbone.layer3.19.bn2.bias True
backbone.layer3.19.conv3.weight True
backbone.layer3.19.bn3.weight True
backbone.layer3.19.bn3.bias True
backbone.layer3.20.conv1.weight True
backbone.layer3.20.bn1.weight True
backbone.layer3.20.bn1.bias True
backbone.layer3.20.conv2.weight True
backbone.layer3.20.bn2.weight True
backbone.layer3.20.bn2.bias True
backbone.layer3.20.conv3.weight True
backbone.layer3.20.bn3.weight True
backbone.layer3.20.bn3.bias True
backbone.layer3.21.conv1.weight True
backbone.layer3.21.bn1.weight True
backbone.layer3.21.bn1.bias True
backbone.layer3.21.conv2.weight True
backbone.layer3.21.bn2.weight True
backbone.layer3.21.bn2.bias True
backbone.layer3.21.conv3.weight True
backbone.layer3.21.bn3.weight True
backbone.layer3.21.bn3.bias True
backbone.layer3.22.conv1.weight True
backbone.layer3.22.bn1.weight True
backbone.layer3.22.bn1.bias True
backbone.layer3.22.conv2.weight True
backbone.layer3.22.bn2.weight True
backbone.layer3.22.bn2.bias True
backbone.layer3.22.conv3.weight True
backbone.layer3.22.bn3.weight True
backbone.layer3.22.bn3.bias True
backbone.layer4.0.conv1.weight True
backbone.layer4.0.bn1.weight True
backbone.layer4.0.bn1.bias True
backbone.layer4.0.conv2.weight True
backbone.layer4.0.bn2.weight True
backbone.layer4.0.bn2.bias True
backbone.layer4.0.conv3.weight True
backbone.layer4.0.bn3.weight True
backbone.layer4.0.bn3.bias True
backbone.layer4.0.downsample.0.weight True
backbone.layer4.0.downsample.1.weight True
backbone.layer4.0.downsample.1.bias True
backbone.layer4.1.conv1.weight True
backbone.layer4.1.bn1.weight True
backbone.layer4.1.bn1.bias True
backbone.layer4.1.conv2.weight True
backbone.layer4.1.bn2.weight True
backbone.layer4.1.bn2.bias True
backbone.layer4.1.conv3.weight True
backbone.layer4.1.bn3.weight True
backbone.layer4.1.bn3.bias True
backbone.layer4.2.conv1.weight True
backbone.layer4.2.bn1.weight True
backbone.layer4.2.bn1.bias True
backbone.layer4.2.conv2.weight True
backbone.layer4.2.bn2.weight True
backbone.layer4.2.bn2.bias True
backbone.layer4.2.conv3.weight True
backbone.layer4.2.bn3.weight True
backbone.layer4.2.bn3.bias True
backbone.feature_fc.weight True
backbone.feature_fc.bias True
backbone.feature_bn.weight True
backbone.feature_bn.bias True
backbone._fc.weight True
backbone._fc.bias True
arcface_loss.weight True
total samples: 14144, training samples: 11315, validation samples: 2829
store samples : 14144

Epoch 1 learning_rate : 1e-05
/home/ymluo/anaconda3/envs/torchenv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
[Epoch:1] 1/22	    BatchTime 17.5343    DataTime 3.9041    Loss_Classification 2.9778e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.109
[Epoch:1] 2/22	    BatchTime 1.3854    DataTime 0.0002    Loss_Classification 3.3200e+00    Loss_Distance 0.0000e+00    acc@1 82.812    acc@5 86.133
[Epoch:1] 3/22	    BatchTime 1.1194    DataTime 0.0003    Loss_Classification 3.3657e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 86.328
[Epoch:1] 4/22	    BatchTime 1.1231    DataTime 0.0002    Loss_Classification 3.0063e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 87.500
[Epoch:1] 5/22	    BatchTime 1.1184    DataTime 0.0003    Loss_Classification 3.3188e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 86.914
[Epoch:1] 6/22	    BatchTime 1.1568    DataTime 0.0002    Loss_Classification 3.1764e+00    Loss_Distance 0.0000e+00    acc@1 82.812    acc@5 85.742
[Epoch:1] 7/22	    BatchTime 1.1339    DataTime 0.0002    Loss_Classification 2.9917e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 86.523
[Epoch:1] 8/22	    BatchTime 1.1461    DataTime 0.0004    Loss_Classification 2.4766e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.648
[Epoch:1] 9/22	    BatchTime 1.1511    DataTime 0.0002    Loss_Classification 2.7660e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.477
[Epoch:1] 10/22	    BatchTime 1.1726    DataTime 0.0002    Loss_Classification 3.5490e+00    Loss_Distance 0.0000e+00    acc@1 83.008    acc@5 85.352
[Epoch:1] 11/22	    BatchTime 1.1613    DataTime 0.0001    Loss_Classification 3.6838e+00    Loss_Distance 0.0000e+00    acc@1 82.031    acc@5 84.570
[Epoch:1] 12/22	    BatchTime 1.1871    DataTime 0.0002    Loss_Classification 3.0044e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 86.719
[Epoch:1] 13/22	    BatchTime 1.1646    DataTime 0.0002    Loss_Classification 3.0115e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 87.500
[Epoch:1] 14/22	    BatchTime 1.1662    DataTime 0.0001    Loss_Classification 3.3474e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 86.523
[Epoch:1] 15/22	    BatchTime 1.1683    DataTime 0.0002    Loss_Classification 3.3061e+00    Loss_Distance 0.0000e+00    acc@1 82.812    acc@5 85.547
[Epoch:1] 16/22	    BatchTime 1.2678    DataTime 0.0002    Loss_Classification 2.2846e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.625
[Epoch:1] 17/22	    BatchTime 1.2164    DataTime 0.0002    Loss_Classification 3.3485e+00    Loss_Distance 0.0000e+00    acc@1 82.617    acc@5 85.352
[Epoch:1] 18/22	    BatchTime 1.2071    DataTime 0.0002    Loss_Classification 2.8791e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:1] 19/22	    BatchTime 1.1803    DataTime 0.0001    Loss_Classification 2.6369e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.648
[Epoch:1] 20/22	    BatchTime 1.1661    DataTime 0.0002    Loss_Classification 3.0434e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 86.914
[Epoch:1] 21/22	    BatchTime 1.2508    DataTime 0.0000    Loss_Classification 3.3969e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 85.352
[Epoch:1] 22/22	    BatchTime 1.2202    DataTime 0.0001    Loss_Classification 2.6538e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 88.086
[Epoch:1]  42.40    Loss_Classification 3.0702e+00    val_Loss_Classification 3.2281e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 84.535    val_acc@1 84.129    acc@5 87.065    val_acc@5 86.532
val_Loss_Classification improve from inf to 3.2280502806454843
Save model to ./models/ep00001-val_Loss_Classification_3.2281-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from inf to 0
Save model to ./models/ep00001-val_Loss_Classification_3.2281-val_Loss_Distance_0.0000.pth

Epoch 2 learning_rate : 9.97534852915723e-06
[Epoch:2] 1/22	    BatchTime 7.9374    DataTime 6.3065    Loss_Classification 3.1937e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 86.719
[Epoch:2] 2/22	    BatchTime 1.1447    DataTime 0.0002    Loss_Classification 3.3772e+00    Loss_Distance 0.0000e+00    acc@1 82.617    acc@5 85.742
[Epoch:2] 3/22	    BatchTime 1.1341    DataTime 0.0001    Loss_Classification 2.4689e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.648
[Epoch:2] 4/22	    BatchTime 1.1454    DataTime 0.0002    Loss_Classification 3.5905e+00    Loss_Distance 0.0000e+00    acc@1 83.203    acc@5 86.523
[Epoch:2] 5/22	    BatchTime 1.1326    DataTime 0.0001    Loss_Classification 3.0402e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.109
[Epoch:2] 6/22	    BatchTime 1.1341    DataTime 0.0001    Loss_Classification 2.4134e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.648
[Epoch:2] 7/22	    BatchTime 1.1522    DataTime 0.0002    Loss_Classification 3.3354e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 85.938
[Epoch:2] 8/22	    BatchTime 1.1633    DataTime 0.0000    Loss_Classification 2.5138e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:2] 9/22	    BatchTime 1.1798    DataTime 0.0002    Loss_Classification 2.6336e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.477
[Epoch:2] 10/22	    BatchTime 1.1708    DataTime 0.0002    Loss_Classification 2.7573e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.281
[Epoch:2] 11/22	    BatchTime 1.1852    DataTime 0.0001    Loss_Classification 2.9838e+00    Loss_Distance 0.0000e+00    acc@1 83.398    acc@5 86.719
[Epoch:2] 12/22	    BatchTime 1.1806    DataTime 0.0002    Loss_Classification 3.1726e+00    Loss_Distance 0.0000e+00    acc@1 83.203    acc@5 87.109
[Epoch:2] 13/22	    BatchTime 1.2379    DataTime 0.0002    Loss_Classification 2.9071e+00    Loss_Distance 0.0000e+00    acc@1 83.203    acc@5 86.328
[Epoch:2] 14/22	    BatchTime 1.2320    DataTime 0.0002    Loss_Classification 3.6418e+00    Loss_Distance 0.0000e+00    acc@1 83.203    acc@5 84.570
[Epoch:2] 15/22	    BatchTime 1.1867    DataTime 0.0001    Loss_Classification 2.9563e+00    Loss_Distance 0.0000e+00    acc@1 83.984    acc@5 87.109
[Epoch:2] 16/22	    BatchTime 1.2007    DataTime 0.0001    Loss_Classification 3.2732e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 86.328
[Epoch:2] 17/22	    BatchTime 1.1853    DataTime 0.0001    Loss_Classification 2.6535e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.281
[Epoch:2] 18/22	    BatchTime 1.1712    DataTime 0.0002    Loss_Classification 3.3937e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 86.523
[Epoch:2] 19/22	    BatchTime 1.2228    DataTime 0.0002    Loss_Classification 3.4965e+00    Loss_Distance 0.0000e+00    acc@1 81.836    acc@5 85.156
[Epoch:2] 20/22	    BatchTime 1.2079    DataTime 0.0001    Loss_Classification 2.3461e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.453
[Epoch:2] 21/22	    BatchTime 1.1932    DataTime 0.0002    Loss_Classification 3.3334e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 86.719
[Epoch:2] 22/22	    BatchTime 1.2646    DataTime 0.0002    Loss_Classification 3.2587e+00    Loss_Distance 0.0000e+00    acc@1 83.398    acc@5 85.938
[Epoch:2]  32.76    Loss_Classification 3.0337e+00    val_Loss_Classification 3.0703e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 84.606    val_acc@1 84.553    acc@5 87.145    val_acc@5 87.027
val_Loss_Classification improve from 3.2280502806454843 to 3.0703313806614045
Save model to ./models/ep00002-val_Loss_Classification_3.0703-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00002-val_Loss_Classification_3.0703-val_Loss_Distance_0.0000.pth

Epoch 3 learning_rate : 9.901664203302126e-06
[Epoch:3] 1/22	    BatchTime 7.6209    DataTime 6.4255    Loss_Classification 2.7326e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.672
[Epoch:3] 2/22	    BatchTime 1.1469    DataTime 0.0000    Loss_Classification 3.2901e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 86.914
[Epoch:3] 3/22	    BatchTime 1.1335    DataTime 0.0001    Loss_Classification 2.5296e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.477
[Epoch:3] 4/22	    BatchTime 1.1456    DataTime 0.0002    Loss_Classification 2.7658e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.672
[Epoch:3] 5/22	    BatchTime 1.1458    DataTime 0.0002    Loss_Classification 2.5852e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.258
[Epoch:3] 6/22	    BatchTime 1.1623    DataTime 0.0002    Loss_Classification 3.0055e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.500
[Epoch:3] 7/22	    BatchTime 1.1795    DataTime 0.0001    Loss_Classification 2.9397e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 86.719
[Epoch:3] 8/22	    BatchTime 1.2360    DataTime 0.0002    Loss_Classification 2.2716e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:3] 9/22	    BatchTime 1.1757    DataTime 0.0002    Loss_Classification 2.4657e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.258
[Epoch:3] 10/22	    BatchTime 1.1942    DataTime 0.0002    Loss_Classification 3.4688e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 86.328
[Epoch:3] 11/22	    BatchTime 1.1879    DataTime 0.0002    Loss_Classification 3.5394e+00    Loss_Distance 0.0000e+00    acc@1 82.617    acc@5 84.766
[Epoch:3] 12/22	    BatchTime 1.1830    DataTime 0.0001    Loss_Classification 3.3248e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 86.719
[Epoch:3] 13/22	    BatchTime 1.2691    DataTime 0.0001    Loss_Classification 2.8413e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.086
[Epoch:3] 14/22	    BatchTime 1.2236    DataTime 0.0002    Loss_Classification 2.9439e+00    Loss_Distance 0.0000e+00    acc@1 83.984    acc@5 87.305
[Epoch:3] 15/22	    BatchTime 1.1990    DataTime 0.0002    Loss_Classification 2.9154e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 87.891
[Epoch:3] 16/22	    BatchTime 1.1935    DataTime 0.0002    Loss_Classification 2.3655e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.039
[Epoch:3] 17/22	    BatchTime 1.1933    DataTime 0.0002    Loss_Classification 3.5518e+00    Loss_Distance 0.0000e+00    acc@1 82.031    acc@5 84.766
[Epoch:3] 18/22	    BatchTime 1.2147    DataTime 0.0002    Loss_Classification 3.0244e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.109
[Epoch:3] 19/22	    BatchTime 1.2652    DataTime 0.0002    Loss_Classification 2.7167e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 89.648
[Epoch:3] 20/22	    BatchTime 1.2375    DataTime 0.0002    Loss_Classification 3.1169e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 86.719
[Epoch:3] 21/22	    BatchTime 1.2153    DataTime 0.0002    Loss_Classification 3.8052e+00    Loss_Distance 0.0000e+00    acc@1 81.836    acc@5 85.352
[Epoch:3] 22/22	    BatchTime 1.2273    DataTime 0.0002    Loss_Classification 3.1283e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 86.133
[Epoch:3]  32.75    Loss_Classification 2.9695e+00    val_Loss_Classification 3.0241e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 85.094    val_acc@1 84.977    acc@5 87.553    val_acc@5 87.133
val_Loss_Classification improve from 3.0703313806614045 to 3.024148147912698
Save model to ./models/ep00003-val_Loss_Classification_3.0241-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00003-val_Loss_Classification_3.0241-val_Loss_Distance_0.0000.pth

Epoch 4 learning_rate : 9.779754323328192e-06
[Epoch:4] 1/22	    BatchTime 6.9081    DataTime 5.5979    Loss_Classification 2.7761e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.086
[Epoch:4] 2/22	    BatchTime 1.1298    DataTime 0.0002    Loss_Classification 3.2747e+00    Loss_Distance 0.0000e+00    acc@1 83.984    acc@5 86.133
[Epoch:4] 3/22	    BatchTime 1.1330    DataTime 0.0003    Loss_Classification 2.9504e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 87.695
[Epoch:4] 4/22	    BatchTime 1.1484    DataTime 0.0001    Loss_Classification 2.9078e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.305
[Epoch:4] 5/22	    BatchTime 1.1797    DataTime 0.0001    Loss_Classification 3.0463e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 86.523
[Epoch:4] 6/22	    BatchTime 1.1904    DataTime 0.0001    Loss_Classification 2.7772e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.062
[Epoch:4] 7/22	    BatchTime 1.1884    DataTime 0.0001    Loss_Classification 2.5804e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 88.477
[Epoch:4] 8/22	    BatchTime 1.2333    DataTime 0.0002    Loss_Classification 3.2328e+00    Loss_Distance 0.0000e+00    acc@1 82.422    acc@5 85.938
[Epoch:4] 9/22	    BatchTime 1.2025    DataTime 0.0002    Loss_Classification 2.6965e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.086
[Epoch:4] 10/22	    BatchTime 1.2000    DataTime 0.0002    Loss_Classification 3.5239e+00    Loss_Distance 0.0000e+00    acc@1 83.008    acc@5 85.547
[Epoch:4] 11/22	    BatchTime 1.1713    DataTime 0.0002    Loss_Classification 3.2930e+00    Loss_Distance 0.0000e+00    acc@1 82.812    acc@5 85.938
[Epoch:4] 12/22	    BatchTime 1.1960    DataTime 0.0002    Loss_Classification 3.2996e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 86.719
[Epoch:4] 13/22	    BatchTime 1.1942    DataTime 0.0001    Loss_Classification 2.8751e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 86.914
[Epoch:4] 14/22	    BatchTime 1.1787    DataTime 0.0001    Loss_Classification 3.3592e+00    Loss_Distance 0.0000e+00    acc@1 83.203    acc@5 86.328
[Epoch:4] 15/22	    BatchTime 1.3787    DataTime 0.0001    Loss_Classification 2.0071e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.820
[Epoch:4] 16/22	    BatchTime 1.2198    DataTime 0.0004    Loss_Classification 2.4653e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:4] 17/22	    BatchTime 1.1979    DataTime 0.0000    Loss_Classification 3.0932e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 86.914
[Epoch:4] 18/22	    BatchTime 1.2265    DataTime 0.0001    Loss_Classification 2.6049e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.281
[Epoch:4] 19/22	    BatchTime 1.2049    DataTime 0.0001    Loss_Classification 2.8042e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 87.891
[Epoch:4] 20/22	    BatchTime 1.2135    DataTime 0.0001    Loss_Classification 3.1191e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.109
[Epoch:4] 21/22	    BatchTime 1.2131    DataTime 0.0001    Loss_Classification 2.1349e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.430
[Epoch:4] 22/22	    BatchTime 1.2086    DataTime 0.0001    Loss_Classification 2.5850e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.672
[Epoch:4]  32.12    Loss_Classification 2.8821e+00    val_Loss_Classification 2.8729e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 85.343    val_acc@1 85.684    acc@5 87.633    val_acc@5 87.663
val_Loss_Classification improve from 3.024148147912698 to 2.872857356501283
Save model to ./models/ep00004-val_Loss_Classification_2.8729-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00004-val_Loss_Classification_2.8729-val_Loss_Distance_0.0000.pth

Epoch 5 learning_rate : 9.610954559391704e-06
[Epoch:5] 1/22	    BatchTime 7.4718    DataTime 6.2798    Loss_Classification 2.4003e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 90.820
[Epoch:5] 2/22	    BatchTime 1.1449    DataTime 0.0000    Loss_Classification 2.2844e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.625
[Epoch:5] 3/22	    BatchTime 1.1490    DataTime 0.0001    Loss_Classification 2.3256e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.062
[Epoch:5] 4/22	    BatchTime 1.1453    DataTime 0.0002    Loss_Classification 2.6364e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.062
[Epoch:5] 5/22	    BatchTime 1.1635    DataTime 0.0001    Loss_Classification 3.0090e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 86.719
[Epoch:5] 6/22	    BatchTime 1.1746    DataTime 0.0002    Loss_Classification 2.8807e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 88.281
[Epoch:5] 7/22	    BatchTime 1.1723    DataTime 0.0002    Loss_Classification 3.0266e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 87.500
[Epoch:5] 8/22	    BatchTime 1.2072    DataTime 0.0002    Loss_Classification 2.9453e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 86.523
[Epoch:5] 9/22	    BatchTime 1.1769    DataTime 0.0002    Loss_Classification 3.5532e+00    Loss_Distance 0.0000e+00    acc@1 83.008    acc@5 85.352
[Epoch:5] 10/22	    BatchTime 1.1888    DataTime 0.0005    Loss_Classification 3.1500e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 86.719
[Epoch:5] 11/22	    BatchTime 1.2117    DataTime 0.0001    Loss_Classification 2.6267e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.867
[Epoch:5] 12/22	    BatchTime 1.2060    DataTime 0.0002    Loss_Classification 2.9035e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 88.086
[Epoch:5] 13/22	    BatchTime 1.2033    DataTime 0.0002    Loss_Classification 2.1366e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:5] 14/22	    BatchTime 1.2121    DataTime 0.0001    Loss_Classification 3.1460e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 85.938
[Epoch:5] 15/22	    BatchTime 1.2798    DataTime 0.0001    Loss_Classification 2.7224e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.867
[Epoch:5] 16/22	    BatchTime 1.2358    DataTime 0.0002    Loss_Classification 2.5300e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.234
[Epoch:5] 17/22	    BatchTime 1.2148    DataTime 0.0002    Loss_Classification 2.7790e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.477
[Epoch:5] 18/22	    BatchTime 1.2137    DataTime 0.0002    Loss_Classification 2.6545e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.281
[Epoch:5] 19/22	    BatchTime 1.2115    DataTime 0.0002    Loss_Classification 3.3430e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 85.938
[Epoch:5] 20/22	    BatchTime 1.2830    DataTime 0.0002    Loss_Classification 2.6954e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.891
[Epoch:5] 21/22	    BatchTime 1.2400    DataTime 0.0002    Loss_Classification 3.0374e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 86.719
[Epoch:5] 22/22	    BatchTime 1.2490    DataTime 0.0002    Loss_Classification 2.9229e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.109
[Epoch:5]  32.76    Loss_Classification 2.8049e+00    val_Loss_Classification 2.6933e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 85.645    val_acc@1 86.497    acc@5 88.104    val_acc@5 87.840
val_Loss_Classification improve from 2.872857356501283 to 2.693345992377218
Save model to ./models/ep00005-val_Loss_Classification_2.6933-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00005-val_Loss_Classification_2.6933-val_Loss_Distance_0.0000.pth

Epoch 6 learning_rate : 9.397114317029975e-06
[Epoch:6] 1/22	    BatchTime 7.2202    DataTime 5.7879    Loss_Classification 1.9722e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.602
[Epoch:6] 2/22	    BatchTime 1.1339    DataTime 0.0003    Loss_Classification 2.4114e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.867
[Epoch:6] 3/22	    BatchTime 1.1359    DataTime 0.0001    Loss_Classification 2.8765e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.695
[Epoch:6] 4/22	    BatchTime 1.1610    DataTime 0.0002    Loss_Classification 3.1311e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.109
[Epoch:6] 5/22	    BatchTime 1.1649    DataTime 0.0001    Loss_Classification 2.7230e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 88.086
[Epoch:6] 6/22	    BatchTime 1.1876    DataTime 0.0001    Loss_Classification 2.7197e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 87.891
[Epoch:6] 7/22	    BatchTime 1.1766    DataTime 0.0002    Loss_Classification 3.1023e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 86.328
[Epoch:6] 8/22	    BatchTime 1.1809    DataTime 0.0001    Loss_Classification 2.9130e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 87.695
[Epoch:6] 9/22	    BatchTime 1.1816    DataTime 0.0003    Loss_Classification 2.7492e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:6] 10/22	    BatchTime 1.1915    DataTime 0.0001    Loss_Classification 2.5051e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.648
[Epoch:6] 11/22	    BatchTime 1.2101    DataTime 0.0001    Loss_Classification 2.6195e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:6] 12/22	    BatchTime 1.1822    DataTime 0.0001    Loss_Classification 3.0618e+00    Loss_Distance 0.0000e+00    acc@1 83.008    acc@5 86.133
[Epoch:6] 13/22	    BatchTime 1.1981    DataTime 0.0003    Loss_Classification 3.3720e+00    Loss_Distance 0.0000e+00    acc@1 82.812    acc@5 85.352
[Epoch:6] 14/22	    BatchTime 1.2261    DataTime 0.0001    Loss_Classification 3.3688e+00    Loss_Distance 0.0000e+00    acc@1 83.008    acc@5 84.766
[Epoch:6] 15/22	    BatchTime 1.2208    DataTime 0.0002    Loss_Classification 3.0299e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 87.500
[Epoch:6] 16/22	    BatchTime 1.2350    DataTime 0.0001    Loss_Classification 2.0699e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.625
[Epoch:6] 17/22	    BatchTime 1.2416    DataTime 0.0002    Loss_Classification 3.0146e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 86.719
[Epoch:6] 18/22	    BatchTime 1.2319    DataTime 0.0003    Loss_Classification 2.7078e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.891
[Epoch:6] 19/22	    BatchTime 1.2268    DataTime 0.0000    Loss_Classification 2.7362e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.062
[Epoch:6] 20/22	    BatchTime 1.2123    DataTime 0.0001    Loss_Classification 2.5682e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:6] 21/22	    BatchTime 1.2332    DataTime 0.0001    Loss_Classification 2.6723e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.477
[Epoch:6] 22/22	    BatchTime 1.2255    DataTime 0.0001    Loss_Classification 2.6130e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.281
[Epoch:6]  32.38    Loss_Classification 2.7699e+00    val_Loss_Classification 2.7240e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 85.804    val_acc@1 86.250    acc@5 88.015    val_acc@5 88.335
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00006-val_Loss_Classification_2.7240-val_Loss_Distance_0.0000.pth

Epoch 7 learning_rate : 9.140576474687265e-06
[Epoch:7] 1/22	    BatchTime 7.2561    DataTime 5.8641    Loss_Classification 2.9276e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.500
[Epoch:7] 2/22	    BatchTime 1.1333    DataTime 0.0002    Loss_Classification 2.6153e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.062
[Epoch:7] 3/22	    BatchTime 1.1358    DataTime 0.0002    Loss_Classification 2.1943e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 91.602
[Epoch:7] 4/22	    BatchTime 1.1672    DataTime 0.0002    Loss_Classification 2.7561e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.281
[Epoch:7] 5/22	    BatchTime 1.1679    DataTime 0.0002    Loss_Classification 2.3350e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.648
[Epoch:7] 6/22	    BatchTime 1.1867    DataTime 0.0001    Loss_Classification 2.3015e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.234
[Epoch:7] 7/22	    BatchTime 1.1825    DataTime 0.0002    Loss_Classification 2.9425e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 86.914
[Epoch:7] 8/22	    BatchTime 1.1945    DataTime 0.0002    Loss_Classification 2.3443e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.648
[Epoch:7] 9/22	    BatchTime 1.2111    DataTime 0.0000    Loss_Classification 2.6564e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 89.258
[Epoch:7] 10/22	    BatchTime 1.2120    DataTime 0.0001    Loss_Classification 2.5932e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:7] 11/22	    BatchTime 1.1888    DataTime 0.0001    Loss_Classification 3.3179e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 85.547
[Epoch:7] 12/22	    BatchTime 1.2418    DataTime 0.0002    Loss_Classification 2.4450e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.867
[Epoch:7] 13/22	    BatchTime 1.2123    DataTime 0.0002    Loss_Classification 2.9166e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.695
[Epoch:7] 14/22	    BatchTime 1.2156    DataTime 0.0001    Loss_Classification 2.9987e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.109
[Epoch:7] 15/22	    BatchTime 1.2292    DataTime 0.0003    Loss_Classification 2.8912e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.109
[Epoch:7] 16/22	    BatchTime 1.2217    DataTime 0.0002    Loss_Classification 2.6731e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:7] 17/22	    BatchTime 1.2064    DataTime 0.0001    Loss_Classification 2.8679e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 87.500
[Epoch:7] 18/22	    BatchTime 1.2938    DataTime 0.0002    Loss_Classification 2.6134e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.477
[Epoch:7] 19/22	    BatchTime 1.2536    DataTime 0.0002    Loss_Classification 2.4946e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:7] 20/22	    BatchTime 1.2288    DataTime 0.0002    Loss_Classification 2.3883e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.453
[Epoch:7] 21/22	    BatchTime 1.2201    DataTime 0.0003    Loss_Classification 2.6834e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.867
[Epoch:7] 22/22	    BatchTime 1.2294    DataTime 0.0002    Loss_Classification 2.7073e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.477
[Epoch:7]  32.59    Loss_Classification 2.6665e+00    val_Loss_Classification 2.6650e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 86.142    val_acc@1 86.921    acc@5 88.565    val_acc@5 88.865
val_Loss_Classification improve from 2.693345992377218 to 2.6650134081889396
Save model to ./models/ep00007-val_Loss_Classification_2.6650-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00007-val_Loss_Classification_2.6650-val_Loss_Distance_0.0000.pth

Epoch 8 learning_rate : 8.844151714648274e-06
[Epoch:8] 1/22	    BatchTime 7.0084    DataTime 5.6636    Loss_Classification 2.4786e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:8] 2/22	    BatchTime 1.1583    DataTime 0.0003    Loss_Classification 2.6380e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 88.086
[Epoch:8] 3/22	    BatchTime 1.1346    DataTime 0.0002    Loss_Classification 3.2484e+00    Loss_Distance 0.0000e+00    acc@1 83.008    acc@5 85.938
[Epoch:8] 4/22	    BatchTime 1.1445    DataTime 0.0000    Loss_Classification 2.3283e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.625
[Epoch:8] 5/22	    BatchTime 1.1652    DataTime 0.0001    Loss_Classification 2.3179e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:8] 6/22	    BatchTime 1.1728    DataTime 0.0001    Loss_Classification 3.1802e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.695
[Epoch:8] 7/22	    BatchTime 1.2029    DataTime 0.0003    Loss_Classification 2.3930e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.453
[Epoch:8] 8/22	    BatchTime 1.2537    DataTime 0.0001    Loss_Classification 3.0478e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.891
[Epoch:8] 9/22	    BatchTime 1.1995    DataTime 0.0001    Loss_Classification 2.8476e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.500
[Epoch:8] 10/22	    BatchTime 1.2046    DataTime 0.0001    Loss_Classification 2.5188e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.891
[Epoch:8] 11/22	    BatchTime 1.1666    DataTime 0.0003    Loss_Classification 2.0767e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.234
[Epoch:8] 12/22	    BatchTime 1.2390    DataTime 0.0002    Loss_Classification 2.3120e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:8] 13/22	    BatchTime 1.2229    DataTime 0.0002    Loss_Classification 2.2555e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 90.234
[Epoch:8] 14/22	    BatchTime 1.2262    DataTime 0.0002    Loss_Classification 2.8164e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.086
[Epoch:8] 15/22	    BatchTime 1.1925    DataTime 0.0002    Loss_Classification 2.8720e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 87.109
[Epoch:8] 16/22	    BatchTime 1.1939    DataTime 0.0002    Loss_Classification 3.4637e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 86.328
[Epoch:8] 17/22	    BatchTime 1.2606    DataTime 0.0002    Loss_Classification 2.3998e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:8] 18/22	    BatchTime 1.2261    DataTime 0.0002    Loss_Classification 2.2495e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:8] 19/22	    BatchTime 1.1915    DataTime 0.0001    Loss_Classification 2.9354e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 88.086
[Epoch:8] 20/22	    BatchTime 1.2808    DataTime 0.0002    Loss_Classification 2.7334e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.695
[Epoch:8] 21/22	    BatchTime 1.2440    DataTime 0.0001    Loss_Classification 2.8202e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.891
[Epoch:8] 22/22	    BatchTime 1.2338    DataTime 0.0001    Loss_Classification 3.0623e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 86.523
[Epoch:8]  32.32    Loss_Classification 2.6816e+00    val_Loss_Classification 2.5641e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 86.097    val_acc@1 86.532    acc@5 88.423    val_acc@5 88.759
val_Loss_Classification improve from 2.6650134081889396 to 2.5640893257224717
Save model to ./models/ep00008-val_Loss_Classification_2.5641-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00008-val_Loss_Classification_2.5641-val_Loss_Distance_0.0000.pth

Epoch 9 learning_rate : 8.511087728614863e-06
[Epoch:9] 1/22	    BatchTime 7.3575    DataTime 6.1172    Loss_Classification 2.3088e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.453
[Epoch:9] 2/22	    BatchTime 1.1376    DataTime 0.0002    Loss_Classification 2.6387e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.867
[Epoch:9] 3/22	    BatchTime 1.1332    DataTime 0.0001    Loss_Classification 2.2647e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:9] 4/22	    BatchTime 1.1789    DataTime 0.0002    Loss_Classification 2.6945e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.281
[Epoch:9] 5/22	    BatchTime 1.1807    DataTime 0.0001    Loss_Classification 2.3466e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:9] 6/22	    BatchTime 1.1657    DataTime 0.0005    Loss_Classification 2.8014e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.305
[Epoch:9] 7/22	    BatchTime 1.1901    DataTime 0.0001    Loss_Classification 2.5415e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:9] 8/22	    BatchTime 1.1766    DataTime 0.0002    Loss_Classification 2.6788e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:9] 9/22	    BatchTime 1.1741    DataTime 0.0006    Loss_Classification 2.5699e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.281
[Epoch:9] 10/22	    BatchTime 1.2515    DataTime 0.0002    Loss_Classification 2.5197e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 88.477
[Epoch:9] 11/22	    BatchTime 1.2091    DataTime 0.0002    Loss_Classification 2.8769e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.477
[Epoch:9] 12/22	    BatchTime 1.1956    DataTime 0.0002    Loss_Classification 2.5551e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.844
[Epoch:9] 13/22	    BatchTime 1.1796    DataTime 0.0002    Loss_Classification 2.9837e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.500
[Epoch:9] 14/22	    BatchTime 1.1981    DataTime 0.0002    Loss_Classification 2.5591e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 87.695
[Epoch:9] 15/22	    BatchTime 1.3052    DataTime 0.0002    Loss_Classification 2.6539e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.062
[Epoch:9] 16/22	    BatchTime 1.2409    DataTime 0.0002    Loss_Classification 2.6696e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.281
[Epoch:9] 17/22	    BatchTime 1.2109    DataTime 0.0002    Loss_Classification 3.2029e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 85.938
[Epoch:9] 18/22	    BatchTime 1.2084    DataTime 0.0002    Loss_Classification 2.4892e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 90.039
[Epoch:9] 19/22	    BatchTime 1.2209    DataTime 0.0002    Loss_Classification 2.5694e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 88.477
[Epoch:9] 20/22	    BatchTime 1.2216    DataTime 0.0002    Loss_Classification 3.2236e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 86.133
[Epoch:9] 21/22	    BatchTime 1.2232    DataTime 0.0002    Loss_Classification 2.4530e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.844
[Epoch:9] 22/22	    BatchTime 1.2368    DataTime 0.0002    Loss_Classification 2.6561e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.867
[Epoch:9]  32.60    Loss_Classification 2.6481e+00    val_Loss_Classification 2.7752e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 86.373    val_acc@1 86.426    acc@5 88.592    val_acc@5 88.158
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00009-val_Loss_Classification_2.7752-val_Loss_Distance_0.0000.pth

Epoch 10 learning_rate : 8.14503363531613e-06
[Epoch:10] 1/22	    BatchTime 7.2011    DataTime 5.8031    Loss_Classification 2.7645e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.891
[Epoch:10] 2/22	    BatchTime 1.1333    DataTime 0.0002    Loss_Classification 1.9714e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:10] 3/22	    BatchTime 1.1497    DataTime 0.0001    Loss_Classification 2.6775e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.062
[Epoch:10] 4/22	    BatchTime 1.1649    DataTime 0.0001    Loss_Classification 3.3458e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 86.523
[Epoch:10] 5/22	    BatchTime 1.1660    DataTime 0.0002    Loss_Classification 2.4262e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.648
[Epoch:10] 6/22	    BatchTime 1.1998    DataTime 0.0001    Loss_Classification 2.6118e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 88.672
[Epoch:10] 7/22	    BatchTime 1.1951    DataTime 0.0002    Loss_Classification 2.7587e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 87.891
[Epoch:10] 8/22	    BatchTime 1.2162    DataTime 0.0001    Loss_Classification 2.2742e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:10] 9/22	    BatchTime 1.2212    DataTime 0.0001    Loss_Classification 2.9328e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.281
[Epoch:10] 10/22	    BatchTime 1.2115    DataTime 0.0001    Loss_Classification 2.3243e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.258
[Epoch:10] 11/22	    BatchTime 1.1976    DataTime 0.0003    Loss_Classification 2.9776e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.500
[Epoch:10] 12/22	    BatchTime 1.1886    DataTime 0.0001    Loss_Classification 2.6144e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.477
[Epoch:10] 13/22	    BatchTime 1.2434    DataTime 0.0002    Loss_Classification 2.4623e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.648
[Epoch:10] 14/22	    BatchTime 1.2127    DataTime 0.0002    Loss_Classification 2.3208e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.453
[Epoch:10] 15/22	    BatchTime 1.2006    DataTime 0.0001    Loss_Classification 2.2177e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:10] 16/22	    BatchTime 1.1923    DataTime 0.0002    Loss_Classification 2.6684e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.086
[Epoch:10] 17/22	    BatchTime 1.2246    DataTime 0.0002    Loss_Classification 2.7874e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 87.305
[Epoch:10] 18/22	    BatchTime 1.2781    DataTime 0.0002    Loss_Classification 2.5056e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.258
[Epoch:10] 19/22	    BatchTime 1.2441    DataTime 0.0002    Loss_Classification 2.7720e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 87.891
[Epoch:10] 20/22	    BatchTime 1.2216    DataTime 0.0001    Loss_Classification 2.4774e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.062
[Epoch:10] 21/22	    BatchTime 1.2218    DataTime 0.0003    Loss_Classification 2.4266e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 88.867
[Epoch:10] 22/22	    BatchTime 1.3638    DataTime 0.0000    Loss_Classification 2.0702e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.820
[Epoch:10]  32.65    Loss_Classification 2.5631e+00    val_Loss_Classification 2.6276e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 86.799    val_acc@1 86.780    acc@5 88.885    val_acc@5 88.795
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00010-val_Loss_Classification_2.6276-val_Loss_Distance_0.0000.pth

Epoch 11 learning_rate : 7.75e-06
[Epoch:11] 1/22	    BatchTime 6.8167    DataTime 5.5521    Loss_Classification 2.6820e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 88.086
[Epoch:11] 2/22	    BatchTime 1.1495    DataTime 0.0002    Loss_Classification 2.6296e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 89.258
[Epoch:11] 3/22	    BatchTime 1.1490    DataTime 0.0002    Loss_Classification 2.7589e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.062
[Epoch:11] 4/22	    BatchTime 1.1688    DataTime 0.0001    Loss_Classification 1.9699e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:11] 5/22	    BatchTime 1.1752    DataTime 0.0008    Loss_Classification 2.9991e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 86.719
[Epoch:11] 6/22	    BatchTime 1.1960    DataTime 0.0003    Loss_Classification 2.4331e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.867
[Epoch:11] 7/22	    BatchTime 1.1822    DataTime 0.0003    Loss_Classification 2.2433e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 90.039
[Epoch:11] 8/22	    BatchTime 1.1939    DataTime 0.0002    Loss_Classification 2.7195e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.891
[Epoch:11] 9/22	    BatchTime 1.2153    DataTime 0.0002    Loss_Classification 2.6814e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.867
[Epoch:11] 10/22	    BatchTime 1.2028    DataTime 0.0002    Loss_Classification 2.9138e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 87.500
[Epoch:11] 11/22	    BatchTime 1.1803    DataTime 0.0002    Loss_Classification 2.0702e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:11] 12/22	    BatchTime 1.2611    DataTime 0.0001    Loss_Classification 2.2463e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:11] 13/22	    BatchTime 1.2312    DataTime 0.0002    Loss_Classification 2.1241e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:11] 14/22	    BatchTime 1.2323    DataTime 0.0000    Loss_Classification 2.2379e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:11] 15/22	    BatchTime 1.2015    DataTime 0.0001    Loss_Classification 2.7538e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 86.914
[Epoch:11] 16/22	    BatchTime 1.2798    DataTime 0.0001    Loss_Classification 2.2712e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:11] 17/22	    BatchTime 1.2139    DataTime 0.0002    Loss_Classification 2.4097e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:11] 18/22	    BatchTime 1.2427    DataTime 0.0002    Loss_Classification 2.5069e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 90.039
[Epoch:11] 19/22	    BatchTime 1.2216    DataTime 0.0002    Loss_Classification 2.9163e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 87.500
[Epoch:11] 20/22	    BatchTime 1.2274    DataTime 0.0001    Loss_Classification 2.2881e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:11] 21/22	    BatchTime 1.2266    DataTime 0.0001    Loss_Classification 2.4637e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.258
[Epoch:11] 22/22	    BatchTime 1.2188    DataTime 0.0001    Loss_Classification 2.9544e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 86.523
[Epoch:11]  32.19    Loss_Classification 2.5124e+00    val_Loss_Classification 2.6160e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 86.816    val_acc@1 87.133    acc@5 89.071    val_acc@5 88.901
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00011-val_Loss_Classification_2.6160-val_Loss_Distance_0.0000.pth

Epoch 12 learning_rate : 7.330314893841102e-06
[Epoch:12] 1/22	    BatchTime 7.3238    DataTime 5.9003    Loss_Classification 2.9774e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.305
[Epoch:12] 2/22	    BatchTime 1.1349    DataTime 0.0003    Loss_Classification 2.6619e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.258
[Epoch:12] 3/22	    BatchTime 1.1447    DataTime 0.0002    Loss_Classification 2.9448e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 87.305
[Epoch:12] 4/22	    BatchTime 1.1916    DataTime 0.0002    Loss_Classification 2.0265e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 91.406
[Epoch:12] 5/22	    BatchTime 1.1664    DataTime 0.0002    Loss_Classification 2.4889e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 89.258
[Epoch:12] 6/22	    BatchTime 1.1824    DataTime 0.0002    Loss_Classification 2.4954e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.258
[Epoch:12] 7/22	    BatchTime 1.1895    DataTime 0.0002    Loss_Classification 2.8711e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 87.695
[Epoch:12] 8/22	    BatchTime 1.1805    DataTime 0.0002    Loss_Classification 2.2628e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 90.234
[Epoch:12] 9/22	    BatchTime 1.2005    DataTime 0.0002    Loss_Classification 2.0933e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.820
[Epoch:12] 10/22	    BatchTime 1.2238    DataTime 0.0002    Loss_Classification 2.3396e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:12] 11/22	    BatchTime 1.2024    DataTime 0.0002    Loss_Classification 2.5363e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.453
[Epoch:12] 12/22	    BatchTime 1.2181    DataTime 0.0005    Loss_Classification 3.1848e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 86.719
[Epoch:12] 13/22	    BatchTime 1.2113    DataTime 0.0002    Loss_Classification 1.6896e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.188
[Epoch:12] 14/22	    BatchTime 1.2092    DataTime 0.0002    Loss_Classification 2.2600e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.648
[Epoch:12] 15/22	    BatchTime 1.2173    DataTime 0.0004    Loss_Classification 2.4400e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 89.258
[Epoch:12] 16/22	    BatchTime 1.3444    DataTime 0.0000    Loss_Classification 2.4953e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:12] 17/22	    BatchTime 1.2847    DataTime 0.0002    Loss_Classification 2.4699e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 89.258
[Epoch:12] 18/22	    BatchTime 1.2437    DataTime 0.0002    Loss_Classification 2.4442e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.477
[Epoch:12] 19/22	    BatchTime 1.2375    DataTime 0.0002    Loss_Classification 2.9378e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.477
[Epoch:12] 20/22	    BatchTime 1.2059    DataTime 0.0002    Loss_Classification 2.0761e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.992
[Epoch:12] 21/22	    BatchTime 1.2257    DataTime 0.0002    Loss_Classification 3.0760e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 86.914
[Epoch:12] 22/22	    BatchTime 1.2470    DataTime 0.0002    Loss_Classification 1.7186e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:12]  32.79    Loss_Classification 2.4768e+00    val_Loss_Classification 2.5265e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.100    val_acc@1 87.275    acc@5 89.382    val_acc@5 89.148
val_Loss_Classification improve from 2.5640893257224717 to 2.526490866484765
Save model to ./models/ep00012-val_Loss_Classification_2.5265-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00012-val_Loss_Classification_2.5265-val_Loss_Distance_0.0000.pth

Epoch 13 learning_rate : 6.890576474687264e-06
[Epoch:13] 1/22	    BatchTime 7.1393    DataTime 5.8614    Loss_Classification 2.8623e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.086
[Epoch:13] 2/22	    BatchTime 1.1470    DataTime 0.0002    Loss_Classification 2.6909e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.867
[Epoch:13] 3/22	    BatchTime 1.1368    DataTime 0.0003    Loss_Classification 2.5089e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.477
[Epoch:13] 4/22	    BatchTime 1.1664    DataTime 0.0003    Loss_Classification 2.9840e+00    Loss_Distance 0.0000e+00    acc@1 84.180    acc@5 87.109
[Epoch:13] 5/22	    BatchTime 1.1586    DataTime 0.0002    Loss_Classification 2.0453e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:13] 6/22	    BatchTime 1.1898    DataTime 0.0002    Loss_Classification 2.7159e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 89.062
[Epoch:13] 7/22	    BatchTime 1.1937    DataTime 0.0002    Loss_Classification 2.1277e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:13] 8/22	    BatchTime 1.1880    DataTime 0.0002    Loss_Classification 2.7667e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.672
[Epoch:13] 9/22	    BatchTime 1.1950    DataTime 0.0003    Loss_Classification 2.4323e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:13] 10/22	    BatchTime 1.2365    DataTime 0.0000    Loss_Classification 2.0449e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.820
[Epoch:13] 11/22	    BatchTime 1.2282    DataTime 0.0001    Loss_Classification 2.8145e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.109
[Epoch:13] 12/22	    BatchTime 1.2343    DataTime 0.0002    Loss_Classification 2.6290e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.867
[Epoch:13] 13/22	    BatchTime 1.1920    DataTime 0.0002    Loss_Classification 2.9660e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.305
[Epoch:13] 14/22	    BatchTime 1.1767    DataTime 0.0002    Loss_Classification 2.9243e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 87.891
[Epoch:13] 15/22	    BatchTime 1.2249    DataTime 0.0001    Loss_Classification 2.4726e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:13] 16/22	    BatchTime 1.2247    DataTime 0.0001    Loss_Classification 2.4998e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:13] 17/22	    BatchTime 1.2428    DataTime 0.0001    Loss_Classification 2.4603e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.672
[Epoch:13] 18/22	    BatchTime 1.2292    DataTime 0.0002    Loss_Classification 2.3495e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:13] 19/22	    BatchTime 1.2032    DataTime 0.0002    Loss_Classification 2.0856e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:13] 20/22	    BatchTime 1.2371    DataTime 0.0002    Loss_Classification 2.3072e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:13] 21/22	    BatchTime 1.3065    DataTime 0.0002    Loss_Classification 1.9785e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:13] 22/22	    BatchTime 1.2761    DataTime 0.0001    Loss_Classification 1.9879e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 91.602
[Epoch:13]  32.53    Loss_Classification 2.4843e+00    val_Loss_Classification 2.5226e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.180    val_acc@1 87.027    acc@5 89.293    val_acc@5 88.971
val_Loss_Classification improve from 2.526490866484765 to 2.522593669901471
Save model to ./models/ep00013-val_Loss_Classification_2.5226-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00013-val_Loss_Classification_2.5226-val_Loss_Distance_0.0000.pth

Epoch 14 learning_rate : 6.435602608679916e-06
[Epoch:14] 1/22	    BatchTime 7.2890    DataTime 5.9027    Loss_Classification 2.3624e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:14] 2/22	    BatchTime 1.1499    DataTime 0.0002    Loss_Classification 2.0364e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:14] 3/22	    BatchTime 1.1373    DataTime 0.0002    Loss_Classification 2.9429e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 87.305
[Epoch:14] 4/22	    BatchTime 1.1579    DataTime 0.0002    Loss_Classification 2.6647e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.477
[Epoch:14] 5/22	    BatchTime 1.1589    DataTime 0.0001    Loss_Classification 2.2178e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 91.016
[Epoch:14] 6/22	    BatchTime 1.1590    DataTime 0.0001    Loss_Classification 2.3037e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:14] 7/22	    BatchTime 1.1878    DataTime 0.0006    Loss_Classification 2.3962e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.258
[Epoch:14] 8/22	    BatchTime 1.1993    DataTime 0.0002    Loss_Classification 2.1333e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.039
[Epoch:14] 9/22	    BatchTime 1.1826    DataTime 0.0001    Loss_Classification 1.9307e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.820
[Epoch:14] 10/22	    BatchTime 1.2065    DataTime 0.0003    Loss_Classification 2.2522e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.453
[Epoch:14] 11/22	    BatchTime 1.2409    DataTime 0.0001    Loss_Classification 2.2859e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.844
[Epoch:14] 12/22	    BatchTime 1.2093    DataTime 0.0002    Loss_Classification 2.6930e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:14] 13/22	    BatchTime 1.2040    DataTime 0.0002    Loss_Classification 2.4495e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.453
[Epoch:14] 14/22	    BatchTime 1.2190    DataTime 0.0001    Loss_Classification 2.2764e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.453
[Epoch:14] 15/22	    BatchTime 1.2170    DataTime 0.0002    Loss_Classification 2.8814e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.891
[Epoch:14] 16/22	    BatchTime 1.2003    DataTime 0.0002    Loss_Classification 2.5958e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.258
[Epoch:14] 17/22	    BatchTime 1.2150    DataTime 0.0002    Loss_Classification 2.2951e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:14] 18/22	    BatchTime 1.2229    DataTime 0.0000    Loss_Classification 2.7366e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.867
[Epoch:14] 19/22	    BatchTime 1.2141    DataTime 0.0001    Loss_Classification 2.4017e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.258
[Epoch:14] 20/22	    BatchTime 1.2850    DataTime 0.0002    Loss_Classification 2.4015e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:14] 21/22	    BatchTime 1.2313    DataTime 0.0002    Loss_Classification 2.1484e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 91.211
[Epoch:14] 22/22	    BatchTime 1.2271    DataTime 0.0002    Loss_Classification 2.7044e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.672
[Epoch:14]  32.51    Loss_Classification 2.4141e+00    val_Loss_Classification 2.6951e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.278    val_acc@1 86.214    acc@5 89.515    val_acc@5 88.229
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00014-val_Loss_Classification_2.6951-val_Loss_Distance_0.0000.pth

Epoch 15 learning_rate : 5.970378084704441e-06
[Epoch:15] 1/22	    BatchTime 7.6219    DataTime 6.1879    Loss_Classification 2.4038e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.648
[Epoch:15] 2/22	    BatchTime 1.1337    DataTime 0.0002    Loss_Classification 3.1291e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 85.938
[Epoch:15] 3/22	    BatchTime 1.1482    DataTime 0.0001    Loss_Classification 2.8428e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 88.086
[Epoch:15] 4/22	    BatchTime 1.1647    DataTime 0.0001    Loss_Classification 2.4852e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:15] 5/22	    BatchTime 1.1745    DataTime 0.0001    Loss_Classification 2.2277e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.430
[Epoch:15] 6/22	    BatchTime 1.1761    DataTime 0.0002    Loss_Classification 2.4875e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:15] 7/22	    BatchTime 1.2075    DataTime 0.0001    Loss_Classification 2.3577e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:15] 8/22	    BatchTime 1.2277    DataTime 0.0002    Loss_Classification 2.4692e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.062
[Epoch:15] 9/22	    BatchTime 1.1935    DataTime 0.0001    Loss_Classification 1.9034e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:15] 10/22	    BatchTime 1.1968    DataTime 0.0002    Loss_Classification 2.5795e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.062
[Epoch:15] 11/22	    BatchTime 1.1703    DataTime 0.0002    Loss_Classification 1.9662e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:15] 12/22	    BatchTime 1.2037    DataTime 0.0002    Loss_Classification 2.3501e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:15] 13/22	    BatchTime 1.2235    DataTime 0.0002    Loss_Classification 2.6479e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.891
[Epoch:15] 14/22	    BatchTime 1.2497    DataTime 0.0002    Loss_Classification 2.0850e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.039
[Epoch:15] 15/22	    BatchTime 1.2301    DataTime 0.0002    Loss_Classification 2.5802e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.672
[Epoch:15] 16/22	    BatchTime 1.2334    DataTime 0.0003    Loss_Classification 2.2966e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.039
[Epoch:15] 17/22	    BatchTime 1.2803    DataTime 0.0001    Loss_Classification 2.6841e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.062
[Epoch:15] 18/22	    BatchTime 1.2646    DataTime 0.0002    Loss_Classification 2.8570e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.086
[Epoch:15] 19/22	    BatchTime 1.2208    DataTime 0.0002    Loss_Classification 2.2155e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.039
[Epoch:15] 20/22	    BatchTime 1.2075    DataTime 0.0002    Loss_Classification 2.7288e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.477
[Epoch:15] 21/22	    BatchTime 1.2049    DataTime 0.0001    Loss_Classification 2.2042e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:15] 22/22	    BatchTime 1.3599    DataTime 0.0002    Loss_Classification 2.5118e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 89.258
[Epoch:15]  33.09    Loss_Classification 2.4551e+00    val_Loss_Classification 2.6567e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.340    val_acc@1 86.992    acc@5 89.338    val_acc@5 88.547
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00015-val_Loss_Classification_2.6567-val_Loss_Distance_0.0000.pth

Epoch 16 learning_rate : 5.500000000000001e-06
[Epoch:16] 1/22	    BatchTime 7.4848    DataTime 6.2476    Loss_Classification 1.9374e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 91.016
[Epoch:16] 2/22	    BatchTime 1.1355    DataTime 0.0002    Loss_Classification 2.3296e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:16] 3/22	    BatchTime 1.1344    DataTime 0.0001    Loss_Classification 2.6483e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 87.891
[Epoch:16] 4/22	    BatchTime 1.1541    DataTime 0.0002    Loss_Classification 2.7635e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 88.086
[Epoch:16] 5/22	    BatchTime 1.1673    DataTime 0.0002    Loss_Classification 2.2345e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:16] 6/22	    BatchTime 1.2053    DataTime 0.0002    Loss_Classification 2.3482e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:16] 7/22	    BatchTime 1.1898    DataTime 0.0003    Loss_Classification 2.0015e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 92.188
[Epoch:16] 8/22	    BatchTime 1.1891    DataTime 0.0003    Loss_Classification 2.3750e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.453
[Epoch:16] 9/22	    BatchTime 1.2218    DataTime 0.0001    Loss_Classification 2.6812e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.281
[Epoch:16] 10/22	    BatchTime 1.2130    DataTime 0.0002    Loss_Classification 2.0687e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.820
[Epoch:16] 11/22	    BatchTime 1.1989    DataTime 0.0003    Loss_Classification 2.2977e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:16] 12/22	    BatchTime 1.2136    DataTime 0.0001    Loss_Classification 2.1923e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:16] 13/22	    BatchTime 1.1896    DataTime 0.0002    Loss_Classification 2.1923e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:16] 14/22	    BatchTime 1.2694    DataTime 0.0001    Loss_Classification 2.4357e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:16] 15/22	    BatchTime 1.2604    DataTime 0.0002    Loss_Classification 2.5745e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:16] 16/22	    BatchTime 1.2445    DataTime 0.0003    Loss_Classification 2.1129e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:16] 17/22	    BatchTime 1.2143    DataTime 0.0000    Loss_Classification 2.7329e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 88.672
[Epoch:16] 18/22	    BatchTime 1.2145    DataTime 0.0001    Loss_Classification 2.5497e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.453
[Epoch:16] 19/22	    BatchTime 1.2103    DataTime 0.0001    Loss_Classification 2.5559e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.477
[Epoch:16] 20/22	    BatchTime 1.2624    DataTime 0.0002    Loss_Classification 2.2481e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.844
[Epoch:16] 21/22	    BatchTime 1.2500    DataTime 0.0002    Loss_Classification 2.7173e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.062
[Epoch:16] 22/22	    BatchTime 1.2238    DataTime 0.0002    Loss_Classification 2.1227e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:16]  32.85    Loss_Classification 2.3691e+00    val_Loss_Classification 2.4876e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.624    val_acc@1 87.345    acc@5 89.711    val_acc@5 89.183
val_Loss_Classification improve from 2.522593669901471 to 2.487568302093862
Save model to ./models/ep00016-val_Loss_Classification_2.4876-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00016-val_Loss_Classification_2.4876-val_Loss_Distance_0.0000.pth

Epoch 17 learning_rate : 5.02962191529556e-06
[Epoch:17] 1/22	    BatchTime 7.5184    DataTime 6.2469    Loss_Classification 1.9911e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:17] 2/22	    BatchTime 1.1488    DataTime 0.0000    Loss_Classification 3.1075e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 85.938
[Epoch:17] 3/22	    BatchTime 1.1385    DataTime 0.0002    Loss_Classification 2.5209e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.453
[Epoch:17] 4/22	    BatchTime 1.1642    DataTime 0.0003    Loss_Classification 2.4238e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.648
[Epoch:17] 5/22	    BatchTime 1.1496    DataTime 0.0005    Loss_Classification 2.5524e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.867
[Epoch:17] 6/22	    BatchTime 1.1950    DataTime 0.0002    Loss_Classification 2.3590e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.844
[Epoch:17] 7/22	    BatchTime 1.1698    DataTime 0.0002    Loss_Classification 2.4871e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.648
[Epoch:17] 8/22	    BatchTime 1.2091    DataTime 0.0002    Loss_Classification 2.3065e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:17] 9/22	    BatchTime 1.1968    DataTime 0.0002    Loss_Classification 2.0750e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:17] 10/22	    BatchTime 1.2090    DataTime 0.0002    Loss_Classification 2.4273e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.453
[Epoch:17] 11/22	    BatchTime 1.1938    DataTime 0.0002    Loss_Classification 2.2429e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:17] 12/22	    BatchTime 1.1758    DataTime 0.0002    Loss_Classification 2.9270e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 87.109
[Epoch:17] 13/22	    BatchTime 1.1790    DataTime 0.0002    Loss_Classification 2.1051e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.625
[Epoch:17] 14/22	    BatchTime 1.3058    DataTime 0.0003    Loss_Classification 2.1459e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:17] 15/22	    BatchTime 1.2416    DataTime 0.0002    Loss_Classification 2.2341e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.844
[Epoch:17] 16/22	    BatchTime 1.2101    DataTime 0.0002    Loss_Classification 2.5770e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.453
[Epoch:17] 17/22	    BatchTime 1.2021    DataTime 0.0002    Loss_Classification 2.3221e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.648
[Epoch:17] 18/22	    BatchTime 1.1929    DataTime 0.0002    Loss_Classification 2.6040e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.672
[Epoch:17] 19/22	    BatchTime 1.2247    DataTime 0.0003    Loss_Classification 2.6510e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:17] 20/22	    BatchTime 1.3203    DataTime 0.0002    Loss_Classification 1.8416e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.992
[Epoch:17] 21/22	    BatchTime 1.2477    DataTime 0.0003    Loss_Classification 1.9644e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.016
[Epoch:17] 22/22	    BatchTime 1.2196    DataTime 0.0003    Loss_Classification 2.2282e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.648
[Epoch:17]  32.81    Loss_Classification 2.3679e+00    val_Loss_Classification 2.5360e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.757    val_acc@1 86.850    acc@5 89.613    val_acc@5 88.724
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00017-val_Loss_Classification_2.5360-val_Loss_Distance_0.0000.pth

Epoch 18 learning_rate : 4.564397391320083e-06
[Epoch:18] 1/22	    BatchTime 6.9870    DataTime 5.6872    Loss_Classification 2.7287e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.086
[Epoch:18] 2/22	    BatchTime 1.1475    DataTime 0.0002    Loss_Classification 2.3361e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:18] 3/22	    BatchTime 1.1372    DataTime 0.0002    Loss_Classification 2.4455e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.453
[Epoch:18] 4/22	    BatchTime 1.1593    DataTime 0.0002    Loss_Classification 2.3849e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:18] 5/22	    BatchTime 1.1605    DataTime 0.0002    Loss_Classification 2.9558e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.500
[Epoch:18] 6/22	    BatchTime 1.1740    DataTime 0.0001    Loss_Classification 2.4950e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:18] 7/22	    BatchTime 1.2317    DataTime 0.0003    Loss_Classification 2.5826e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.086
[Epoch:18] 8/22	    BatchTime 1.1675    DataTime 0.0000    Loss_Classification 2.1508e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.648
[Epoch:18] 9/22	    BatchTime 1.1781    DataTime 0.0002    Loss_Classification 2.3449e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:18] 10/22	    BatchTime 1.3045    DataTime 0.0001    Loss_Classification 2.3992e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.039
[Epoch:18] 11/22	    BatchTime 1.2225    DataTime 0.0002    Loss_Classification 1.9909e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.406
[Epoch:18] 12/22	    BatchTime 1.2114    DataTime 0.0002    Loss_Classification 1.8644e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.188
[Epoch:18] 13/22	    BatchTime 1.1793    DataTime 0.0002    Loss_Classification 1.9632e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.406
[Epoch:18] 14/22	    BatchTime 1.2162    DataTime 0.0002    Loss_Classification 2.7876e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 88.477
[Epoch:18] 15/22	    BatchTime 1.2153    DataTime 0.0002    Loss_Classification 2.5215e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 89.258
[Epoch:18] 16/22	    BatchTime 1.2178    DataTime 0.0002    Loss_Classification 2.5412e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.453
[Epoch:18] 17/22	    BatchTime 1.2087    DataTime 0.0002    Loss_Classification 2.1057e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.820
[Epoch:18] 18/22	    BatchTime 1.2371    DataTime 0.0001    Loss_Classification 2.4213e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.258
[Epoch:18] 19/22	    BatchTime 1.2169    DataTime 0.0002    Loss_Classification 2.4182e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 90.039
[Epoch:18] 20/22	    BatchTime 1.2065    DataTime 0.0002    Loss_Classification 2.0775e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.820
[Epoch:18] 21/22	    BatchTime 1.2709    DataTime 0.0002    Loss_Classification 1.9925e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.039
[Epoch:18] 22/22	    BatchTime 1.2796    DataTime 0.0002    Loss_Classification 2.6502e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 89.062
[Epoch:18]  32.33    Loss_Classification 2.3708e+00    val_Loss_Classification 2.5618e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.731    val_acc@1 87.063    acc@5 89.737    val_acc@5 88.901
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00018-val_Loss_Classification_2.5618-val_Loss_Distance_0.0000.pth

Epoch 19 learning_rate : 4.109423525312737e-06
[Epoch:19] 1/22	    BatchTime 7.4758    DataTime 6.2069    Loss_Classification 2.5218e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 89.062
[Epoch:19] 2/22	    BatchTime 1.1344    DataTime 0.0002    Loss_Classification 2.5907e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:19] 3/22	    BatchTime 1.1374    DataTime 0.0001    Loss_Classification 2.4918e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.844
[Epoch:19] 4/22	    BatchTime 1.1476    DataTime 0.0005    Loss_Classification 2.1544e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:19] 5/22	    BatchTime 1.1894    DataTime 0.0002    Loss_Classification 2.5277e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.281
[Epoch:19] 6/22	    BatchTime 1.1878    DataTime 0.0002    Loss_Classification 2.1709e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.453
[Epoch:19] 7/22	    BatchTime 1.1989    DataTime 0.0001    Loss_Classification 2.6514e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.672
[Epoch:19] 8/22	    BatchTime 1.1966    DataTime 0.0002    Loss_Classification 2.2070e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.039
[Epoch:19] 9/22	    BatchTime 1.1738    DataTime 0.0002    Loss_Classification 2.6282e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.477
[Epoch:19] 10/22	    BatchTime 1.2517    DataTime 0.0003    Loss_Classification 2.1995e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:19] 11/22	    BatchTime 1.2174    DataTime 0.0000    Loss_Classification 2.2890e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 90.625
[Epoch:19] 12/22	    BatchTime 1.2359    DataTime 0.0001    Loss_Classification 2.2644e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:19] 13/22	    BatchTime 1.2192    DataTime 0.0003    Loss_Classification 1.8962e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.992
[Epoch:19] 14/22	    BatchTime 1.1999    DataTime 0.0001    Loss_Classification 3.2034e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 86.719
[Epoch:19] 15/22	    BatchTime 1.2168    DataTime 0.0002    Loss_Classification 2.2042e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.625
[Epoch:19] 16/22	    BatchTime 1.2531    DataTime 0.0002    Loss_Classification 2.7624e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:19] 17/22	    BatchTime 1.2389    DataTime 0.0001    Loss_Classification 1.8681e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:19] 18/22	    BatchTime 1.2320    DataTime 0.0002    Loss_Classification 2.3494e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:19] 19/22	    BatchTime 1.2074    DataTime 0.0002    Loss_Classification 1.9912e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.602
[Epoch:19] 20/22	    BatchTime 1.2788    DataTime 0.0001    Loss_Classification 2.1879e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.820
[Epoch:19] 21/22	    BatchTime 1.2640    DataTime 0.0001    Loss_Classification 1.9874e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:19] 22/22	    BatchTime 1.2270    DataTime 0.0002    Loss_Classification 1.8724e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:19]  32.88    Loss_Classification 2.3191e+00    val_Loss_Classification 2.5414e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.988    val_acc@1 87.098    acc@5 89.959    val_acc@5 88.830
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00019-val_Loss_Classification_2.5414-val_Loss_Distance_0.0000.pth

Epoch 20 learning_rate : 3.6696851061588997e-06
[Epoch:20] 1/22	    BatchTime 7.4140    DataTime 6.1394    Loss_Classification 1.9612e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.992
[Epoch:20] 2/22	    BatchTime 1.1484    DataTime 0.0002    Loss_Classification 2.7268e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.281
[Epoch:20] 3/22	    BatchTime 1.1483    DataTime 0.0001    Loss_Classification 2.0973e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:20] 4/22	    BatchTime 1.1538    DataTime 0.0002    Loss_Classification 3.2729e+00    Loss_Distance 0.0000e+00    acc@1 83.984    acc@5 85.547
[Epoch:20] 5/22	    BatchTime 1.1722    DataTime 0.0002    Loss_Classification 2.4813e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.453
[Epoch:20] 6/22	    BatchTime 1.1799    DataTime 0.0002    Loss_Classification 2.3857e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:20] 7/22	    BatchTime 1.1829    DataTime 0.0001    Loss_Classification 2.8642e+00    Loss_Distance 0.0000e+00    acc@1 84.961    acc@5 87.695
[Epoch:20] 8/22	    BatchTime 1.2426    DataTime 0.0001    Loss_Classification 2.6153e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.672
[Epoch:20] 9/22	    BatchTime 1.2377    DataTime 0.0002    Loss_Classification 2.1075e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.211
[Epoch:20] 10/22	    BatchTime 1.2149    DataTime 0.0002    Loss_Classification 2.8159e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:20] 11/22	    BatchTime 1.1963    DataTime 0.0002    Loss_Classification 2.2427e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.844
[Epoch:20] 12/22	    BatchTime 1.1900    DataTime 0.0001    Loss_Classification 2.0338e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:20] 13/22	    BatchTime 1.2019    DataTime 0.0001    Loss_Classification 2.3989e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:20] 14/22	    BatchTime 1.2445    DataTime 0.0002    Loss_Classification 2.3259e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.648
[Epoch:20] 15/22	    BatchTime 1.2704    DataTime 0.0002    Loss_Classification 2.1583e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.820
[Epoch:20] 16/22	    BatchTime 1.2489    DataTime 0.0001    Loss_Classification 1.5942e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:20] 17/22	    BatchTime 1.2155    DataTime 0.0002    Loss_Classification 2.4738e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.453
[Epoch:20] 18/22	    BatchTime 1.2281    DataTime 0.0002    Loss_Classification 2.4549e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.258
[Epoch:20] 19/22	    BatchTime 1.2129    DataTime 0.0003    Loss_Classification 2.1461e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:20] 20/22	    BatchTime 1.2230    DataTime 0.0002    Loss_Classification 2.2084e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.234
[Epoch:20] 21/22	    BatchTime 1.2612    DataTime 0.0001    Loss_Classification 2.1486e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:20] 22/22	    BatchTime 1.2535    DataTime 0.0004    Loss_Classification 2.7697e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.305
[Epoch:20]  32.84    Loss_Classification 2.3765e+00    val_Loss_Classification 2.5007e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.704    val_acc@1 87.734    acc@5 89.693    val_acc@5 89.396
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00020-val_Loss_Classification_2.5007-val_Loss_Distance_0.0000.pth

Epoch 21 learning_rate : 3.250000000000001e-06
[Epoch:21] 1/22	    BatchTime 7.2572    DataTime 5.9333    Loss_Classification 2.5637e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 88.867
[Epoch:21] 2/22	    BatchTime 1.1348    DataTime 0.0002    Loss_Classification 1.5801e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:21] 3/22	    BatchTime 1.1388    DataTime 0.0002    Loss_Classification 2.2296e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 90.039
[Epoch:21] 4/22	    BatchTime 1.1627    DataTime 0.0001    Loss_Classification 2.3071e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:21] 5/22	    BatchTime 1.1759    DataTime 0.0002    Loss_Classification 2.4493e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.672
[Epoch:21] 6/22	    BatchTime 1.1835    DataTime 0.0002    Loss_Classification 2.6954e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:21] 7/22	    BatchTime 1.1924    DataTime 0.0002    Loss_Classification 2.9440e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.891
[Epoch:21] 8/22	    BatchTime 1.2476    DataTime 0.0001    Loss_Classification 2.3483e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.453
[Epoch:21] 9/22	    BatchTime 1.2194    DataTime 0.0003    Loss_Classification 2.7263e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 88.086
[Epoch:21] 10/22	    BatchTime 1.1970    DataTime 0.0004    Loss_Classification 2.2830e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.039
[Epoch:21] 11/22	    BatchTime 1.1851    DataTime 0.0002    Loss_Classification 2.0170e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:21] 12/22	    BatchTime 1.2964    DataTime 0.0002    Loss_Classification 2.0773e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:21] 13/22	    BatchTime 1.2486    DataTime 0.0002    Loss_Classification 2.4820e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.648
[Epoch:21] 14/22	    BatchTime 1.1887    DataTime 0.0002    Loss_Classification 2.3380e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 88.867
[Epoch:21] 15/22	    BatchTime 1.1829    DataTime 0.0004    Loss_Classification 2.4002e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.867
[Epoch:21] 16/22	    BatchTime 1.2576    DataTime 0.0002    Loss_Classification 2.6040e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:21] 17/22	    BatchTime 1.2718    DataTime 0.0002    Loss_Classification 2.3674e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.453
[Epoch:21] 18/22	    BatchTime 1.2608    DataTime 0.0000    Loss_Classification 2.3914e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:21] 19/22	    BatchTime 1.2330    DataTime 0.0002    Loss_Classification 2.7324e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.062
[Epoch:21] 20/22	    BatchTime 1.2261    DataTime 0.0002    Loss_Classification 1.8122e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.406
[Epoch:21] 21/22	    BatchTime 1.2351    DataTime 0.0001    Loss_Classification 1.8478e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:21] 22/22	    BatchTime 1.2851    DataTime 0.0002    Loss_Classification 2.6707e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.281
[Epoch:21]  32.78    Loss_Classification 2.3576e+00    val_Loss_Classification 2.4451e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.722    val_acc@1 87.734    acc@5 89.569    val_acc@5 89.537
val_Loss_Classification improve from 2.487568302093862 to 2.445129118103912
Save model to ./models/ep00021-val_Loss_Classification_2.4451-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00021-val_Loss_Classification_2.4451-val_Loss_Distance_0.0000.pth

Epoch 22 learning_rate : 2.8549663646838717e-06
[Epoch:22] 1/22	    BatchTime 7.4353    DataTime 6.1241    Loss_Classification 2.4645e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:22] 2/22	    BatchTime 1.1366    DataTime 0.0001    Loss_Classification 2.1849e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:22] 3/22	    BatchTime 1.1364    DataTime 0.0002    Loss_Classification 2.3806e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.844
[Epoch:22] 4/22	    BatchTime 1.1603    DataTime 0.0001    Loss_Classification 2.5741e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.281
[Epoch:22] 5/22	    BatchTime 1.1688    DataTime 0.0002    Loss_Classification 2.6642e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.672
[Epoch:22] 6/22	    BatchTime 1.1912    DataTime 0.0002    Loss_Classification 2.7134e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.086
[Epoch:22] 7/22	    BatchTime 1.1822    DataTime 0.0001    Loss_Classification 1.8063e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.188
[Epoch:22] 8/22	    BatchTime 1.1812    DataTime 0.0007    Loss_Classification 2.0541e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 90.234
[Epoch:22] 9/22	    BatchTime 1.1950    DataTime 0.0004    Loss_Classification 1.9857e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:22] 10/22	    BatchTime 1.2772    DataTime 0.0004    Loss_Classification 2.4047e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.062
[Epoch:22] 11/22	    BatchTime 1.2324    DataTime 0.0002    Loss_Classification 2.5147e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.062
[Epoch:22] 12/22	    BatchTime 1.2201    DataTime 0.0002    Loss_Classification 2.2606e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:22] 13/22	    BatchTime 1.1957    DataTime 0.0002    Loss_Classification 2.4835e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:22] 14/22	    BatchTime 1.2371    DataTime 0.0000    Loss_Classification 2.5594e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.672
[Epoch:22] 15/22	    BatchTime 1.2302    DataTime 0.0001    Loss_Classification 2.2707e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 90.234
[Epoch:22] 16/22	    BatchTime 1.2187    DataTime 0.0001    Loss_Classification 2.6659e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.672
[Epoch:22] 17/22	    BatchTime 1.2128    DataTime 0.0002    Loss_Classification 2.7512e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.695
[Epoch:22] 18/22	    BatchTime 1.2164    DataTime 0.0002    Loss_Classification 2.5713e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.477
[Epoch:22] 19/22	    BatchTime 1.2509    DataTime 0.0002    Loss_Classification 2.4136e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.062
[Epoch:22] 20/22	    BatchTime 1.2187    DataTime 0.0002    Loss_Classification 2.5416e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.258
[Epoch:22] 21/22	    BatchTime 1.1986    DataTime 0.0002    Loss_Classification 2.0307e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.625
[Epoch:22] 22/22	    BatchTime 1.2188    DataTime 0.0001    Loss_Classification 2.3218e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:22]  32.71    Loss_Classification 2.3917e+00    val_Loss_Classification 2.4519e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.660    val_acc@1 87.310    acc@5 89.524    val_acc@5 89.254
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00022-val_Loss_Classification_2.4519-val_Loss_Distance_0.0000.pth

Epoch 23 learning_rate : 2.4889122713851393e-06
[Epoch:23] 1/22	    BatchTime 7.3655    DataTime 6.0909    Loss_Classification 2.0045e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:23] 2/22	    BatchTime 1.1599    DataTime 0.0002    Loss_Classification 2.5837e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.477
[Epoch:23] 3/22	    BatchTime 1.1346    DataTime 0.0002    Loss_Classification 1.9141e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:23] 4/22	    BatchTime 1.1672    DataTime 0.0002    Loss_Classification 2.3883e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:23] 5/22	    BatchTime 1.1711    DataTime 0.0002    Loss_Classification 2.4280e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:23] 6/22	    BatchTime 1.1763    DataTime 0.0002    Loss_Classification 2.3681e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.258
[Epoch:23] 7/22	    BatchTime 1.2003    DataTime 0.0001    Loss_Classification 2.7320e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 87.891
[Epoch:23] 8/22	    BatchTime 1.1798    DataTime 0.0002    Loss_Classification 2.6093e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.258
[Epoch:23] 9/22	    BatchTime 1.2029    DataTime 0.0002    Loss_Classification 2.3000e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:23] 10/22	    BatchTime 1.1983    DataTime 0.0003    Loss_Classification 2.6478e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 88.867
[Epoch:23] 11/22	    BatchTime 1.2318    DataTime 0.0002    Loss_Classification 1.9997e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:23] 12/22	    BatchTime 1.2691    DataTime 0.0001    Loss_Classification 2.1716e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:23] 13/22	    BatchTime 1.2255    DataTime 0.0002    Loss_Classification 1.6568e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.188
[Epoch:23] 14/22	    BatchTime 1.2226    DataTime 0.0001    Loss_Classification 2.4306e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:23] 15/22	    BatchTime 1.2001    DataTime 0.0001    Loss_Classification 2.4358e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.062
[Epoch:23] 16/22	    BatchTime 1.2572    DataTime 0.0002    Loss_Classification 1.9800e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:23] 17/22	    BatchTime 1.2428    DataTime 0.0002    Loss_Classification 2.4427e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.062
[Epoch:23] 18/22	    BatchTime 1.2175    DataTime 0.0000    Loss_Classification 2.8699e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.305
[Epoch:23] 19/22	    BatchTime 1.2114    DataTime 0.0001    Loss_Classification 2.2977e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:23] 20/22	    BatchTime 1.2356    DataTime 0.0002    Loss_Classification 2.3479e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 89.844
[Epoch:23] 21/22	    BatchTime 1.2499    DataTime 0.0001    Loss_Classification 2.1995e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:23] 22/22	    BatchTime 1.2357    DataTime 0.0002    Loss_Classification 2.2799e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:23]  32.76    Loss_Classification 2.3222e+00    val_Loss_Classification 2.5569e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.308    val_acc@1 87.098    acc@5 89.817    val_acc@5 88.759
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00023-val_Loss_Classification_2.5569-val_Loss_Distance_0.0000.pth

Epoch 24 learning_rate : 2.155848285351727e-06
[Epoch:24] 1/22	    BatchTime 7.1363    DataTime 5.6899    Loss_Classification 1.9318e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.602
[Epoch:24] 2/22	    BatchTime 1.1347    DataTime 0.0002    Loss_Classification 3.1937e+00    Loss_Distance 0.0000e+00    acc@1 83.984    acc@5 86.133
[Epoch:24] 3/22	    BatchTime 1.1391    DataTime 0.0002    Loss_Classification 2.4835e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.867
[Epoch:24] 4/22	    BatchTime 1.1826    DataTime 0.0002    Loss_Classification 1.9587e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:24] 5/22	    BatchTime 1.1872    DataTime 0.0009    Loss_Classification 2.6041e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.477
[Epoch:24] 6/22	    BatchTime 1.1870    DataTime 0.0003    Loss_Classification 2.2405e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:24] 7/22	    BatchTime 1.1922    DataTime 0.0001    Loss_Classification 2.4043e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.648
[Epoch:24] 8/22	    BatchTime 1.1888    DataTime 0.0002    Loss_Classification 2.0615e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.625
[Epoch:24] 9/22	    BatchTime 1.2625    DataTime 0.0003    Loss_Classification 2.2318e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:24] 10/22	    BatchTime 1.2785    DataTime 0.0000    Loss_Classification 2.1997e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:24] 11/22	    BatchTime 1.2195    DataTime 0.0002    Loss_Classification 2.1307e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:24] 12/22	    BatchTime 1.2024    DataTime 0.0002    Loss_Classification 1.9718e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:24] 13/22	    BatchTime 1.1888    DataTime 0.0002    Loss_Classification 2.8355e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.891
[Epoch:24] 14/22	    BatchTime 1.2316    DataTime 0.0002    Loss_Classification 2.7406e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 88.281
[Epoch:24] 15/22	    BatchTime 1.3275    DataTime 0.0002    Loss_Classification 2.5092e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.844
[Epoch:24] 16/22	    BatchTime 1.2607    DataTime 0.0002    Loss_Classification 1.7872e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 92.383
[Epoch:24] 17/22	    BatchTime 1.2157    DataTime 0.0001    Loss_Classification 2.1143e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:24] 18/22	    BatchTime 1.2073    DataTime 0.0002    Loss_Classification 2.0018e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 91.211
[Epoch:24] 19/22	    BatchTime 1.2379    DataTime 0.0002    Loss_Classification 2.4069e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.648
[Epoch:24] 20/22	    BatchTime 1.2332    DataTime 0.0001    Loss_Classification 2.3137e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:24] 21/22	    BatchTime 1.2311    DataTime 0.0003    Loss_Classification 1.7215e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.188
[Epoch:24] 22/22	    BatchTime 1.2499    DataTime 0.0001    Loss_Classification 2.5154e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.477
[Epoch:24]  32.69    Loss_Classification 2.2890e+00    val_Loss_Classification 2.4202e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.157    val_acc@1 87.663    acc@5 90.012    val_acc@5 89.678
val_Loss_Classification improve from 2.445129118103912 to 2.420207574621196
Save model to ./models/ep00024-val_Loss_Classification_2.4202-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00024-val_Loss_Classification_2.4202-val_Loss_Distance_0.0000.pth

Epoch 25 learning_rate : 1.8594235253127369e-06
[Epoch:25] 1/22	    BatchTime 7.3020    DataTime 6.0132    Loss_Classification 2.3239e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:25] 2/22	    BatchTime 1.1357    DataTime 0.0002    Loss_Classification 2.1703e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.016
[Epoch:25] 3/22	    BatchTime 1.1502    DataTime 0.0002    Loss_Classification 2.1199e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.016
[Epoch:25] 4/22	    BatchTime 1.1535    DataTime 0.0002    Loss_Classification 2.5243e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:25] 5/22	    BatchTime 1.1569    DataTime 0.0002    Loss_Classification 2.0510e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:25] 6/22	    BatchTime 1.1858    DataTime 0.0003    Loss_Classification 2.4922e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.477
[Epoch:25] 7/22	    BatchTime 1.1939    DataTime 0.0002    Loss_Classification 2.6223e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.086
[Epoch:25] 8/22	    BatchTime 1.1988    DataTime 0.0002    Loss_Classification 2.4383e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.258
[Epoch:25] 9/22	    BatchTime 1.1842    DataTime 0.0001    Loss_Classification 2.5194e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.648
[Epoch:25] 10/22	    BatchTime 1.2052    DataTime 0.0003    Loss_Classification 1.5319e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 93.164
[Epoch:25] 11/22	    BatchTime 1.2277    DataTime 0.0000    Loss_Classification 2.2853e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.844
[Epoch:25] 12/22	    BatchTime 1.2230    DataTime 0.0001    Loss_Classification 2.3849e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:25] 13/22	    BatchTime 1.2023    DataTime 0.0001    Loss_Classification 2.1767e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:25] 14/22	    BatchTime 1.2073    DataTime 0.0001    Loss_Classification 2.1991e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:25] 15/22	    BatchTime 1.2252    DataTime 0.0002    Loss_Classification 2.3985e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:25] 16/22	    BatchTime 1.2718    DataTime 0.0001    Loss_Classification 2.2258e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:25] 17/22	    BatchTime 1.2416    DataTime 0.0001    Loss_Classification 2.4138e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.062
[Epoch:25] 18/22	    BatchTime 1.2407    DataTime 0.0001    Loss_Classification 2.7401e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.867
[Epoch:25] 19/22	    BatchTime 1.2024    DataTime 0.0002    Loss_Classification 2.2331e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:25] 20/22	    BatchTime 1.2355    DataTime 0.0002    Loss_Classification 2.1569e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:25] 21/22	    BatchTime 1.2207    DataTime 0.0001    Loss_Classification 3.6285e+00    Loss_Distance 0.0000e+00    acc@1 83.594    acc@5 85.352
[Epoch:25] 22/22	    BatchTime 1.2494    DataTime 0.0004    Loss_Classification 2.7465e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.477
[Epoch:25]  32.61    Loss_Classification 2.3810e+00    val_Loss_Classification 2.3706e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.820    val_acc@1 88.052    acc@5 89.737    val_acc@5 89.396
val_Loss_Classification improve from 2.420207574621196 to 2.3706111568324175
Save model to ./models/ep00025-val_Loss_Classification_2.3706-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00025-val_Loss_Classification_2.3706-val_Loss_Distance_0.0000.pth

Epoch 26 learning_rate : 1.6028856829700258e-06
[Epoch:26] 1/22	    BatchTime 7.3081    DataTime 5.9283    Loss_Classification 1.8425e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:26] 2/22	    BatchTime 1.1476    DataTime 0.0002    Loss_Classification 2.0431e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.016
[Epoch:26] 3/22	    BatchTime 1.1372    DataTime 0.0002    Loss_Classification 2.5235e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:26] 4/22	    BatchTime 1.1480    DataTime 0.0001    Loss_Classification 2.3598e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 90.039
[Epoch:26] 5/22	    BatchTime 1.1660    DataTime 0.0001    Loss_Classification 2.2097e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:26] 6/22	    BatchTime 1.1855    DataTime 0.0002    Loss_Classification 2.1507e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:26] 7/22	    BatchTime 1.1829    DataTime 0.0002    Loss_Classification 2.5085e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.062
[Epoch:26] 8/22	    BatchTime 1.2115    DataTime 0.0001    Loss_Classification 2.3695e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.453
[Epoch:26] 9/22	    BatchTime 1.2146    DataTime 0.0004    Loss_Classification 2.4541e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.844
[Epoch:26] 10/22	    BatchTime 1.2066    DataTime 0.0002    Loss_Classification 2.3263e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 90.039
[Epoch:26] 11/22	    BatchTime 1.1981    DataTime 0.0002    Loss_Classification 2.4599e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.258
[Epoch:26] 12/22	    BatchTime 1.1989    DataTime 0.0001    Loss_Classification 2.2862e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.234
[Epoch:26] 13/22	    BatchTime 1.2341    DataTime 0.0001    Loss_Classification 2.5466e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.062
[Epoch:26] 14/22	    BatchTime 1.2357    DataTime 0.0002    Loss_Classification 2.2361e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:26] 15/22	    BatchTime 1.2027    DataTime 0.0002    Loss_Classification 2.4465e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.477
[Epoch:26] 16/22	    BatchTime 1.2105    DataTime 0.0002    Loss_Classification 2.3192e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:26] 17/22	    BatchTime 1.2315    DataTime 0.0003    Loss_Classification 1.8710e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:26] 18/22	    BatchTime 1.2230    DataTime 0.0001    Loss_Classification 2.6318e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.672
[Epoch:26] 19/22	    BatchTime 1.2134    DataTime 0.0002    Loss_Classification 1.9151e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.797
[Epoch:26] 20/22	    BatchTime 1.3507    DataTime 0.0002    Loss_Classification 2.3847e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.258
[Epoch:26] 21/22	    BatchTime 1.2709    DataTime 0.0000    Loss_Classification 2.3111e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:26] 22/22	    BatchTime 1.2233    DataTime 0.0002    Loss_Classification 2.4840e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.867
[Epoch:26]  32.70    Loss_Classification 2.3036e+00    val_Loss_Classification 2.4642e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.077    val_acc@1 87.275    acc@5 89.906    val_acc@5 89.183
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00026-val_Loss_Classification_2.4642-val_Loss_Distance_0.0000.pth

Epoch 27 learning_rate : 1.3890454406082957e-06
[Epoch:27] 1/22	    BatchTime 7.1616    DataTime 5.8235    Loss_Classification 2.6127e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.477
[Epoch:27] 2/22	    BatchTime 1.1350    DataTime 0.0002    Loss_Classification 1.8575e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.383
[Epoch:27] 3/22	    BatchTime 1.1371    DataTime 0.0002    Loss_Classification 2.3392e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.234
[Epoch:27] 4/22	    BatchTime 1.1904    DataTime 0.0002    Loss_Classification 2.5713e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.672
[Epoch:27] 5/22	    BatchTime 1.1781    DataTime 0.0002    Loss_Classification 1.7703e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.383
[Epoch:27] 6/22	    BatchTime 1.1861    DataTime 0.0002    Loss_Classification 2.7684e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.281
[Epoch:27] 7/22	    BatchTime 1.1912    DataTime 0.0001    Loss_Classification 2.3952e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.039
[Epoch:27] 8/22	    BatchTime 1.1863    DataTime 0.0002    Loss_Classification 2.7683e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.477
[Epoch:27] 9/22	    BatchTime 1.2024    DataTime 0.0002    Loss_Classification 2.7158e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.477
[Epoch:27] 10/22	    BatchTime 1.2373    DataTime 0.0000    Loss_Classification 1.8694e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:27] 11/22	    BatchTime 1.2064    DataTime 0.0004    Loss_Classification 2.6749e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.672
[Epoch:27] 12/22	    BatchTime 1.1951    DataTime 0.0003    Loss_Classification 2.8641e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 86.914
[Epoch:27] 13/22	    BatchTime 1.2005    DataTime 0.0002    Loss_Classification 2.3599e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.453
[Epoch:27] 14/22	    BatchTime 1.1963    DataTime 0.0005    Loss_Classification 2.4498e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.258
[Epoch:27] 15/22	    BatchTime 1.2982    DataTime 0.0002    Loss_Classification 2.2491e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.234
[Epoch:27] 16/22	    BatchTime 1.2739    DataTime 0.0002    Loss_Classification 2.0942e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.430
[Epoch:27] 17/22	    BatchTime 1.2365    DataTime 0.0002    Loss_Classification 2.2634e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.625
[Epoch:27] 18/22	    BatchTime 1.2136    DataTime 0.0002    Loss_Classification 1.9637e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:27] 19/22	    BatchTime 1.2172    DataTime 0.0002    Loss_Classification 1.9952e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:27] 20/22	    BatchTime 1.2403    DataTime 0.0002    Loss_Classification 2.1559e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:27] 21/22	    BatchTime 1.2232    DataTime 0.0003    Loss_Classification 2.3915e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.648
[Epoch:27] 22/22	    BatchTime 1.2338    DataTime 0.0002    Loss_Classification 2.0298e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:27]  32.54    Loss_Classification 2.3255e+00    val_Loss_Classification 2.4428e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 87.935    val_acc@1 87.663    acc@5 89.924    val_acc@5 89.431
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00027-val_Loss_Classification_2.4428-val_Loss_Distance_0.0000.pth

Epoch 28 learning_rate : 1.220245676671809e-06
[Epoch:28] 1/22	    BatchTime 7.3514    DataTime 6.0792    Loss_Classification 2.0975e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:28] 2/22	    BatchTime 1.1489    DataTime 0.0002    Loss_Classification 2.0373e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.406
[Epoch:28] 3/22	    BatchTime 1.1354    DataTime 0.0002    Loss_Classification 2.0950e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:28] 4/22	    BatchTime 1.1751    DataTime 0.0002    Loss_Classification 2.1166e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 90.625
[Epoch:28] 5/22	    BatchTime 1.1739    DataTime 0.0002    Loss_Classification 2.1867e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.625
[Epoch:28] 6/22	    BatchTime 1.1947    DataTime 0.0002    Loss_Classification 2.1370e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.648
[Epoch:28] 7/22	    BatchTime 1.2008    DataTime 0.0002    Loss_Classification 3.0050e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.109
[Epoch:28] 8/22	    BatchTime 1.1892    DataTime 0.0000    Loss_Classification 2.2189e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:28] 9/22	    BatchTime 1.2604    DataTime 0.0002    Loss_Classification 2.2742e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.453
[Epoch:28] 10/22	    BatchTime 1.2263    DataTime 0.0001    Loss_Classification 2.5182e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.062
[Epoch:28] 11/22	    BatchTime 1.2117    DataTime 0.0002    Loss_Classification 2.2645e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.039
[Epoch:28] 12/22	    BatchTime 1.2161    DataTime 0.0003    Loss_Classification 1.8520e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:28] 13/22	    BatchTime 1.2281    DataTime 0.0002    Loss_Classification 2.3397e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:28] 14/22	    BatchTime 1.2075    DataTime 0.0002    Loss_Classification 2.3680e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.062
[Epoch:28] 15/22	    BatchTime 1.2381    DataTime 0.0002    Loss_Classification 2.4533e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.477
[Epoch:28] 16/22	    BatchTime 1.2256    DataTime 0.0002    Loss_Classification 1.8761e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.016
[Epoch:28] 17/22	    BatchTime 1.2280    DataTime 0.0001    Loss_Classification 2.7102e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.672
[Epoch:28] 18/22	    BatchTime 1.2436    DataTime 0.0001    Loss_Classification 1.9870e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:28] 19/22	    BatchTime 1.2943    DataTime 0.0002    Loss_Classification 2.2623e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.234
[Epoch:28] 20/22	    BatchTime 1.2600    DataTime 0.0001    Loss_Classification 2.2745e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.648
[Epoch:28] 21/22	    BatchTime 1.2328    DataTime 0.0001    Loss_Classification 1.9386e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:28] 22/22	    BatchTime 1.2331    DataTime 0.0002    Loss_Classification 1.8554e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:28]  32.88    Loss_Classification 2.2213e+00    val_Loss_Classification 2.4272e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.184    val_acc@1 87.946    acc@5 90.110    val_acc@5 89.537
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00028-val_Loss_Classification_2.4272-val_Loss_Distance_0.0000.pth

Epoch 29 learning_rate : 1.0983357966978744e-06
[Epoch:29] 1/22	    BatchTime 7.1952    DataTime 5.9027    Loss_Classification 2.2240e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:29] 2/22	    BatchTime 1.1497    DataTime 0.0006    Loss_Classification 1.7000e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.383
[Epoch:29] 3/22	    BatchTime 1.1374    DataTime 0.0002    Loss_Classification 2.6501e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:29] 4/22	    BatchTime 1.1751    DataTime 0.0002    Loss_Classification 2.2484e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.062
[Epoch:29] 5/22	    BatchTime 1.1925    DataTime 0.0001    Loss_Classification 2.2133e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.625
[Epoch:29] 6/22	    BatchTime 1.1840    DataTime 0.0002    Loss_Classification 2.2762e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:29] 7/22	    BatchTime 1.1922    DataTime 0.0002    Loss_Classification 2.1760e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:29] 8/22	    BatchTime 1.2127    DataTime 0.0001    Loss_Classification 3.1223e+00    Loss_Distance 0.0000e+00    acc@1 84.766    acc@5 87.305
[Epoch:29] 9/22	    BatchTime 1.1986    DataTime 0.0002    Loss_Classification 2.1227e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:29] 10/22	    BatchTime 1.2195    DataTime 0.0001    Loss_Classification 2.3570e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:29] 11/22	    BatchTime 1.2110    DataTime 0.0001    Loss_Classification 2.2489e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:29] 12/22	    BatchTime 1.2183    DataTime 0.0001    Loss_Classification 1.9513e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.992
[Epoch:29] 13/22	    BatchTime 1.2163    DataTime 0.0001    Loss_Classification 2.3652e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:29] 14/22	    BatchTime 1.2258    DataTime 0.0001    Loss_Classification 2.4481e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.039
[Epoch:29] 15/22	    BatchTime 1.2025    DataTime 0.0001    Loss_Classification 2.3945e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.430
[Epoch:29] 16/22	    BatchTime 1.2524    DataTime 0.0001    Loss_Classification 1.6582e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.578
[Epoch:29] 17/22	    BatchTime 1.2598    DataTime 0.0001    Loss_Classification 2.7056e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:29] 18/22	    BatchTime 1.2198    DataTime 0.0003    Loss_Classification 2.5246e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.281
[Epoch:29] 19/22	    BatchTime 1.2116    DataTime 0.0001    Loss_Classification 2.3121e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.453
[Epoch:29] 20/22	    BatchTime 1.2878    DataTime 0.0001    Loss_Classification 2.2904e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:29] 21/22	    BatchTime 1.2434    DataTime 0.0002    Loss_Classification 1.7681e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.992
[Epoch:29] 22/22	    BatchTime 1.2197    DataTime 0.0000    Loss_Classification 2.1097e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 91.016
[Epoch:29]  32.63    Loss_Classification 2.2667e+00    val_Loss_Classification 2.3720e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.006    val_acc@1 87.770    acc@5 90.101    val_acc@5 89.148
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00029-val_Loss_Classification_2.3720-val_Loss_Distance_0.0000.pth

Epoch 30 learning_rate : 1.0246514708427697e-06
[Epoch:30] 1/22	    BatchTime 7.1759    DataTime 5.8465    Loss_Classification 2.2843e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:30] 2/22	    BatchTime 1.1352    DataTime 0.0002    Loss_Classification 2.7188e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.477
[Epoch:30] 3/22	    BatchTime 1.1610    DataTime 0.0001    Loss_Classification 2.5177e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 88.867
[Epoch:30] 4/22	    BatchTime 1.1771    DataTime 0.0002    Loss_Classification 2.3416e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.453
[Epoch:30] 5/22	    BatchTime 1.1740    DataTime 0.0002    Loss_Classification 1.9200e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:30] 6/22	    BatchTime 1.2034    DataTime 0.0001    Loss_Classification 2.1916e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.648
[Epoch:30] 7/22	    BatchTime 1.2003    DataTime 0.0002    Loss_Classification 2.0602e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:30] 8/22	    BatchTime 1.2075    DataTime 0.0001    Loss_Classification 2.5370e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.281
[Epoch:30] 9/22	    BatchTime 1.1836    DataTime 0.0002    Loss_Classification 2.5297e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.086
[Epoch:30] 10/22	    BatchTime 1.2113    DataTime 0.0002    Loss_Classification 2.1915e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:30] 11/22	    BatchTime 1.2363    DataTime 0.0002    Loss_Classification 2.1812e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.039
[Epoch:30] 12/22	    BatchTime 1.2160    DataTime 0.0002    Loss_Classification 1.8804e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:30] 13/22	    BatchTime 1.2206    DataTime 0.0001    Loss_Classification 2.1178e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.820
[Epoch:30] 14/22	    BatchTime 1.2494    DataTime 0.0001    Loss_Classification 2.0156e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:30] 15/22	    BatchTime 1.2297    DataTime 0.0003    Loss_Classification 2.6348e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.648
[Epoch:30] 16/22	    BatchTime 1.2226    DataTime 0.0002    Loss_Classification 1.9761e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:30] 17/22	    BatchTime 1.1952    DataTime 0.0003    Loss_Classification 2.2135e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.430
[Epoch:30] 18/22	    BatchTime 1.2706    DataTime 0.0000    Loss_Classification 2.0590e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:30] 19/22	    BatchTime 1.2300    DataTime 0.0003    Loss_Classification 2.4524e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.453
[Epoch:30] 20/22	    BatchTime 1.2159    DataTime 0.0002    Loss_Classification 2.4439e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.258
[Epoch:30] 21/22	    BatchTime 1.2852    DataTime 0.0002    Loss_Classification 2.0334e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.016
[Epoch:30] 22/22	    BatchTime 1.2796    DataTime 0.0002    Loss_Classification 2.5344e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.477
[Epoch:30]  32.68    Loss_Classification 2.2652e+00    val_Loss_Classification 2.4520e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.166    val_acc@1 87.840    acc@5 89.941    val_acc@5 89.290
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00030-val_Loss_Classification_2.4520-val_Loss_Distance_0.0000.pth

Epoch 31 learning_rate : 1e-05
[Epoch:31] 1/22	    BatchTime 7.4241    DataTime 6.1523    Loss_Classification 1.8003e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 92.383
[Epoch:31] 2/22	    BatchTime 1.1348    DataTime 0.0002    Loss_Classification 2.3611e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:31] 3/22	    BatchTime 1.1366    DataTime 0.0002    Loss_Classification 2.0532e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.820
[Epoch:31] 4/22	    BatchTime 1.1536    DataTime 0.0002    Loss_Classification 2.7108e+00    Loss_Distance 0.0000e+00    acc@1 85.156    acc@5 87.891
[Epoch:31] 5/22	    BatchTime 1.1765    DataTime 0.0002    Loss_Classification 1.9999e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:31] 6/22	    BatchTime 1.2048    DataTime 0.0002    Loss_Classification 2.3862e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.477
[Epoch:31] 7/22	    BatchTime 1.1869    DataTime 0.0002    Loss_Classification 1.5088e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.383
[Epoch:31] 8/22	    BatchTime 1.2411    DataTime 0.0003    Loss_Classification 1.9804e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:31] 9/22	    BatchTime 1.2206    DataTime 0.0002    Loss_Classification 2.5008e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.062
[Epoch:31] 10/22	    BatchTime 1.2123    DataTime 0.0002    Loss_Classification 2.3995e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:31] 11/22	    BatchTime 1.2042    DataTime 0.0003    Loss_Classification 2.8615e+00    Loss_Distance 0.0000e+00    acc@1 84.375    acc@5 86.133
[Epoch:31] 12/22	    BatchTime 1.1925    DataTime 0.0002    Loss_Classification 2.1091e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.453
[Epoch:31] 13/22	    BatchTime 1.1962    DataTime 0.0002    Loss_Classification 2.0112e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.016
[Epoch:31] 14/22	    BatchTime 1.2446    DataTime 0.0000    Loss_Classification 2.5296e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 88.281
[Epoch:31] 15/22	    BatchTime 1.2286    DataTime 0.0002    Loss_Classification 1.6684e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 92.773
[Epoch:31] 16/22	    BatchTime 1.2343    DataTime 0.0001    Loss_Classification 2.3888e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:31] 17/22	    BatchTime 1.2010    DataTime 0.0001    Loss_Classification 2.6999e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.086
[Epoch:31] 18/22	    BatchTime 1.2106    DataTime 0.0001    Loss_Classification 2.3098e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.844
[Epoch:31] 19/22	    BatchTime 1.2596    DataTime 0.0002    Loss_Classification 2.5998e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:31] 20/22	    BatchTime 1.2349    DataTime 0.0002    Loss_Classification 1.5841e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 93.359
[Epoch:31] 21/22	    BatchTime 1.2256    DataTime 0.0002    Loss_Classification 1.6666e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 92.383
[Epoch:31] 22/22	    BatchTime 1.2166    DataTime 0.0002    Loss_Classification 2.3756e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.258
[Epoch:31]  32.74    Loss_Classification 2.2048e+00    val_Loss_Classification 2.5014e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.228    val_acc@1 87.381    acc@5 90.083    val_acc@5 89.077
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00031-val_Loss_Classification_2.5014-val_Loss_Distance_0.0000.pth

Epoch 32 learning_rate : 9.97534852915723e-06
[Epoch:32] 1/22	    BatchTime 6.9769    DataTime 5.6423    Loss_Classification 2.0401e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 91.211
[Epoch:32] 2/22	    BatchTime 1.1510    DataTime 0.0003    Loss_Classification 2.0184e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 91.406
[Epoch:32] 3/22	    BatchTime 1.1399    DataTime 0.0002    Loss_Classification 2.4903e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.086
[Epoch:32] 4/22	    BatchTime 1.1835    DataTime 0.0002    Loss_Classification 1.9566e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 91.406
[Epoch:32] 5/22	    BatchTime 1.1751    DataTime 0.0004    Loss_Classification 2.5410e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.672
[Epoch:32] 6/22	    BatchTime 1.1922    DataTime 0.0003    Loss_Classification 2.5187e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.281
[Epoch:32] 7/22	    BatchTime 1.2072    DataTime 0.0004    Loss_Classification 2.6019e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 88.867
[Epoch:32] 8/22	    BatchTime 1.2027    DataTime 0.0002    Loss_Classification 2.5616e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 87.695
[Epoch:32] 9/22	    BatchTime 1.2192    DataTime 0.0002    Loss_Classification 2.4975e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.062
[Epoch:32] 10/22	    BatchTime 1.2186    DataTime 0.0002    Loss_Classification 2.6912e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 88.477
[Epoch:32] 11/22	    BatchTime 1.2011    DataTime 0.0002    Loss_Classification 2.3776e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.844
[Epoch:32] 12/22	    BatchTime 1.2684    DataTime 0.0003    Loss_Classification 1.8886e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:32] 13/22	    BatchTime 1.2328    DataTime 0.0002    Loss_Classification 2.4951e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:32] 14/22	    BatchTime 1.2391    DataTime 0.0002    Loss_Classification 1.6028e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 92.773
[Epoch:32] 15/22	    BatchTime 1.2001    DataTime 0.0002    Loss_Classification 1.8861e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:32] 16/22	    BatchTime 1.2560    DataTime 0.0002    Loss_Classification 1.8685e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.406
[Epoch:32] 17/22	    BatchTime 1.2305    DataTime 0.0004    Loss_Classification 2.5190e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.453
[Epoch:32] 18/22	    BatchTime 1.2119    DataTime 0.0000    Loss_Classification 2.2739e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:32] 19/22	    BatchTime 1.2363    DataTime 0.0003    Loss_Classification 1.7898e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.992
[Epoch:32] 20/22	    BatchTime 1.2321    DataTime 0.0002    Loss_Classification 1.6260e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 93.359
[Epoch:32] 21/22	    BatchTime 1.2574    DataTime 0.0002    Loss_Classification 2.2545e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.844
[Epoch:32] 22/22	    BatchTime 1.2302    DataTime 0.0002    Loss_Classification 1.8790e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.625
[Epoch:32]  32.46    Loss_Classification 2.1990e+00    val_Loss_Classification 2.3278e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.210    val_acc@1 88.300    acc@5 90.243    val_acc@5 89.855
val_Loss_Classification improve from 2.3706111568324175 to 2.3277687903384345
Save model to ./models/ep00032-val_Loss_Classification_2.3278-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00032-val_Loss_Classification_2.3278-val_Loss_Distance_0.0000.pth

Epoch 33 learning_rate : 9.901664203302126e-06
[Epoch:33] 1/22	    BatchTime 6.9959    DataTime 5.6928    Loss_Classification 2.9244e+00    Loss_Distance 0.0000e+00    acc@1 85.742    acc@5 86.719
[Epoch:33] 2/22	    BatchTime 1.1487    DataTime 0.0002    Loss_Classification 1.9203e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:33] 3/22	    BatchTime 1.1386    DataTime 0.0003    Loss_Classification 1.9209e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 91.797
[Epoch:33] 4/22	    BatchTime 1.1793    DataTime 0.0002    Loss_Classification 2.4888e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:33] 5/22	    BatchTime 1.1768    DataTime 0.0002    Loss_Classification 2.5245e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.062
[Epoch:33] 6/22	    BatchTime 1.1839    DataTime 0.0002    Loss_Classification 2.2585e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:33] 7/22	    BatchTime 1.2018    DataTime 0.0001    Loss_Classification 2.6060e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.867
[Epoch:33] 8/22	    BatchTime 1.1998    DataTime 0.0001    Loss_Classification 2.5448e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.672
[Epoch:33] 9/22	    BatchTime 1.1868    DataTime 0.0003    Loss_Classification 2.8377e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.258
[Epoch:33] 10/22	    BatchTime 1.1906    DataTime 0.0001    Loss_Classification 1.8310e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:33] 11/22	    BatchTime 1.2050    DataTime 0.0001    Loss_Classification 2.6859e+00    Loss_Distance 0.0000e+00    acc@1 85.547    acc@5 87.695
[Epoch:33] 12/22	    BatchTime 1.2834    DataTime 0.0002    Loss_Classification 2.2341e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:33] 13/22	    BatchTime 1.2304    DataTime 0.0002    Loss_Classification 2.4580e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.062
[Epoch:33] 14/22	    BatchTime 1.2104    DataTime 0.0002    Loss_Classification 1.9944e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:33] 15/22	    BatchTime 1.1980    DataTime 0.0002    Loss_Classification 1.7658e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 92.383
[Epoch:33] 16/22	    BatchTime 1.2549    DataTime 0.0001    Loss_Classification 1.9029e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.406
[Epoch:33] 17/22	    BatchTime 1.2329    DataTime 0.0002    Loss_Classification 1.9959e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:33] 18/22	    BatchTime 1.2055    DataTime 0.0001    Loss_Classification 2.2216e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:33] 19/22	    BatchTime 1.2420    DataTime 0.0001    Loss_Classification 2.6070e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.672
[Epoch:33] 20/22	    BatchTime 1.2201    DataTime 0.0002    Loss_Classification 2.0184e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:33] 21/22	    BatchTime 1.2631    DataTime 0.0001    Loss_Classification 2.3966e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.039
[Epoch:33] 22/22	    BatchTime 1.2726    DataTime 0.0001    Loss_Classification 1.7774e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:33]  32.42    Loss_Classification 2.2689e+00    val_Loss_Classification 2.4031e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.210    val_acc@1 88.264    acc@5 90.012    val_acc@5 89.466
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00033-val_Loss_Classification_2.4031-val_Loss_Distance_0.0000.pth

Epoch 34 learning_rate : 9.779754323328192e-06
[Epoch:34] 1/22	    BatchTime 7.2653    DataTime 5.8363    Loss_Classification 2.0754e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.016
[Epoch:34] 2/22	    BatchTime 1.1342    DataTime 0.0002    Loss_Classification 2.4555e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.648
[Epoch:34] 3/22	    BatchTime 1.1357    DataTime 0.0002    Loss_Classification 1.7985e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:34] 4/22	    BatchTime 1.1541    DataTime 0.0001    Loss_Classification 2.1869e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.039
[Epoch:34] 5/22	    BatchTime 1.1847    DataTime 0.0002    Loss_Classification 2.0382e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:34] 6/22	    BatchTime 1.1937    DataTime 0.0001    Loss_Classification 1.8701e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:34] 7/22	    BatchTime 1.1900    DataTime 0.0001    Loss_Classification 1.9577e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:34] 8/22	    BatchTime 1.1838    DataTime 0.0001    Loss_Classification 1.8143e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.992
[Epoch:34] 9/22	    BatchTime 1.1804    DataTime 0.0002    Loss_Classification 2.3287e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:34] 10/22	    BatchTime 1.2632    DataTime 0.0002    Loss_Classification 2.3706e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.648
[Epoch:34] 11/22	    BatchTime 1.2254    DataTime 0.0002    Loss_Classification 2.0514e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.406
[Epoch:34] 12/22	    BatchTime 1.2209    DataTime 0.0002    Loss_Classification 1.8004e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.383
[Epoch:34] 13/22	    BatchTime 1.1952    DataTime 0.0002    Loss_Classification 3.3033e+00    Loss_Distance 0.0000e+00    acc@1 84.570    acc@5 86.133
[Epoch:34] 14/22	    BatchTime 1.2893    DataTime 0.0002    Loss_Classification 1.8957e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:34] 15/22	    BatchTime 1.2789    DataTime 0.0001    Loss_Classification 2.3493e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:34] 16/22	    BatchTime 1.2201    DataTime 0.0001    Loss_Classification 2.2778e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:34] 17/22	    BatchTime 1.2096    DataTime 0.0002    Loss_Classification 1.6511e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.578
[Epoch:34] 18/22	    BatchTime 1.2145    DataTime 0.0002    Loss_Classification 2.2503e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.039
[Epoch:34] 19/22	    BatchTime 1.1995    DataTime 0.0000    Loss_Classification 3.0652e+00    Loss_Distance 0.0000e+00    acc@1 83.789    acc@5 86.719
[Epoch:34] 20/22	    BatchTime 1.2461    DataTime 0.0002    Loss_Classification 2.0921e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.016
[Epoch:34] 21/22	    BatchTime 1.2406    DataTime 0.0002    Loss_Classification 2.4052e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.430
[Epoch:34] 22/22	    BatchTime 1.2205    DataTime 0.0002    Loss_Classification 2.3782e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.258
[Epoch:34]  32.65    Loss_Classification 2.2007e+00    val_Loss_Classification 2.3977e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.707    val_acc@1 87.593    acc@5 90.394    val_acc@5 89.502
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00034-val_Loss_Classification_2.3977-val_Loss_Distance_0.0000.pth

Epoch 35 learning_rate : 9.610954559391704e-06
[Epoch:35] 1/22	    BatchTime 7.3344    DataTime 6.0165    Loss_Classification 2.1686e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 90.039
[Epoch:35] 2/22	    BatchTime 1.1499    DataTime 0.0002    Loss_Classification 2.1875e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:35] 3/22	    BatchTime 1.1477    DataTime 0.0004    Loss_Classification 1.9485e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:35] 4/22	    BatchTime 1.1541    DataTime 0.0002    Loss_Classification 1.9889e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:35] 5/22	    BatchTime 1.1665    DataTime 0.0002    Loss_Classification 1.5352e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.969
[Epoch:35] 6/22	    BatchTime 1.1803    DataTime 0.0002    Loss_Classification 2.2207e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:35] 7/22	    BatchTime 1.2053    DataTime 0.0002    Loss_Classification 2.3846e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.258
[Epoch:35] 8/22	    BatchTime 1.2221    DataTime 0.0002    Loss_Classification 1.6172e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.773
[Epoch:35] 9/22	    BatchTime 1.1770    DataTime 0.0000    Loss_Classification 2.0131e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:35] 10/22	    BatchTime 1.1766    DataTime 0.0002    Loss_Classification 2.1102e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:35] 11/22	    BatchTime 1.2519    DataTime 0.0002    Loss_Classification 2.1143e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.820
[Epoch:35] 12/22	    BatchTime 1.2259    DataTime 0.0002    Loss_Classification 1.7467e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:35] 13/22	    BatchTime 1.2252    DataTime 0.0001    Loss_Classification 1.4986e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 93.359
[Epoch:35] 14/22	    BatchTime 1.2249    DataTime 0.0001    Loss_Classification 1.9486e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:35] 15/22	    BatchTime 1.1959    DataTime 0.0002    Loss_Classification 1.9330e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.602
[Epoch:35] 16/22	    BatchTime 1.2456    DataTime 0.0002    Loss_Classification 1.9220e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.016
[Epoch:35] 17/22	    BatchTime 1.2344    DataTime 0.0002    Loss_Classification 2.2385e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:35] 18/22	    BatchTime 1.2588    DataTime 0.0002    Loss_Classification 2.1814e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:35] 19/22	    BatchTime 1.2141    DataTime 0.0002    Loss_Classification 2.4910e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.062
[Epoch:35] 20/22	    BatchTime 1.2459    DataTime 0.0001    Loss_Classification 2.5938e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.281
[Epoch:35] 21/22	    BatchTime 1.2641    DataTime 0.0002    Loss_Classification 2.5367e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 88.867
[Epoch:35] 22/22	    BatchTime 1.2554    DataTime 0.0002    Loss_Classification 2.1066e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:35]  32.76    Loss_Classification 2.0675e+00    val_Loss_Classification 2.3634e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.045    val_acc@1 88.052    acc@5 90.785    val_acc@5 89.466
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00035-val_Loss_Classification_2.3634-val_Loss_Distance_0.0000.pth

Epoch 36 learning_rate : 9.397114317029975e-06
[Epoch:36] 1/22	    BatchTime 7.3654    DataTime 5.7285    Loss_Classification 1.9831e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:36] 2/22	    BatchTime 1.1346    DataTime 0.0003    Loss_Classification 2.4371e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.281
[Epoch:36] 3/22	    BatchTime 1.1364    DataTime 0.0002    Loss_Classification 1.5781e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.773
[Epoch:36] 4/22	    BatchTime 1.1795    DataTime 0.0008    Loss_Classification 2.4993e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.062
[Epoch:36] 5/22	    BatchTime 1.1713    DataTime 0.0004    Loss_Classification 2.3124e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.430
[Epoch:36] 6/22	    BatchTime 1.1822    DataTime 0.0001    Loss_Classification 1.8521e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:36] 7/22	    BatchTime 1.1869    DataTime 0.0002    Loss_Classification 2.2164e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:36] 8/22	    BatchTime 1.2017    DataTime 0.0002    Loss_Classification 1.6563e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.969
[Epoch:36] 9/22	    BatchTime 1.2189    DataTime 0.0003    Loss_Classification 1.8889e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.211
[Epoch:36] 10/22	    BatchTime 1.2177    DataTime 0.0000    Loss_Classification 1.6132e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.578
[Epoch:36] 11/22	    BatchTime 1.2500    DataTime 0.0001    Loss_Classification 2.2058e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:36] 12/22	    BatchTime 1.2168    DataTime 0.0001    Loss_Classification 2.4860e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 88.672
[Epoch:36] 13/22	    BatchTime 1.1961    DataTime 0.0003    Loss_Classification 2.1934e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:36] 14/22	    BatchTime 1.2365    DataTime 0.0001    Loss_Classification 2.4434e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:36] 15/22	    BatchTime 1.2199    DataTime 0.0001    Loss_Classification 2.1787e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.234
[Epoch:36] 16/22	    BatchTime 1.2454    DataTime 0.0002    Loss_Classification 1.9298e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:36] 17/22	    BatchTime 1.2201    DataTime 0.0001    Loss_Classification 2.2196e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:36] 18/22	    BatchTime 1.2374    DataTime 0.0001    Loss_Classification 2.0422e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:36] 19/22	    BatchTime 1.2223    DataTime 0.0001    Loss_Classification 2.2073e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.820
[Epoch:36] 20/22	    BatchTime 1.2631    DataTime 0.0001    Loss_Classification 2.7477e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.500
[Epoch:36] 21/22	    BatchTime 1.2494    DataTime 0.0002    Loss_Classification 2.2525e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.039
[Epoch:36] 22/22	    BatchTime 1.2361    DataTime 0.0002    Loss_Classification 2.6119e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.477
[Epoch:36]  32.79    Loss_Classification 2.1616e+00    val_Loss_Classification 2.3483e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.974    val_acc@1 88.052    acc@5 90.412    val_acc@5 89.396
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00036-val_Loss_Classification_2.3483-val_Loss_Distance_0.0000.pth

Epoch 37 learning_rate : 9.140576474687265e-06
[Epoch:37] 1/22	    BatchTime 7.0684    DataTime 5.6864    Loss_Classification 1.8888e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:37] 2/22	    BatchTime 1.1361    DataTime 0.0002    Loss_Classification 1.4778e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.555
[Epoch:37] 3/22	    BatchTime 1.1344    DataTime 0.0002    Loss_Classification 2.4546e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 88.672
[Epoch:37] 4/22	    BatchTime 1.1776    DataTime 0.0001    Loss_Classification 1.8039e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.602
[Epoch:37] 5/22	    BatchTime 1.1827    DataTime 0.0002    Loss_Classification 1.9124e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:37] 6/22	    BatchTime 1.2046    DataTime 0.0001    Loss_Classification 2.1950e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:37] 7/22	    BatchTime 1.1947    DataTime 0.0002    Loss_Classification 1.7740e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.797
[Epoch:37] 8/22	    BatchTime 1.2148    DataTime 0.0002    Loss_Classification 1.9737e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:37] 9/22	    BatchTime 1.2153    DataTime 0.0002    Loss_Classification 1.7366e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.602
[Epoch:37] 10/22	    BatchTime 1.1926    DataTime 0.0002    Loss_Classification 2.0606e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:37] 11/22	    BatchTime 1.1817    DataTime 0.0002    Loss_Classification 1.7189e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.383
[Epoch:37] 12/22	    BatchTime 1.3210    DataTime 0.0002    Loss_Classification 1.9296e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:37] 13/22	    BatchTime 1.2530    DataTime 0.0003    Loss_Classification 2.4881e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:37] 14/22	    BatchTime 1.2318    DataTime 0.0002    Loss_Classification 1.9640e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.992
[Epoch:37] 15/22	    BatchTime 1.2068    DataTime 0.0000    Loss_Classification 1.8504e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.406
[Epoch:37] 16/22	    BatchTime 1.2480    DataTime 0.0001    Loss_Classification 1.9868e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.406
[Epoch:37] 17/22	    BatchTime 1.2287    DataTime 0.0002    Loss_Classification 1.9530e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:37] 18/22	    BatchTime 1.2330    DataTime 0.0002    Loss_Classification 1.7764e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.992
[Epoch:37] 19/22	    BatchTime 1.2855    DataTime 0.0002    Loss_Classification 2.8861e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 87.695
[Epoch:37] 20/22	    BatchTime 1.2709    DataTime 0.0002    Loss_Classification 2.0075e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.406
[Epoch:37] 21/22	    BatchTime 1.2372    DataTime 0.0002    Loss_Classification 1.6179e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.578
[Epoch:37] 22/22	    BatchTime 1.2147    DataTime 0.0002    Loss_Classification 2.1446e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:37]  32.63    Loss_Classification 1.9819e+00    val_Loss_Classification 2.3710e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.347    val_acc@1 88.017    acc@5 91.060    val_acc@5 89.820
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00037-val_Loss_Classification_2.3710-val_Loss_Distance_0.0000.pth

Epoch 38 learning_rate : 8.844151714648274e-06
[Epoch:38] 1/22	    BatchTime 7.4922    DataTime 6.2533    Loss_Classification 1.4780e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 92.969
[Epoch:38] 2/22	    BatchTime 1.1636    DataTime 0.0002    Loss_Classification 2.0854e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:38] 3/22	    BatchTime 1.1344    DataTime 0.0002    Loss_Classification 1.8655e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 92.383
[Epoch:38] 4/22	    BatchTime 1.1530    DataTime 0.0001    Loss_Classification 2.3609e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:38] 5/22	    BatchTime 1.1763    DataTime 0.0002    Loss_Classification 2.2220e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.430
[Epoch:38] 6/22	    BatchTime 1.1932    DataTime 0.0001    Loss_Classification 1.5785e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.969
[Epoch:38] 7/22	    BatchTime 1.2076    DataTime 0.0001    Loss_Classification 1.5444e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.773
[Epoch:38] 8/22	    BatchTime 1.1998    DataTime 0.0002    Loss_Classification 2.1654e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:38] 9/22	    BatchTime 1.1840    DataTime 0.0002    Loss_Classification 1.7972e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 92.188
[Epoch:38] 10/22	    BatchTime 1.2611    DataTime 0.0002    Loss_Classification 2.4635e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.867
[Epoch:38] 11/22	    BatchTime 1.2575    DataTime 0.0001    Loss_Classification 2.2748e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:38] 12/22	    BatchTime 1.2400    DataTime 0.0002    Loss_Classification 1.9508e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.406
[Epoch:38] 13/22	    BatchTime 1.2005    DataTime 0.0003    Loss_Classification 2.4826e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 88.477
[Epoch:38] 14/22	    BatchTime 1.2038    DataTime 0.0002    Loss_Classification 2.3059e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 89.844
[Epoch:38] 15/22	    BatchTime 1.2426    DataTime 0.0005    Loss_Classification 2.3906e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.039
[Epoch:38] 16/22	    BatchTime 1.2332    DataTime 0.0002    Loss_Classification 2.2464e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.062
[Epoch:38] 17/22	    BatchTime 1.2386    DataTime 0.0002    Loss_Classification 1.9402e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.602
[Epoch:38] 18/22	    BatchTime 1.2154    DataTime 0.0002    Loss_Classification 2.0755e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 89.844
[Epoch:38] 19/22	    BatchTime 1.2330    DataTime 0.0000    Loss_Classification 2.5073e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 88.477
[Epoch:38] 20/22	    BatchTime 1.2839    DataTime 0.0001    Loss_Classification 2.4661e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:38] 21/22	    BatchTime 1.2424    DataTime 0.0001    Loss_Classification 1.9193e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:38] 22/22	    BatchTime 1.2301    DataTime 0.0001    Loss_Classification 1.6711e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 93.164
[Epoch:38]  32.99    Loss_Classification 2.0814e+00    val_Loss_Classification 2.3125e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.125    val_acc@1 88.158    acc@5 90.732    val_acc@5 89.643
val_Loss_Classification improve from 2.3277687903384345 to 2.312508453535671
Save model to ./models/ep00038-val_Loss_Classification_2.3125-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00038-val_Loss_Classification_2.3125-val_Loss_Distance_0.0000.pth

Epoch 39 learning_rate : 8.511087728614863e-06
[Epoch:39] 1/22	    BatchTime 7.2684    DataTime 5.9149    Loss_Classification 1.8742e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.820
[Epoch:39] 2/22	    BatchTime 1.1365    DataTime 0.0003    Loss_Classification 1.9165e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:39] 3/22	    BatchTime 1.1374    DataTime 0.0000    Loss_Classification 2.2325e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 89.648
[Epoch:39] 4/22	    BatchTime 1.1669    DataTime 0.0001    Loss_Classification 2.0260e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 91.016
[Epoch:39] 5/22	    BatchTime 1.1852    DataTime 0.0002    Loss_Classification 1.5514e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.773
[Epoch:39] 6/22	    BatchTime 1.1703    DataTime 0.0002    Loss_Classification 2.2340e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:39] 7/22	    BatchTime 1.1881    DataTime 0.0002    Loss_Classification 1.9454e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.211
[Epoch:39] 8/22	    BatchTime 1.1782    DataTime 0.0001    Loss_Classification 1.7730e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.820
[Epoch:39] 9/22	    BatchTime 1.2028    DataTime 0.0001    Loss_Classification 2.3272e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.258
[Epoch:39] 10/22	    BatchTime 1.2721    DataTime 0.0001    Loss_Classification 2.3514e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.258
[Epoch:39] 11/22	    BatchTime 1.2258    DataTime 0.0002    Loss_Classification 1.5881e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.773
[Epoch:39] 12/22	    BatchTime 1.2126    DataTime 0.0002    Loss_Classification 2.3601e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.453
[Epoch:39] 13/22	    BatchTime 1.1940    DataTime 0.0001    Loss_Classification 2.0002e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.016
[Epoch:39] 14/22	    BatchTime 1.2380    DataTime 0.0001    Loss_Classification 2.0288e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:39] 15/22	    BatchTime 1.2393    DataTime 0.0001    Loss_Classification 2.0229e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:39] 16/22	    BatchTime 1.2296    DataTime 0.0002    Loss_Classification 2.7180e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.477
[Epoch:39] 17/22	    BatchTime 1.1919    DataTime 0.0004    Loss_Classification 2.0550e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.820
[Epoch:39] 18/22	    BatchTime 1.1971    DataTime 0.0001    Loss_Classification 2.4018e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:39] 19/22	    BatchTime 1.3441    DataTime 0.0001    Loss_Classification 2.3993e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.453
[Epoch:39] 20/22	    BatchTime 1.2927    DataTime 0.0001    Loss_Classification 2.6781e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.086
[Epoch:39] 21/22	    BatchTime 1.2393    DataTime 0.0002    Loss_Classification 1.8936e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.406
[Epoch:39] 22/22	    BatchTime 1.2284    DataTime 0.0001    Loss_Classification 2.4348e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.867
[Epoch:39]  32.74    Loss_Classification 2.1278e+00    val_Loss_Classification 2.2343e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 88.841    val_acc@1 88.512    acc@5 90.341    val_acc@5 89.678
val_Loss_Classification improve from 2.312508453535671 to 2.2343385211989077
Save model to ./models/ep00039-val_Loss_Classification_2.2343-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00039-val_Loss_Classification_2.2343-val_Loss_Distance_0.0000.pth

Epoch 40 learning_rate : 8.14503363531613e-06
[Epoch:40] 1/22	    BatchTime 7.3983    DataTime 6.1259    Loss_Classification 2.0353e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:40] 2/22	    BatchTime 1.1347    DataTime 0.0002    Loss_Classification 2.4101e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.844
[Epoch:40] 3/22	    BatchTime 1.1505    DataTime 0.0002    Loss_Classification 1.5320e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.969
[Epoch:40] 4/22	    BatchTime 1.1489    DataTime 0.0002    Loss_Classification 2.8364e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 87.305
[Epoch:40] 5/22	    BatchTime 1.1681    DataTime 0.0002    Loss_Classification 1.7719e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:40] 6/22	    BatchTime 1.2003    DataTime 0.0002    Loss_Classification 2.0011e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:40] 7/22	    BatchTime 1.2314    DataTime 0.0002    Loss_Classification 1.5072e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.969
[Epoch:40] 8/22	    BatchTime 1.2204    DataTime 0.0000    Loss_Classification 1.8264e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.797
[Epoch:40] 9/22	    BatchTime 1.1893    DataTime 0.0002    Loss_Classification 2.0718e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:40] 10/22	    BatchTime 1.1823    DataTime 0.0002    Loss_Classification 1.6582e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.773
[Epoch:40] 11/22	    BatchTime 1.1732    DataTime 0.0001    Loss_Classification 2.1996e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.648
[Epoch:40] 12/22	    BatchTime 1.2173    DataTime 0.0002    Loss_Classification 2.1927e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.234
[Epoch:40] 13/22	    BatchTime 1.2096    DataTime 0.0002    Loss_Classification 2.1128e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.820
[Epoch:40] 14/22	    BatchTime 1.1955    DataTime 0.0002    Loss_Classification 1.8730e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:40] 15/22	    BatchTime 1.2212    DataTime 0.0002    Loss_Classification 2.2113e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:40] 16/22	    BatchTime 1.2232    DataTime 0.0001    Loss_Classification 2.0268e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 91.016
[Epoch:40] 17/22	    BatchTime 1.2186    DataTime 0.0001    Loss_Classification 1.4782e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.555
[Epoch:40] 18/22	    BatchTime 1.2382    DataTime 0.0001    Loss_Classification 2.2969e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.039
[Epoch:40] 19/22	    BatchTime 1.2433    DataTime 0.0002    Loss_Classification 2.5585e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:40] 20/22	    BatchTime 1.2182    DataTime 0.0001    Loss_Classification 1.9053e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:40] 21/22	    BatchTime 1.2105    DataTime 0.0001    Loss_Classification 2.2631e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.062
[Epoch:40] 22/22	    BatchTime 1.4080    DataTime 0.0002    Loss_Classification 2.4929e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.086
[Epoch:40]  32.80    Loss_Classification 2.0573e+00    val_Loss_Classification 2.2199e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.134    val_acc@1 88.441    acc@5 90.687    val_acc@5 89.820
val_Loss_Classification improve from 2.2343385211989077 to 2.219941882962429
Save model to ./models/ep00040-val_Loss_Classification_2.2199-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00040-val_Loss_Classification_2.2199-val_Loss_Distance_0.0000.pth

Epoch 41 learning_rate : 7.75e-06
[Epoch:41] 1/22	    BatchTime 7.3339    DataTime 6.0594    Loss_Classification 2.2147e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.844
[Epoch:41] 2/22	    BatchTime 1.1485    DataTime 0.0001    Loss_Classification 1.7272e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:41] 3/22	    BatchTime 1.1400    DataTime 0.0002    Loss_Classification 2.1585e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.430
[Epoch:41] 4/22	    BatchTime 1.1532    DataTime 0.0001    Loss_Classification 1.4929e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.164
[Epoch:41] 5/22	    BatchTime 1.1711    DataTime 0.0002    Loss_Classification 2.2754e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:41] 6/22	    BatchTime 1.1816    DataTime 0.0001    Loss_Classification 1.9068e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:41] 7/22	    BatchTime 1.1842    DataTime 0.0002    Loss_Classification 2.3921e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 89.648
[Epoch:41] 8/22	    BatchTime 1.2077    DataTime 0.0001    Loss_Classification 2.6080e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.672
[Epoch:41] 9/22	    BatchTime 1.1857    DataTime 0.0001    Loss_Classification 2.1445e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.625
[Epoch:41] 10/22	    BatchTime 1.2278    DataTime 0.0002    Loss_Classification 2.1855e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:41] 11/22	    BatchTime 1.2284    DataTime 0.0001    Loss_Classification 1.8976e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:41] 12/22	    BatchTime 1.2083    DataTime 0.0001    Loss_Classification 2.1843e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.039
[Epoch:41] 13/22	    BatchTime 1.2010    DataTime 0.0002    Loss_Classification 2.0250e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.016
[Epoch:41] 14/22	    BatchTime 1.2051    DataTime 0.0002    Loss_Classification 2.2522e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:41] 15/22	    BatchTime 1.2334    DataTime 0.0002    Loss_Classification 1.4589e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.555
[Epoch:41] 16/22	    BatchTime 1.2336    DataTime 0.0002    Loss_Classification 2.0030e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 92.188
[Epoch:41] 17/22	    BatchTime 1.2092    DataTime 0.0000    Loss_Classification 1.7442e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:41] 18/22	    BatchTime 1.2281    DataTime 0.0002    Loss_Classification 1.8405e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:41] 19/22	    BatchTime 1.2131    DataTime 0.0002    Loss_Classification 1.8000e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:41] 20/22	    BatchTime 1.2363    DataTime 0.0002    Loss_Classification 2.6083e+00    Loss_Distance 0.0000e+00    acc@1 85.352    acc@5 86.719
[Epoch:41] 21/22	    BatchTime 1.3380    DataTime 0.0002    Loss_Classification 1.9392e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:41] 22/22	    BatchTime 1.2723    DataTime 0.0002    Loss_Classification 2.0467e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:41]  32.74    Loss_Classification 2.0412e+00    val_Loss_Classification 2.1832e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.142    val_acc@1 88.936    acc@5 90.776    val_acc@5 90.385
val_Loss_Classification improve from 2.219941882962429 to 2.1832483778492056
Save model to ./models/ep00041-val_Loss_Classification_2.1832-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00041-val_Loss_Classification_2.1832-val_Loss_Distance_0.0000.pth

Epoch 42 learning_rate : 7.330314893841102e-06
[Epoch:42] 1/22	    BatchTime 7.3237    DataTime 6.1180    Loss_Classification 1.9707e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.406
[Epoch:42] 2/22	    BatchTime 1.1639    DataTime 0.0002    Loss_Classification 1.7274e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:42] 3/22	    BatchTime 1.1383    DataTime 0.0002    Loss_Classification 2.1494e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:42] 4/22	    BatchTime 1.1786    DataTime 0.0002    Loss_Classification 1.6073e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.578
[Epoch:42] 5/22	    BatchTime 1.1494    DataTime 0.0002    Loss_Classification 2.3901e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.867
[Epoch:42] 6/22	    BatchTime 1.1689    DataTime 0.0002    Loss_Classification 1.9705e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:42] 7/22	    BatchTime 1.1813    DataTime 0.0001    Loss_Classification 2.2199e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.844
[Epoch:42] 8/22	    BatchTime 1.2026    DataTime 0.0002    Loss_Classification 2.0745e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:42] 9/22	    BatchTime 1.2006    DataTime 0.0001    Loss_Classification 2.0180e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.602
[Epoch:42] 10/22	    BatchTime 1.1883    DataTime 0.0001    Loss_Classification 2.5115e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.477
[Epoch:42] 11/22	    BatchTime 1.2201    DataTime 0.0001    Loss_Classification 2.1623e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.234
[Epoch:42] 12/22	    BatchTime 1.2019    DataTime 0.0002    Loss_Classification 2.3585e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.648
[Epoch:42] 13/22	    BatchTime 1.1915    DataTime 0.0002    Loss_Classification 1.5479e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 93.164
[Epoch:42] 14/22	    BatchTime 1.2038    DataTime 0.0002    Loss_Classification 1.6987e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.188
[Epoch:42] 15/22	    BatchTime 1.2444    DataTime 0.0002    Loss_Classification 2.0559e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:42] 16/22	    BatchTime 1.2444    DataTime 0.0002    Loss_Classification 2.3631e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.453
[Epoch:42] 17/22	    BatchTime 1.2147    DataTime 0.0004    Loss_Classification 2.1186e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:42] 18/22	    BatchTime 1.1933    DataTime 0.0002    Loss_Classification 1.7898e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.578
[Epoch:42] 19/22	    BatchTime 1.2505    DataTime 0.0000    Loss_Classification 2.4713e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.062
[Epoch:42] 20/22	    BatchTime 1.2262    DataTime 0.0002    Loss_Classification 2.1618e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.039
[Epoch:42] 21/22	    BatchTime 1.1973    DataTime 0.0002    Loss_Classification 1.8886e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:42] 22/22	    BatchTime 1.3650    DataTime 0.0002    Loss_Classification 2.6149e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 88.477
[Epoch:42]  32.65    Loss_Classification 2.0850e+00    val_Loss_Classification 2.2168e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.000    val_acc@1 88.724    acc@5 90.616    val_acc@5 90.315
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00042-val_Loss_Classification_2.2168-val_Loss_Distance_0.0000.pth

Epoch 43 learning_rate : 6.890576474687264e-06
[Epoch:43] 1/22	    BatchTime 7.4725    DataTime 6.1723    Loss_Classification 1.8866e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 91.406
[Epoch:43] 2/22	    BatchTime 1.1475    DataTime 0.0002    Loss_Classification 2.0529e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:43] 3/22	    BatchTime 1.1351    DataTime 0.0002    Loss_Classification 2.2725e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.430
[Epoch:43] 4/22	    BatchTime 1.1503    DataTime 0.0002    Loss_Classification 1.7623e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:43] 5/22	    BatchTime 1.1677    DataTime 0.0001    Loss_Classification 1.6147e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.773
[Epoch:43] 6/22	    BatchTime 1.1820    DataTime 0.0002    Loss_Classification 2.2605e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.258
[Epoch:43] 7/22	    BatchTime 1.2127    DataTime 0.0002    Loss_Classification 1.6581e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.992
[Epoch:43] 8/22	    BatchTime 1.1952    DataTime 0.0002    Loss_Classification 2.1357e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.039
[Epoch:43] 9/22	    BatchTime 1.1751    DataTime 0.0002    Loss_Classification 2.1265e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:43] 10/22	    BatchTime 1.1928    DataTime 0.0002    Loss_Classification 2.2793e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.844
[Epoch:43] 11/22	    BatchTime 1.1965    DataTime 0.0002    Loss_Classification 2.3612e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 89.453
[Epoch:43] 12/22	    BatchTime 1.2192    DataTime 0.0002    Loss_Classification 1.3122e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.945
[Epoch:43] 13/22	    BatchTime 1.2217    DataTime 0.0002    Loss_Classification 2.4409e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.672
[Epoch:43] 14/22	    BatchTime 1.2142    DataTime 0.0000    Loss_Classification 2.0781e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.820
[Epoch:43] 15/22	    BatchTime 1.2208    DataTime 0.0002    Loss_Classification 2.5192e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.672
[Epoch:43] 16/22	    BatchTime 1.2687    DataTime 0.0002    Loss_Classification 1.9976e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.602
[Epoch:43] 17/22	    BatchTime 1.2535    DataTime 0.0002    Loss_Classification 2.2520e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:43] 18/22	    BatchTime 1.2252    DataTime 0.0003    Loss_Classification 2.3081e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:43] 19/22	    BatchTime 1.2006    DataTime 0.0002    Loss_Classification 1.9981e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:43] 20/22	    BatchTime 1.2443    DataTime 0.0002    Loss_Classification 1.7904e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.188
[Epoch:43] 21/22	    BatchTime 1.2195    DataTime 0.0004    Loss_Classification 2.0334e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:43] 22/22	    BatchTime 1.2243    DataTime 0.0002    Loss_Classification 1.8100e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.992
[Epoch:43]  32.74    Loss_Classification 2.0432e+00    val_Loss_Classification 2.2052e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.160    val_acc@1 88.547    acc@5 90.829    val_acc@5 90.279
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00043-val_Loss_Classification_2.2052-val_Loss_Distance_0.0000.pth

Epoch 44 learning_rate : 6.435602608679916e-06
[Epoch:44] 1/22	    BatchTime 7.2454    DataTime 5.9832    Loss_Classification 2.1478e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:44] 2/22	    BatchTime 1.1495    DataTime 0.0002    Loss_Classification 2.3631e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.062
[Epoch:44] 3/22	    BatchTime 1.1392    DataTime 0.0002    Loss_Classification 1.9826e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:44] 4/22	    BatchTime 1.1487    DataTime 0.0002    Loss_Classification 1.9516e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:44] 5/22	    BatchTime 1.1819    DataTime 0.0002    Loss_Classification 1.7055e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:44] 6/22	    BatchTime 1.1778    DataTime 0.0002    Loss_Classification 1.6593e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.578
[Epoch:44] 7/22	    BatchTime 1.2203    DataTime 0.0001    Loss_Classification 2.3187e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.844
[Epoch:44] 8/22	    BatchTime 1.2252    DataTime 0.0001    Loss_Classification 1.9504e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:44] 9/22	    BatchTime 1.1967    DataTime 0.0002    Loss_Classification 1.8462e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:44] 10/22	    BatchTime 1.1912    DataTime 0.0002    Loss_Classification 1.9735e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:44] 11/22	    BatchTime 1.2072    DataTime 0.0002    Loss_Classification 1.6466e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.773
[Epoch:44] 12/22	    BatchTime 1.2177    DataTime 0.0000    Loss_Classification 1.6453e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.578
[Epoch:44] 13/22	    BatchTime 1.2097    DataTime 0.0001    Loss_Classification 1.8642e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:44] 14/22	    BatchTime 1.2232    DataTime 0.0002    Loss_Classification 2.3958e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 89.648
[Epoch:44] 15/22	    BatchTime 1.2115    DataTime 0.0002    Loss_Classification 1.9654e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:44] 16/22	    BatchTime 1.2675    DataTime 0.0002    Loss_Classification 2.5877e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.672
[Epoch:44] 17/22	    BatchTime 1.2767    DataTime 0.0002    Loss_Classification 1.7191e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.383
[Epoch:44] 18/22	    BatchTime 1.2291    DataTime 0.0002    Loss_Classification 1.9246e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.602
[Epoch:44] 19/22	    BatchTime 1.2118    DataTime 0.0002    Loss_Classification 2.0494e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:44] 20/22	    BatchTime 1.2415    DataTime 0.0001    Loss_Classification 1.7810e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:44] 21/22	    BatchTime 1.2256    DataTime 0.0001    Loss_Classification 1.7384e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 92.383
[Epoch:44] 22/22	    BatchTime 1.2209    DataTime 0.0002    Loss_Classification 2.2020e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:44]  32.62    Loss_Classification 1.9736e+00    val_Loss_Classification 2.3072e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.604    val_acc@1 88.370    acc@5 91.140    val_acc@5 90.032
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00044-val_Loss_Classification_2.3072-val_Loss_Distance_0.0000.pth

Epoch 45 learning_rate : 5.970378084704441e-06
[Epoch:45] 1/22	    BatchTime 7.2120    DataTime 5.8234    Loss_Classification 1.6820e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.578
[Epoch:45] 2/22	    BatchTime 1.1362    DataTime 0.0002    Loss_Classification 2.3589e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.039
[Epoch:45] 3/22	    BatchTime 1.1516    DataTime 0.0001    Loss_Classification 1.8007e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.383
[Epoch:45] 4/22	    BatchTime 1.1623    DataTime 0.0002    Loss_Classification 1.8920e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.406
[Epoch:45] 5/22	    BatchTime 1.1703    DataTime 0.0003    Loss_Classification 2.2703e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.453
[Epoch:45] 6/22	    BatchTime 1.1748    DataTime 0.0000    Loss_Classification 1.9486e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 90.820
[Epoch:45] 7/22	    BatchTime 1.1788    DataTime 0.0002    Loss_Classification 2.1714e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:45] 8/22	    BatchTime 1.2017    DataTime 0.0002    Loss_Classification 2.0452e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.820
[Epoch:45] 9/22	    BatchTime 1.2697    DataTime 0.0002    Loss_Classification 1.7163e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.992
[Epoch:45] 10/22	    BatchTime 1.2477    DataTime 0.0001    Loss_Classification 1.8813e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.992
[Epoch:45] 11/22	    BatchTime 1.2176    DataTime 0.0002    Loss_Classification 1.9817e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:45] 12/22	    BatchTime 1.1986    DataTime 0.0002    Loss_Classification 1.7298e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:45] 13/22	    BatchTime 1.1953    DataTime 0.0002    Loss_Classification 2.0637e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.430
[Epoch:45] 14/22	    BatchTime 1.2209    DataTime 0.0002    Loss_Classification 1.5544e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 93.164
[Epoch:45] 15/22	    BatchTime 1.2223    DataTime 0.0002    Loss_Classification 1.9613e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:45] 16/22	    BatchTime 1.2223    DataTime 0.0002    Loss_Classification 1.8281e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:45] 17/22	    BatchTime 1.2445    DataTime 0.0002    Loss_Classification 2.4642e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.062
[Epoch:45] 18/22	    BatchTime 1.2476    DataTime 0.0003    Loss_Classification 2.2538e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:45] 19/22	    BatchTime 1.2171    DataTime 0.0001    Loss_Classification 1.8363e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:45] 20/22	    BatchTime 1.2359    DataTime 0.0001    Loss_Classification 2.3524e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.453
[Epoch:45] 21/22	    BatchTime 1.2814    DataTime 0.0001    Loss_Classification 2.0720e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.844
[Epoch:45] 22/22	    BatchTime 1.2680    DataTime 0.0001    Loss_Classification 1.8589e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:45]  32.68    Loss_Classification 1.9874e+00    val_Loss_Classification 2.1684e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.373    val_acc@1 88.830    acc@5 90.980    val_acc@5 90.385
val_Loss_Classification improve from 2.1832483778492056 to 2.168435896736609
Save model to ./models/ep00045-val_Loss_Classification_2.1684-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00045-val_Loss_Classification_2.1684-val_Loss_Distance_0.0000.pth

Epoch 46 learning_rate : 5.500000000000001e-06
[Epoch:46] 1/22	    BatchTime 7.1580    DataTime 5.8342    Loss_Classification 1.8624e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.406
[Epoch:46] 2/22	    BatchTime 1.1363    DataTime 0.0002    Loss_Classification 1.9208e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:46] 3/22	    BatchTime 1.1365    DataTime 0.0002    Loss_Classification 1.8021e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.602
[Epoch:46] 4/22	    BatchTime 1.1524    DataTime 0.0002    Loss_Classification 2.1852e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:46] 5/22	    BatchTime 1.1637    DataTime 0.0001    Loss_Classification 1.8244e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.992
[Epoch:46] 6/22	    BatchTime 1.1949    DataTime 0.0001    Loss_Classification 1.8458e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:46] 7/22	    BatchTime 1.1804    DataTime 0.0002    Loss_Classification 2.4948e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:46] 8/22	    BatchTime 1.1949    DataTime 0.0004    Loss_Classification 1.8761e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:46] 9/22	    BatchTime 1.2446    DataTime 0.0002    Loss_Classification 2.2594e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:46] 10/22	    BatchTime 1.2265    DataTime 0.0001    Loss_Classification 1.5285e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.164
[Epoch:46] 11/22	    BatchTime 1.2183    DataTime 0.0007    Loss_Classification 1.7793e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.797
[Epoch:46] 12/22	    BatchTime 1.2067    DataTime 0.0000    Loss_Classification 1.9264e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:46] 13/22	    BatchTime 1.2486    DataTime 0.0001    Loss_Classification 1.8594e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:46] 14/22	    BatchTime 1.2207    DataTime 0.0002    Loss_Classification 1.8155e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:46] 15/22	    BatchTime 1.2081    DataTime 0.0001    Loss_Classification 1.6744e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.992
[Epoch:46] 16/22	    BatchTime 1.2034    DataTime 0.0002    Loss_Classification 2.0760e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:46] 17/22	    BatchTime 1.3172    DataTime 0.0002    Loss_Classification 2.0965e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 91.406
[Epoch:46] 18/22	    BatchTime 1.2694    DataTime 0.0002    Loss_Classification 1.4525e+00    Loss_Distance 0.0000e+00    acc@1 92.969    acc@5 93.359
[Epoch:46] 19/22	    BatchTime 1.2082    DataTime 0.0001    Loss_Classification 1.9683e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 90.820
[Epoch:46] 20/22	    BatchTime 1.1856    DataTime 0.0002    Loss_Classification 1.9411e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:46] 21/22	    BatchTime 1.2230    DataTime 0.0001    Loss_Classification 2.2315e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.258
[Epoch:46] 22/22	    BatchTime 1.2738    DataTime 0.0002    Loss_Classification 2.0639e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:46]  32.57    Loss_Classification 1.9311e+00    val_Loss_Classification 2.1513e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.906    val_acc@1 88.653    acc@5 91.202    val_acc@5 90.279
val_Loss_Classification improve from 2.168435896736609 to 2.151284309190337
Save model to ./models/ep00046-val_Loss_Classification_2.1513-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00046-val_Loss_Classification_2.1513-val_Loss_Distance_0.0000.pth

Epoch 47 learning_rate : 5.02962191529556e-06
[Epoch:47] 1/22	    BatchTime 7.5533    DataTime 6.2349    Loss_Classification 1.6090e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.773
[Epoch:47] 2/22	    BatchTime 1.1494    DataTime 0.0002    Loss_Classification 2.3221e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.648
[Epoch:47] 3/22	    BatchTime 1.1364    DataTime 0.0002    Loss_Classification 2.0565e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:47] 4/22	    BatchTime 1.1502    DataTime 0.0001    Loss_Classification 1.7874e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 92.188
[Epoch:47] 5/22	    BatchTime 1.1499    DataTime 0.0001    Loss_Classification 1.6069e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.773
[Epoch:47] 6/22	    BatchTime 1.1679    DataTime 0.0001    Loss_Classification 2.0143e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.211
[Epoch:47] 7/22	    BatchTime 1.1692    DataTime 0.0001    Loss_Classification 1.5449e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.164
[Epoch:47] 8/22	    BatchTime 1.1821    DataTime 0.0002    Loss_Classification 1.9529e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:47] 9/22	    BatchTime 1.2111    DataTime 0.0001    Loss_Classification 2.2282e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:47] 10/22	    BatchTime 1.1889    DataTime 0.0002    Loss_Classification 1.7819e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:47] 11/22	    BatchTime 1.1759    DataTime 0.0001    Loss_Classification 2.1348e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.430
[Epoch:47] 12/22	    BatchTime 1.2162    DataTime 0.0001    Loss_Classification 2.1094e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:47] 13/22	    BatchTime 1.2060    DataTime 0.0001    Loss_Classification 2.4740e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 89.062
[Epoch:47] 14/22	    BatchTime 1.2254    DataTime 0.0001    Loss_Classification 2.2191e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.844
[Epoch:47] 15/22	    BatchTime 1.1906    DataTime 0.0002    Loss_Classification 2.1967e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.039
[Epoch:47] 16/22	    BatchTime 1.2021    DataTime 0.0002    Loss_Classification 1.9784e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:47] 17/22	    BatchTime 1.2874    DataTime 0.0000    Loss_Classification 1.7809e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:47] 18/22	    BatchTime 1.2503    DataTime 0.0002    Loss_Classification 2.7182e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 88.086
[Epoch:47] 19/22	    BatchTime 1.2455    DataTime 0.0002    Loss_Classification 1.7512e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 92.578
[Epoch:47] 20/22	    BatchTime 1.2221    DataTime 0.0002    Loss_Classification 1.5730e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.383
[Epoch:47] 21/22	    BatchTime 1.2035    DataTime 0.0003    Loss_Classification 1.8914e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.797
[Epoch:47] 22/22	    BatchTime 1.1939    DataTime 0.0003    Loss_Classification 2.1794e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:47]  32.68    Loss_Classification 1.9959e+00    val_Loss_Classification 2.1073e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.453    val_acc@1 88.936    acc@5 91.051    val_acc@5 90.562
val_Loss_Classification improve from 2.151284309190337 to 2.1073112130460068
Save model to ./models/ep00047-val_Loss_Classification_2.1073-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00047-val_Loss_Classification_2.1073-val_Loss_Distance_0.0000.pth

Epoch 48 learning_rate : 4.564397391320083e-06
[Epoch:48] 1/22	    BatchTime 7.1275    DataTime 5.7802    Loss_Classification 1.9393e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.430
[Epoch:48] 2/22	    BatchTime 1.1491    DataTime 0.0002    Loss_Classification 1.6192e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.383
[Epoch:48] 3/22	    BatchTime 1.1373    DataTime 0.0001    Loss_Classification 2.0604e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:48] 4/22	    BatchTime 1.1493    DataTime 0.0002    Loss_Classification 1.8114e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:48] 5/22	    BatchTime 1.1652    DataTime 0.0002    Loss_Classification 2.2313e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.039
[Epoch:48] 6/22	    BatchTime 1.1708    DataTime 0.0002    Loss_Classification 1.9816e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:48] 7/22	    BatchTime 1.1955    DataTime 0.0002    Loss_Classification 2.1659e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:48] 8/22	    BatchTime 1.1807    DataTime 0.0001    Loss_Classification 1.4520e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.969
[Epoch:48] 9/22	    BatchTime 1.2208    DataTime 0.0002    Loss_Classification 1.7501e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.578
[Epoch:48] 10/22	    BatchTime 1.2211    DataTime 0.0002    Loss_Classification 2.4142e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.062
[Epoch:48] 11/22	    BatchTime 1.1961    DataTime 0.0000    Loss_Classification 1.6697e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:48] 12/22	    BatchTime 1.1964    DataTime 0.0002    Loss_Classification 2.2892e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.672
[Epoch:48] 13/22	    BatchTime 1.2177    DataTime 0.0002    Loss_Classification 2.1840e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:48] 14/22	    BatchTime 1.2059    DataTime 0.0001    Loss_Classification 1.7725e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.406
[Epoch:48] 15/22	    BatchTime 1.2451    DataTime 0.0002    Loss_Classification 1.6368e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:48] 16/22	    BatchTime 1.2837    DataTime 0.0001    Loss_Classification 2.0023e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.039
[Epoch:48] 17/22	    BatchTime 1.2174    DataTime 0.0001    Loss_Classification 1.9942e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:48] 18/22	    BatchTime 1.1919    DataTime 0.0001    Loss_Classification 1.9597e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:48] 19/22	    BatchTime 1.2329    DataTime 0.0001    Loss_Classification 2.1486e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:48] 20/22	    BatchTime 1.2526    DataTime 0.0002    Loss_Classification 1.8889e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:48] 21/22	    BatchTime 1.2316    DataTime 0.0002    Loss_Classification 2.5085e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.672
[Epoch:48] 22/22	    BatchTime 1.2728    DataTime 0.0001    Loss_Classification 2.2939e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.453
[Epoch:48]  32.46    Loss_Classification 1.9897e+00    val_Loss_Classification 2.2616e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.409    val_acc@1 88.689    acc@5 90.794    val_acc@5 89.926
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00048-val_Loss_Classification_2.2616-val_Loss_Distance_0.0000.pth

Epoch 49 learning_rate : 4.109423525312737e-06
[Epoch:49] 1/22	    BatchTime 7.4220    DataTime 6.0519    Loss_Classification 1.8020e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:49] 2/22	    BatchTime 1.2485    DataTime 0.0002    Loss_Classification 1.9559e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.406
[Epoch:49] 3/22	    BatchTime 1.2931    DataTime 0.0002    Loss_Classification 2.0037e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:49] 4/22	    BatchTime 1.2868    DataTime 0.0002    Loss_Classification 2.0416e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:49] 5/22	    BatchTime 1.1938    DataTime 0.0002    Loss_Classification 1.9513e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:49] 6/22	    BatchTime 1.1885    DataTime 0.0002    Loss_Classification 2.0927e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:49] 7/22	    BatchTime 1.1771    DataTime 0.0002    Loss_Classification 1.7723e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.188
[Epoch:49] 8/22	    BatchTime 1.2278    DataTime 0.0002    Loss_Classification 2.0989e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:49] 9/22	    BatchTime 1.2123    DataTime 0.0002    Loss_Classification 1.5828e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:49] 10/22	    BatchTime 1.2054    DataTime 0.0002    Loss_Classification 1.9015e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.211
[Epoch:49] 11/22	    BatchTime 1.2496    DataTime 0.0002    Loss_Classification 2.2426e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.430
[Epoch:49] 12/22	    BatchTime 1.2438    DataTime 0.0002    Loss_Classification 2.6776e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.281
[Epoch:49] 13/22	    BatchTime 1.2096    DataTime 0.0002    Loss_Classification 2.1805e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:49] 14/22	    BatchTime 1.2023    DataTime 0.0002    Loss_Classification 1.5997e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.578
[Epoch:49] 15/22	    BatchTime 1.2654    DataTime 0.0002    Loss_Classification 2.4580e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.062
[Epoch:49] 16/22	    BatchTime 1.2222    DataTime 0.0002    Loss_Classification 1.8109e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.602
[Epoch:49] 17/22	    BatchTime 1.2101    DataTime 0.0000    Loss_Classification 2.0921e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.234
[Epoch:49] 18/22	    BatchTime 1.2240    DataTime 0.0001    Loss_Classification 1.8139e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.797
[Epoch:49] 19/22	    BatchTime 1.2285    DataTime 0.0005    Loss_Classification 2.0134e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:49] 20/22	    BatchTime 1.2749    DataTime 0.0002    Loss_Classification 2.1737e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.430
[Epoch:49] 21/22	    BatchTime 1.2309    DataTime 0.0002    Loss_Classification 1.9715e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:49] 22/22	    BatchTime 1.2271    DataTime 0.0002    Loss_Classification 1.9431e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.992
[Epoch:49]  33.24    Loss_Classification 2.0082e+00    val_Loss_Classification 2.1523e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.373    val_acc@1 89.113    acc@5 90.998    val_acc@5 90.597
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00049-val_Loss_Classification_2.1523-val_Loss_Distance_0.0000.pth

Epoch 50 learning_rate : 3.6696851061588997e-06
[Epoch:50] 1/22	    BatchTime 7.4298    DataTime 6.1310    Loss_Classification 1.7513e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:50] 2/22	    BatchTime 1.1493    DataTime 0.0002    Loss_Classification 2.0166e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.625
[Epoch:50] 3/22	    BatchTime 1.1461    DataTime 0.0001    Loss_Classification 2.1140e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.625
[Epoch:50] 4/22	    BatchTime 1.1692    DataTime 0.0002    Loss_Classification 2.2443e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.062
[Epoch:50] 5/22	    BatchTime 1.1745    DataTime 0.0002    Loss_Classification 2.0989e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:50] 6/22	    BatchTime 1.1825    DataTime 0.0002    Loss_Classification 1.4747e+00    Loss_Distance 0.0000e+00    acc@1 92.383    acc@5 93.750
[Epoch:50] 7/22	    BatchTime 1.1943    DataTime 0.0002    Loss_Classification 2.2621e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 90.039
[Epoch:50] 8/22	    BatchTime 1.1992    DataTime 0.0002    Loss_Classification 1.9689e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:50] 9/22	    BatchTime 1.2755    DataTime 0.0002    Loss_Classification 2.3337e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.648
[Epoch:50] 10/22	    BatchTime 1.2435    DataTime 0.0001    Loss_Classification 1.9327e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.797
[Epoch:50] 11/22	    BatchTime 1.2122    DataTime 0.0002    Loss_Classification 1.8356e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:50] 12/22	    BatchTime 1.2047    DataTime 0.0001    Loss_Classification 2.4401e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.672
[Epoch:50] 13/22	    BatchTime 1.1999    DataTime 0.0002    Loss_Classification 1.6132e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.383
[Epoch:50] 14/22	    BatchTime 1.2234    DataTime 0.0002    Loss_Classification 1.9399e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.016
[Epoch:50] 15/22	    BatchTime 1.2168    DataTime 0.0000    Loss_Classification 1.6773e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.578
[Epoch:50] 16/22	    BatchTime 1.2046    DataTime 0.0001    Loss_Classification 2.2949e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.039
[Epoch:50] 17/22	    BatchTime 1.4318    DataTime 0.0002    Loss_Classification 1.8280e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.992
[Epoch:50] 18/22	    BatchTime 1.2566    DataTime 0.0002    Loss_Classification 1.6408e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.773
[Epoch:50] 19/22	    BatchTime 1.2151    DataTime 0.0002    Loss_Classification 1.7225e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.992
[Epoch:50] 20/22	    BatchTime 1.2204    DataTime 0.0002    Loss_Classification 2.1877e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:50] 21/22	    BatchTime 1.4765    DataTime 0.0001    Loss_Classification 1.8424e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:50] 22/22	    BatchTime 1.2254    DataTime 0.0002    Loss_Classification 2.2655e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:50]  33.25    Loss_Classification 1.9766e+00    val_Loss_Classification 2.3128e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.773    val_acc@1 88.088    acc@5 91.122    val_acc@5 89.855
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00050-val_Loss_Classification_2.3128-val_Loss_Distance_0.0000.pth

Epoch 51 learning_rate : 3.250000000000001e-06
[Epoch:51] 1/22	    BatchTime 7.0535    DataTime 5.7854    Loss_Classification 2.2094e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.039
[Epoch:51] 2/22	    BatchTime 1.1352    DataTime 0.0003    Loss_Classification 2.0078e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.820
[Epoch:51] 3/22	    BatchTime 1.1367    DataTime 0.0000    Loss_Classification 1.6953e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:51] 4/22	    BatchTime 1.1780    DataTime 0.0003    Loss_Classification 2.3036e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 89.453
[Epoch:51] 5/22	    BatchTime 1.1691    DataTime 0.0002    Loss_Classification 1.9147e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:51] 6/22	    BatchTime 1.2064    DataTime 0.0001    Loss_Classification 1.4659e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.969
[Epoch:51] 7/22	    BatchTime 1.1960    DataTime 0.0001    Loss_Classification 2.4182e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:51] 8/22	    BatchTime 1.1712    DataTime 0.0002    Loss_Classification 2.0268e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:51] 9/22	    BatchTime 1.1986    DataTime 0.0002    Loss_Classification 1.4669e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 92.773
[Epoch:51] 10/22	    BatchTime 1.2400    DataTime 0.0001    Loss_Classification 2.0095e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.234
[Epoch:51] 11/22	    BatchTime 1.2195    DataTime 0.0002    Loss_Classification 1.9296e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:51] 12/22	    BatchTime 1.1890    DataTime 0.0001    Loss_Classification 2.1316e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:51] 13/22	    BatchTime 1.2381    DataTime 0.0001    Loss_Classification 1.6675e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.383
[Epoch:51] 14/22	    BatchTime 1.2168    DataTime 0.0002    Loss_Classification 2.1690e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:51] 15/22	    BatchTime 1.2026    DataTime 0.0001    Loss_Classification 1.6332e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.969
[Epoch:51] 16/22	    BatchTime 1.2399    DataTime 0.0001    Loss_Classification 1.7644e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:51] 17/22	    BatchTime 1.2251    DataTime 0.0001    Loss_Classification 2.1149e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 89.844
[Epoch:51] 18/22	    BatchTime 1.3337    DataTime 0.0001    Loss_Classification 2.6123e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 88.281
[Epoch:51] 19/22	    BatchTime 1.2605    DataTime 0.0001    Loss_Classification 1.8810e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:51] 20/22	    BatchTime 1.2542    DataTime 0.0001    Loss_Classification 1.5423e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.773
[Epoch:51] 21/22	    BatchTime 1.2160    DataTime 0.0002    Loss_Classification 1.8385e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.797
[Epoch:51] 22/22	    BatchTime 1.2219    DataTime 0.0002    Loss_Classification 2.3838e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 89.062
[Epoch:51]  32.50    Loss_Classification 1.9630e+00    val_Loss_Classification 2.3398e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.790    val_acc@1 88.088    acc@5 91.069    val_acc@5 89.643
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00051-val_Loss_Classification_2.3398-val_Loss_Distance_0.0000.pth

Epoch 52 learning_rate : 2.8549663646838717e-06
[Epoch:52] 1/22	    BatchTime 7.2027    DataTime 5.9246    Loss_Classification 2.2496e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.258
[Epoch:52] 2/22	    BatchTime 1.1377    DataTime 0.0002    Loss_Classification 2.1988e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.625
[Epoch:52] 3/22	    BatchTime 1.1377    DataTime 0.0002    Loss_Classification 2.0999e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:52] 4/22	    BatchTime 1.1819    DataTime 0.0002    Loss_Classification 1.6242e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.383
[Epoch:52] 5/22	    BatchTime 1.1698    DataTime 0.0001    Loss_Classification 1.9941e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.602
[Epoch:52] 6/22	    BatchTime 1.1969    DataTime 0.0001    Loss_Classification 2.0795e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.648
[Epoch:52] 7/22	    BatchTime 1.2052    DataTime 0.0001    Loss_Classification 2.0499e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:52] 8/22	    BatchTime 1.2521    DataTime 0.0002    Loss_Classification 1.8598e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.406
[Epoch:52] 9/22	    BatchTime 1.2468    DataTime 0.0002    Loss_Classification 1.6945e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:52] 10/22	    BatchTime 1.2107    DataTime 0.0000    Loss_Classification 1.7657e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.992
[Epoch:52] 11/22	    BatchTime 1.1941    DataTime 0.0001    Loss_Classification 1.8150e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.797
[Epoch:52] 12/22	    BatchTime 1.2013    DataTime 0.0002    Loss_Classification 1.9719e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:52] 13/22	    BatchTime 1.2257    DataTime 0.0002    Loss_Classification 1.5344e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.359
[Epoch:52] 14/22	    BatchTime 1.2253    DataTime 0.0001    Loss_Classification 2.0194e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.211
[Epoch:52] 15/22	    BatchTime 1.2486    DataTime 0.0003    Loss_Classification 2.0655e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:52] 16/22	    BatchTime 1.2286    DataTime 0.0002    Loss_Classification 1.8196e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.211
[Epoch:52] 17/22	    BatchTime 1.2103    DataTime 0.0002    Loss_Classification 2.2107e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.453
[Epoch:52] 18/22	    BatchTime 1.2261    DataTime 0.0003    Loss_Classification 1.7862e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:52] 19/22	    BatchTime 1.2309    DataTime 0.0002    Loss_Classification 2.0828e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.430
[Epoch:52] 20/22	    BatchTime 1.2350    DataTime 0.0002    Loss_Classification 2.2541e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.039
[Epoch:52] 21/22	    BatchTime 1.2218    DataTime 0.0002    Loss_Classification 2.1328e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.625
[Epoch:52] 22/22	    BatchTime 1.2521    DataTime 0.0002    Loss_Classification 1.6371e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.992
[Epoch:52]  32.64    Loss_Classification 1.9521e+00    val_Loss_Classification 2.1714e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.684    val_acc@1 88.406    acc@5 91.104    val_acc@5 90.173
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00052-val_Loss_Classification_2.1714-val_Loss_Distance_0.0000.pth

Epoch 53 learning_rate : 2.4889122713851393e-06
[Epoch:53] 1/22	    BatchTime 7.4549    DataTime 6.2042    Loss_Classification 1.8524e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:53] 2/22	    BatchTime 1.1904    DataTime 0.0001    Loss_Classification 2.1076e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:53] 3/22	    BatchTime 1.1350    DataTime 0.0003    Loss_Classification 2.0256e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:53] 4/22	    BatchTime 1.1674    DataTime 0.0001    Loss_Classification 1.5165e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 92.773
[Epoch:53] 5/22	    BatchTime 1.1775    DataTime 0.0002    Loss_Classification 1.8052e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.578
[Epoch:53] 6/22	    BatchTime 1.1706    DataTime 0.0002    Loss_Classification 2.1025e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:53] 7/22	    BatchTime 1.1831    DataTime 0.0001    Loss_Classification 2.5420e+00    Loss_Distance 0.0000e+00    acc@1 86.133    acc@5 88.086
[Epoch:53] 8/22	    BatchTime 1.2531    DataTime 0.0001    Loss_Classification 1.6864e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.383
[Epoch:53] 9/22	    BatchTime 1.2223    DataTime 0.0001    Loss_Classification 2.0175e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:53] 10/22	    BatchTime 1.2091    DataTime 0.0001    Loss_Classification 1.9363e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:53] 11/22	    BatchTime 1.2056    DataTime 0.0002    Loss_Classification 1.7472e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:53] 12/22	    BatchTime 1.2000    DataTime 0.0003    Loss_Classification 1.8672e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.211
[Epoch:53] 13/22	    BatchTime 1.2244    DataTime 0.0000    Loss_Classification 2.0973e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:53] 14/22	    BatchTime 1.2186    DataTime 0.0001    Loss_Classification 1.6315e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:53] 15/22	    BatchTime 1.2053    DataTime 0.0002    Loss_Classification 2.0331e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.234
[Epoch:53] 16/22	    BatchTime 1.2934    DataTime 0.0003    Loss_Classification 2.0399e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:53] 17/22	    BatchTime 1.2712    DataTime 0.0002    Loss_Classification 1.6652e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.383
[Epoch:53] 18/22	    BatchTime 1.2450    DataTime 0.0001    Loss_Classification 1.4467e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 93.164
[Epoch:53] 19/22	    BatchTime 1.2229    DataTime 0.0002    Loss_Classification 1.9739e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.211
[Epoch:53] 20/22	    BatchTime 1.2280    DataTime 0.0002    Loss_Classification 1.7539e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.383
[Epoch:53] 21/22	    BatchTime 1.2241    DataTime 0.0001    Loss_Classification 2.0800e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:53] 22/22	    BatchTime 1.2586    DataTime 0.0002    Loss_Classification 1.7380e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 91.602
[Epoch:53]  32.96    Loss_Classification 1.8939e+00    val_Loss_Classification 2.1540e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.719    val_acc@1 88.971    acc@5 91.344    val_acc@5 90.315
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00053-val_Loss_Classification_2.1540-val_Loss_Distance_0.0000.pth

Epoch 54 learning_rate : 2.155848285351727e-06
[Epoch:54] 1/22	    BatchTime 7.2971    DataTime 5.9384    Loss_Classification 1.8892e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.602
[Epoch:54] 2/22	    BatchTime 1.1354    DataTime 0.0002    Loss_Classification 2.0231e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:54] 3/22	    BatchTime 1.1365    DataTime 0.0002    Loss_Classification 1.9685e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:54] 4/22	    BatchTime 1.1762    DataTime 0.0001    Loss_Classification 2.1625e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:54] 5/22	    BatchTime 1.1861    DataTime 0.0001    Loss_Classification 2.0487e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.625
[Epoch:54] 6/22	    BatchTime 1.1897    DataTime 0.0001    Loss_Classification 1.9692e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.211
[Epoch:54] 7/22	    BatchTime 1.1739    DataTime 0.0005    Loss_Classification 2.4917e+00    Loss_Distance 0.0000e+00    acc@1 87.109    acc@5 88.867
[Epoch:54] 8/22	    BatchTime 1.1959    DataTime 0.0002    Loss_Classification 2.0560e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:54] 9/22	    BatchTime 1.2702    DataTime 0.0001    Loss_Classification 1.9560e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:54] 10/22	    BatchTime 1.2610    DataTime 0.0003    Loss_Classification 1.8594e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:54] 11/22	    BatchTime 1.2130    DataTime 0.0001    Loss_Classification 1.7017e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.578
[Epoch:54] 12/22	    BatchTime 1.2047    DataTime 0.0002    Loss_Classification 1.8561e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.797
[Epoch:54] 13/22	    BatchTime 1.1849    DataTime 0.0004    Loss_Classification 2.1909e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:54] 14/22	    BatchTime 1.2382    DataTime 0.0002    Loss_Classification 1.8575e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.406
[Epoch:54] 15/22	    BatchTime 1.2304    DataTime 0.0002    Loss_Classification 2.1830e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.820
[Epoch:54] 16/22	    BatchTime 1.3018    DataTime 0.0002    Loss_Classification 2.0563e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:54] 17/22	    BatchTime 1.2399    DataTime 0.0000    Loss_Classification 2.1409e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:54] 18/22	    BatchTime 1.2236    DataTime 0.0002    Loss_Classification 1.6398e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 92.383
[Epoch:54] 19/22	    BatchTime 1.2178    DataTime 0.0002    Loss_Classification 2.2714e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.844
[Epoch:54] 20/22	    BatchTime 1.2228    DataTime 0.0002    Loss_Classification 1.4373e+00    Loss_Distance 0.0000e+00    acc@1 92.383    acc@5 93.555
[Epoch:54] 21/22	    BatchTime 1.2527    DataTime 0.0002    Loss_Classification 1.6783e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.992
[Epoch:54] 22/22	    BatchTime 1.2473    DataTime 0.0002    Loss_Classification 2.1889e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:54]  32.80    Loss_Classification 1.9830e+00    val_Loss_Classification 2.2756e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.808    val_acc@1 88.264    acc@5 91.167    val_acc@5 89.820
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00054-val_Loss_Classification_2.2756-val_Loss_Distance_0.0000.pth

Epoch 55 learning_rate : 1.8594235253127369e-06
[Epoch:55] 1/22	    BatchTime 7.5061    DataTime 6.1145    Loss_Classification 1.8556e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.602
[Epoch:55] 2/22	    BatchTime 1.1384    DataTime 0.0002    Loss_Classification 2.0591e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:55] 3/22	    BatchTime 1.1472    DataTime 0.0001    Loss_Classification 1.9186e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.211
[Epoch:55] 4/22	    BatchTime 1.1534    DataTime 0.0001    Loss_Classification 2.2236e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.234
[Epoch:55] 5/22	    BatchTime 1.1704    DataTime 0.0002    Loss_Classification 2.0749e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.039
[Epoch:55] 6/22	    BatchTime 1.1837    DataTime 0.0001    Loss_Classification 1.7572e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.797
[Epoch:55] 7/22	    BatchTime 1.1926    DataTime 0.0002    Loss_Classification 1.9799e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.406
[Epoch:55] 8/22	    BatchTime 1.1991    DataTime 0.0004    Loss_Classification 1.8590e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:55] 9/22	    BatchTime 1.2364    DataTime 0.0004    Loss_Classification 1.7914e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.797
[Epoch:55] 10/22	    BatchTime 1.2224    DataTime 0.0002    Loss_Classification 2.0007e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.625
[Epoch:55] 11/22	    BatchTime 1.2128    DataTime 0.0001    Loss_Classification 1.6127e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.773
[Epoch:55] 12/22	    BatchTime 1.2165    DataTime 0.0002    Loss_Classification 2.1049e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:55] 13/22	    BatchTime 1.2100    DataTime 0.0001    Loss_Classification 1.7306e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.578
[Epoch:55] 14/22	    BatchTime 1.2107    DataTime 0.0002    Loss_Classification 2.0477e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:55] 15/22	    BatchTime 1.2463    DataTime 0.0001    Loss_Classification 1.9915e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:55] 16/22	    BatchTime 1.2268    DataTime 0.0002    Loss_Classification 2.1700e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.430
[Epoch:55] 17/22	    BatchTime 1.2113    DataTime 0.0004    Loss_Classification 1.4053e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 93.359
[Epoch:55] 18/22	    BatchTime 1.2685    DataTime 0.0001    Loss_Classification 1.6680e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 91.992
[Epoch:55] 19/22	    BatchTime 1.2224    DataTime 0.0002    Loss_Classification 2.5197e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 89.258
[Epoch:55] 20/22	    BatchTime 1.2340    DataTime 0.0000    Loss_Classification 1.7276e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 91.992
[Epoch:55] 21/22	    BatchTime 1.2282    DataTime 0.0002    Loss_Classification 1.8823e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.406
[Epoch:55] 22/22	    BatchTime 1.2235    DataTime 0.0002    Loss_Classification 1.8453e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.797
[Epoch:55]  32.86    Loss_Classification 1.9194e+00    val_Loss_Classification 2.2920e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.924    val_acc@1 88.512    acc@5 91.362    val_acc@5 89.961
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00055-val_Loss_Classification_2.2920-val_Loss_Distance_0.0000.pth

Epoch 56 learning_rate : 1.6028856829700258e-06
[Epoch:56] 1/22	    BatchTime 7.1274    DataTime 5.7660    Loss_Classification 2.1815e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:56] 2/22	    BatchTime 1.1489    DataTime 0.0002    Loss_Classification 1.7041e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:56] 3/22	    BatchTime 1.1389    DataTime 0.0002    Loss_Classification 1.7115e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 92.383
[Epoch:56] 4/22	    BatchTime 1.1544    DataTime 0.0007    Loss_Classification 2.1585e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.430
[Epoch:56] 5/22	    BatchTime 1.1692    DataTime 0.0006    Loss_Classification 2.1269e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:56] 6/22	    BatchTime 1.2016    DataTime 0.0002    Loss_Classification 2.0806e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:56] 7/22	    BatchTime 1.1901    DataTime 0.0001    Loss_Classification 1.4541e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.750
[Epoch:56] 8/22	    BatchTime 1.2309    DataTime 0.0002    Loss_Classification 2.0685e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.406
[Epoch:56] 9/22	    BatchTime 1.2000    DataTime 0.0002    Loss_Classification 2.2155e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:56] 10/22	    BatchTime 1.1807    DataTime 0.0002    Loss_Classification 1.9605e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:56] 11/22	    BatchTime 1.2960    DataTime 0.0002    Loss_Classification 2.1509e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 89.844
[Epoch:56] 12/22	    BatchTime 1.2502    DataTime 0.0002    Loss_Classification 2.3469e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:56] 13/22	    BatchTime 1.2284    DataTime 0.0001    Loss_Classification 1.9477e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:56] 14/22	    BatchTime 1.2240    DataTime 0.0001    Loss_Classification 1.6672e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 92.188
[Epoch:56] 15/22	    BatchTime 1.1910    DataTime 0.0003    Loss_Classification 1.8640e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:56] 16/22	    BatchTime 1.2225    DataTime 0.0004    Loss_Classification 1.9175e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.406
[Epoch:56] 17/22	    BatchTime 1.2391    DataTime 0.0000    Loss_Classification 1.8351e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.406
[Epoch:56] 18/22	    BatchTime 1.2214    DataTime 0.0001    Loss_Classification 1.7402e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:56] 19/22	    BatchTime 1.2331    DataTime 0.0001    Loss_Classification 2.0057e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.406
[Epoch:56] 20/22	    BatchTime 1.2925    DataTime 0.0002    Loss_Classification 2.0372e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 91.211
[Epoch:56] 21/22	    BatchTime 1.2584    DataTime 0.0001    Loss_Classification 1.7870e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.383
[Epoch:56] 22/22	    BatchTime 1.2215    DataTime 0.0002    Loss_Classification 2.2070e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:56]  32.62    Loss_Classification 1.9622e+00    val_Loss_Classification 2.3100e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.693    val_acc@1 88.300    acc@5 91.300    val_acc@5 89.608
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00056-val_Loss_Classification_2.3100-val_Loss_Distance_0.0000.pth

Epoch 57 learning_rate : 1.3890454406082957e-06
[Epoch:57] 1/22	    BatchTime 7.4726    DataTime 6.2846    Loss_Classification 2.2232e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:57] 2/22	    BatchTime 1.1356    DataTime 0.0002    Loss_Classification 1.2679e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 94.141
[Epoch:57] 3/22	    BatchTime 1.1371    DataTime 0.0001    Loss_Classification 2.1382e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:57] 4/22	    BatchTime 1.1935    DataTime 0.0002    Loss_Classification 1.6848e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.797
[Epoch:57] 5/22	    BatchTime 1.1744    DataTime 0.0002    Loss_Classification 2.0481e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:57] 6/22	    BatchTime 1.1836    DataTime 0.0000    Loss_Classification 2.0465e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:57] 7/22	    BatchTime 1.1898    DataTime 0.0001    Loss_Classification 1.9735e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.406
[Epoch:57] 8/22	    BatchTime 1.1798    DataTime 0.0001    Loss_Classification 1.6295e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.578
[Epoch:57] 9/22	    BatchTime 1.3050    DataTime 0.0001    Loss_Classification 1.6661e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.188
[Epoch:57] 10/22	    BatchTime 1.2649    DataTime 0.0002    Loss_Classification 2.1272e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:57] 11/22	    BatchTime 1.2008    DataTime 0.0001    Loss_Classification 1.4542e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.164
[Epoch:57] 12/22	    BatchTime 1.1919    DataTime 0.0001    Loss_Classification 1.9050e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:57] 13/22	    BatchTime 1.2361    DataTime 0.0001    Loss_Classification 2.3123e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.648
[Epoch:57] 14/22	    BatchTime 1.2295    DataTime 0.0002    Loss_Classification 2.2878e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.648
[Epoch:57] 15/22	    BatchTime 1.1993    DataTime 0.0003    Loss_Classification 1.7745e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:57] 16/22	    BatchTime 1.2538    DataTime 0.0002    Loss_Classification 1.8176e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.797
[Epoch:57] 17/22	    BatchTime 1.2006    DataTime 0.0002    Loss_Classification 2.0580e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:57] 18/22	    BatchTime 1.3471    DataTime 0.0001    Loss_Classification 1.8189e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.797
[Epoch:57] 19/22	    BatchTime 1.2962    DataTime 0.0001    Loss_Classification 1.9714e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.211
[Epoch:57] 20/22	    BatchTime 1.2308    DataTime 0.0002    Loss_Classification 2.0155e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.211
[Epoch:57] 21/22	    BatchTime 1.2115    DataTime 0.0001    Loss_Classification 2.3120e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.844
[Epoch:57] 22/22	    BatchTime 1.4776    DataTime 0.0001    Loss_Classification 2.0496e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 91.797
[Epoch:57]  33.31    Loss_Classification 1.9355e+00    val_Loss_Classification 2.2961e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 90.004    val_acc@1 88.335    acc@5 91.264    val_acc@5 90.032
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00057-val_Loss_Classification_2.2961-val_Loss_Distance_0.0000.pth

Epoch 58 learning_rate : 1.220245676671809e-06
[Epoch:58] 1/22	    BatchTime 7.2786    DataTime 5.9212    Loss_Classification 1.9856e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 91.016
[Epoch:58] 2/22	    BatchTime 1.1485    DataTime 0.0002    Loss_Classification 2.3563e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.844
[Epoch:58] 3/22	    BatchTime 1.1384    DataTime 0.0002    Loss_Classification 1.9862e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.016
[Epoch:58] 4/22	    BatchTime 1.1546    DataTime 0.0004    Loss_Classification 1.8151e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:58] 5/22	    BatchTime 1.1724    DataTime 0.0005    Loss_Classification 1.8217e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:58] 6/22	    BatchTime 1.1787    DataTime 0.0002    Loss_Classification 2.0462e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.430
[Epoch:58] 7/22	    BatchTime 1.2001    DataTime 0.0000    Loss_Classification 2.1994e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:58] 8/22	    BatchTime 1.1925    DataTime 0.0002    Loss_Classification 2.0922e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:58] 9/22	    BatchTime 1.1871    DataTime 0.0002    Loss_Classification 2.0503e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.039
[Epoch:58] 10/22	    BatchTime 1.2165    DataTime 0.0002    Loss_Classification 2.1343e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:58] 11/22	    BatchTime 1.2075    DataTime 0.0002    Loss_Classification 2.1073e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:58] 12/22	    BatchTime 1.2341    DataTime 0.0002    Loss_Classification 1.6996e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.406
[Epoch:58] 13/22	    BatchTime 1.2615    DataTime 0.0002    Loss_Classification 2.3218e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.258
[Epoch:58] 14/22	    BatchTime 1.2326    DataTime 0.0004    Loss_Classification 1.6954e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.602
[Epoch:58] 15/22	    BatchTime 1.2117    DataTime 0.0002    Loss_Classification 1.8915e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:58] 16/22	    BatchTime 1.2040    DataTime 0.0002    Loss_Classification 1.7128e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:58] 17/22	    BatchTime 1.2755    DataTime 0.0002    Loss_Classification 1.9149e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.406
[Epoch:58] 18/22	    BatchTime 1.2412    DataTime 0.0002    Loss_Classification 1.8290e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.992
[Epoch:58] 19/22	    BatchTime 1.2101    DataTime 0.0002    Loss_Classification 1.9961e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:58] 20/22	    BatchTime 1.1926    DataTime 0.0002    Loss_Classification 1.6456e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:58] 21/22	    BatchTime 1.2633    DataTime 0.0002    Loss_Classification 2.0357e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.625
[Epoch:58] 22/22	    BatchTime 1.2668    DataTime 0.0001    Loss_Classification 1.9783e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:58]  32.67    Loss_Classification 1.9689e+00    val_Loss_Classification 2.1177e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.702    val_acc@1 89.113    acc@5 91.025    val_acc@5 90.527
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00058-val_Loss_Classification_2.1177-val_Loss_Distance_0.0000.pth

Epoch 59 learning_rate : 1.0983357966978744e-06
[Epoch:59] 1/22	    BatchTime 7.3971    DataTime 6.1154    Loss_Classification 1.9531e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.406
[Epoch:59] 2/22	    BatchTime 1.1520    DataTime 0.0002    Loss_Classification 1.8650e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 92.188
[Epoch:59] 3/22	    BatchTime 1.1409    DataTime 0.0002    Loss_Classification 2.1694e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.844
[Epoch:59] 4/22	    BatchTime 1.1577    DataTime 0.0000    Loss_Classification 1.7922e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:59] 5/22	    BatchTime 1.1872    DataTime 0.0004    Loss_Classification 1.7882e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.992
[Epoch:59] 6/22	    BatchTime 1.1857    DataTime 0.0002    Loss_Classification 1.7583e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.797
[Epoch:59] 7/22	    BatchTime 1.1875    DataTime 0.0002    Loss_Classification 1.9155e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:59] 8/22	    BatchTime 1.2438    DataTime 0.0002    Loss_Classification 1.4465e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 93.555
[Epoch:59] 9/22	    BatchTime 1.2132    DataTime 0.0002    Loss_Classification 1.4518e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.359
[Epoch:59] 10/22	    BatchTime 1.2042    DataTime 0.0002    Loss_Classification 1.9199e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.820
[Epoch:59] 11/22	    BatchTime 1.1784    DataTime 0.0002    Loss_Classification 1.5423e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:59] 12/22	    BatchTime 1.2332    DataTime 0.0002    Loss_Classification 2.0240e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.234
[Epoch:59] 13/22	    BatchTime 1.2242    DataTime 0.0002    Loss_Classification 1.9772e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.625
[Epoch:59] 14/22	    BatchTime 1.2211    DataTime 0.0001    Loss_Classification 2.0678e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:59] 15/22	    BatchTime 1.2077    DataTime 0.0001    Loss_Classification 2.2309e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:59] 16/22	    BatchTime 1.3161    DataTime 0.0002    Loss_Classification 1.8945e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.602
[Epoch:59] 17/22	    BatchTime 1.2637    DataTime 0.0002    Loss_Classification 2.6793e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.477
[Epoch:59] 18/22	    BatchTime 1.2262    DataTime 0.0002    Loss_Classification 1.8863e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.211
[Epoch:59] 19/22	    BatchTime 1.2111    DataTime 0.0001    Loss_Classification 1.4588e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 93.359
[Epoch:59] 20/22	    BatchTime 1.2380    DataTime 0.0001    Loss_Classification 1.5628e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.773
[Epoch:59] 21/22	    BatchTime 1.2944    DataTime 0.0001    Loss_Classification 1.4316e+00    Loss_Distance 0.0000e+00    acc@1 92.383    acc@5 92.969
[Epoch:59] 22/22	    BatchTime 1.2798    DataTime 0.0001    Loss_Classification 2.3319e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.062
[Epoch:59]  32.96    Loss_Classification 1.8703e+00    val_Loss_Classification 2.0726e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.853    val_acc@1 89.183    acc@5 91.415    val_acc@5 90.562
val_Loss_Classification improve from 2.1073112130460068 to 2.0726060702127382
Save model to ./models/ep00059-val_Loss_Classification_2.0726-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00059-val_Loss_Classification_2.0726-val_Loss_Distance_0.0000.pth

Epoch 60 learning_rate : 1.0246514708427697e-06
[Epoch:60] 1/22	    BatchTime 7.4840    DataTime 6.1800    Loss_Classification 1.9880e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:60] 2/22	    BatchTime 1.1358    DataTime 0.0002    Loss_Classification 1.9087e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:60] 3/22	    BatchTime 1.1508    DataTime 0.0000    Loss_Classification 1.7549e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.383
[Epoch:60] 4/22	    BatchTime 1.1618    DataTime 0.0001    Loss_Classification 2.1086e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:60] 5/22	    BatchTime 1.1650    DataTime 0.0001    Loss_Classification 2.2196e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.258
[Epoch:60] 6/22	    BatchTime 1.1895    DataTime 0.0001    Loss_Classification 1.7736e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:60] 7/22	    BatchTime 1.1863    DataTime 0.0001    Loss_Classification 2.5044e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 88.086
[Epoch:60] 8/22	    BatchTime 1.2289    DataTime 0.0002    Loss_Classification 2.0551e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.820
[Epoch:60] 9/22	    BatchTime 1.2053    DataTime 0.0001    Loss_Classification 2.2250e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 89.453
[Epoch:60] 10/22	    BatchTime 1.2156    DataTime 0.0002    Loss_Classification 2.1141e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.625
[Epoch:60] 11/22	    BatchTime 1.1783    DataTime 0.0004    Loss_Classification 1.9390e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:60] 12/22	    BatchTime 1.2377    DataTime 0.0002    Loss_Classification 1.5349e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.164
[Epoch:60] 13/22	    BatchTime 1.2335    DataTime 0.0002    Loss_Classification 2.0844e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:60] 14/22	    BatchTime 1.2007    DataTime 0.0002    Loss_Classification 1.5206e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 93.164
[Epoch:60] 15/22	    BatchTime 1.2093    DataTime 0.0003    Loss_Classification 1.6819e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:60] 16/22	    BatchTime 1.2411    DataTime 0.0003    Loss_Classification 2.0553e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:60] 17/22	    BatchTime 1.2343    DataTime 0.0002    Loss_Classification 1.8922e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:60] 18/22	    BatchTime 1.2429    DataTime 0.0002    Loss_Classification 1.9717e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:60] 19/22	    BatchTime 1.2117    DataTime 0.0002    Loss_Classification 1.8651e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.797
[Epoch:60] 20/22	    BatchTime 1.2144    DataTime 0.0002    Loss_Classification 1.8265e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:60] 21/22	    BatchTime 1.5049    DataTime 0.0002    Loss_Classification 2.1200e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.430
[Epoch:60] 22/22	    BatchTime 1.2428    DataTime 0.0002    Loss_Classification 1.7414e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.969
[Epoch:60]  33.07    Loss_Classification 1.9493e+00    val_Loss_Classification 2.2229e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.711    val_acc@1 88.936    acc@5 91.175    val_acc@5 90.032
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00060-val_Loss_Classification_2.2229-val_Loss_Distance_0.0000.pth

Epoch 61 learning_rate : 1e-05
[Epoch:61] 1/22	    BatchTime 7.3547    DataTime 6.0017    Loss_Classification 2.0643e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:61] 2/22	    BatchTime 1.1370    DataTime 0.0002    Loss_Classification 1.9885e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.406
[Epoch:61] 3/22	    BatchTime 1.1396    DataTime 0.0001    Loss_Classification 1.5354e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 93.359
[Epoch:61] 4/22	    BatchTime 1.1517    DataTime 0.0002    Loss_Classification 1.8215e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 92.188
[Epoch:61] 5/22	    BatchTime 1.1684    DataTime 0.0001    Loss_Classification 1.9448e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:61] 6/22	    BatchTime 1.1982    DataTime 0.0002    Loss_Classification 1.9663e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.406
[Epoch:61] 7/22	    BatchTime 1.1924    DataTime 0.0000    Loss_Classification 2.0934e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:61] 8/22	    BatchTime 1.1735    DataTime 0.0001    Loss_Classification 1.4988e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.359
[Epoch:61] 9/22	    BatchTime 1.1853    DataTime 0.0001    Loss_Classification 2.4794e+00    Loss_Distance 0.0000e+00    acc@1 86.523    acc@5 87.891
[Epoch:61] 10/22	    BatchTime 1.4492    DataTime 0.0003    Loss_Classification 2.2898e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.453
[Epoch:61] 11/22	    BatchTime 1.2144    DataTime 0.0003    Loss_Classification 2.2180e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 89.648
[Epoch:61] 12/22	    BatchTime 1.2036    DataTime 0.0002    Loss_Classification 1.9910e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:61] 13/22	    BatchTime 1.1754    DataTime 0.0002    Loss_Classification 2.3441e+00    Loss_Distance 0.0000e+00    acc@1 86.719    acc@5 88.477
[Epoch:61] 14/22	    BatchTime 1.2562    DataTime 0.0001    Loss_Classification 2.0257e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.820
[Epoch:61] 15/22	    BatchTime 1.2343    DataTime 0.0001    Loss_Classification 2.1109e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.430
[Epoch:61] 16/22	    BatchTime 1.2204    DataTime 0.0002    Loss_Classification 1.4731e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 93.359
[Epoch:61] 17/22	    BatchTime 1.1912    DataTime 0.0001    Loss_Classification 1.5799e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.969
[Epoch:61] 18/22	    BatchTime 1.2749    DataTime 0.0002    Loss_Classification 1.8267e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.602
[Epoch:61] 19/22	    BatchTime 1.2406    DataTime 0.0001    Loss_Classification 2.1652e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.625
[Epoch:61] 20/22	    BatchTime 1.2281    DataTime 0.0001    Loss_Classification 1.6893e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:61] 21/22	    BatchTime 1.2323    DataTime 0.0002    Loss_Classification 2.2653e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.453
[Epoch:61] 22/22	    BatchTime 1.2929    DataTime 0.0001    Loss_Classification 1.4950e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.969
[Epoch:61]  32.91    Loss_Classification 1.9485e+00    val_Loss_Classification 2.1964e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.515    val_acc@1 88.547    acc@5 91.113    val_acc@5 90.138
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00061-val_Loss_Classification_2.1964-val_Loss_Distance_0.0000.pth

Epoch 62 learning_rate : 9.97534852915723e-06
[Epoch:62] 1/22	    BatchTime 7.3069    DataTime 6.0129    Loss_Classification 2.0591e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:62] 2/22	    BatchTime 1.1473    DataTime 0.0002    Loss_Classification 2.0194e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.820
[Epoch:62] 3/22	    BatchTime 1.1375    DataTime 0.0002    Loss_Classification 1.5093e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 92.773
[Epoch:62] 4/22	    BatchTime 1.1841    DataTime 0.0002    Loss_Classification 1.7156e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.188
[Epoch:62] 5/22	    BatchTime 1.1676    DataTime 0.0001    Loss_Classification 2.1677e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.648
[Epoch:62] 6/22	    BatchTime 1.1850    DataTime 0.0001    Loss_Classification 1.7954e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.602
[Epoch:62] 7/22	    BatchTime 1.1873    DataTime 0.0002    Loss_Classification 1.7284e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:62] 8/22	    BatchTime 1.2522    DataTime 0.0004    Loss_Classification 2.0420e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.211
[Epoch:62] 9/22	    BatchTime 1.2210    DataTime 0.0002    Loss_Classification 1.7851e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:62] 10/22	    BatchTime 1.1932    DataTime 0.0002    Loss_Classification 2.0344e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.430
[Epoch:62] 11/22	    BatchTime 1.2309    DataTime 0.0003    Loss_Classification 2.0421e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.625
[Epoch:62] 12/22	    BatchTime 1.2242    DataTime 0.0002    Loss_Classification 1.8918e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:62] 13/22	    BatchTime 1.2100    DataTime 0.0001    Loss_Classification 2.7040e+00    Loss_Distance 0.0000e+00    acc@1 85.938    acc@5 87.695
[Epoch:62] 14/22	    BatchTime 1.2362    DataTime 0.0001    Loss_Classification 2.1441e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.430
[Epoch:62] 15/22	    BatchTime 1.2502    DataTime 0.0002    Loss_Classification 1.9550e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:62] 16/22	    BatchTime 1.2301    DataTime 0.0002    Loss_Classification 2.0349e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:62] 17/22	    BatchTime 1.2173    DataTime 0.0002    Loss_Classification 1.5530e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.578
[Epoch:62] 18/22	    BatchTime 1.2493    DataTime 0.0000    Loss_Classification 1.7774e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.797
[Epoch:62] 19/22	    BatchTime 1.2370    DataTime 0.0001    Loss_Classification 1.4470e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.969
[Epoch:62] 20/22	    BatchTime 1.2222    DataTime 0.0001    Loss_Classification 2.0574e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:62] 21/22	    BatchTime 1.2203    DataTime 0.0001    Loss_Classification 1.6734e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 92.188
[Epoch:62] 22/22	    BatchTime 1.3745    DataTime 0.0001    Loss_Classification 1.8108e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:62]  32.88    Loss_Classification 1.9067e+00    val_Loss_Classification 2.1400e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.959    val_acc@1 89.042    acc@5 91.264    val_acc@5 90.385
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00062-val_Loss_Classification_2.1400-val_Loss_Distance_0.0000.pth

Epoch 63 learning_rate : 9.901664203302126e-06
[Epoch:63] 1/22	    BatchTime 7.6430    DataTime 6.3296    Loss_Classification 1.9292e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.992
[Epoch:63] 2/22	    BatchTime 1.1484    DataTime 0.0002    Loss_Classification 1.6912e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.773
[Epoch:63] 3/22	    BatchTime 1.1381    DataTime 0.0001    Loss_Classification 1.9612e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.211
[Epoch:63] 4/22	    BatchTime 1.1670    DataTime 0.0002    Loss_Classification 1.8694e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:63] 5/22	    BatchTime 1.1647    DataTime 0.0002    Loss_Classification 1.8484e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.992
[Epoch:63] 6/22	    BatchTime 1.1740    DataTime 0.0001    Loss_Classification 1.5251e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.773
[Epoch:63] 7/22	    BatchTime 1.1963    DataTime 0.0001    Loss_Classification 1.8404e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 91.406
[Epoch:63] 8/22	    BatchTime 1.1868    DataTime 0.0002    Loss_Classification 2.2262e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.234
[Epoch:63] 9/22	    BatchTime 1.2338    DataTime 0.0002    Loss_Classification 1.8391e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.211
[Epoch:63] 10/22	    BatchTime 1.2273    DataTime 0.0002    Loss_Classification 2.1597e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.820
[Epoch:63] 11/22	    BatchTime 1.1963    DataTime 0.0002    Loss_Classification 2.0842e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.844
[Epoch:63] 12/22	    BatchTime 1.1963    DataTime 0.0000    Loss_Classification 2.0389e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.234
[Epoch:63] 13/22	    BatchTime 1.1792    DataTime 0.0002    Loss_Classification 1.9063e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.211
[Epoch:63] 14/22	    BatchTime 1.2864    DataTime 0.0002    Loss_Classification 1.4268e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.164
[Epoch:63] 15/22	    BatchTime 1.2528    DataTime 0.0002    Loss_Classification 1.7392e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.211
[Epoch:63] 16/22	    BatchTime 1.2535    DataTime 0.0002    Loss_Classification 1.7544e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:63] 17/22	    BatchTime 1.2612    DataTime 0.0002    Loss_Classification 1.3134e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.555
[Epoch:63] 18/22	    BatchTime 1.1961    DataTime 0.0002    Loss_Classification 1.9292e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.016
[Epoch:63] 19/22	    BatchTime 1.2115    DataTime 0.0002    Loss_Classification 1.7117e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.188
[Epoch:63] 20/22	    BatchTime 1.2776    DataTime 0.0001    Loss_Classification 1.8672e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.406
[Epoch:63] 21/22	    BatchTime 1.2413    DataTime 0.0003    Loss_Classification 2.0827e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:63] 22/22	    BatchTime 1.2443    DataTime 0.0002    Loss_Classification 1.8376e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.211
[Epoch:63]  33.08    Loss_Classification 1.8446e+00    val_Loss_Classification 2.3507e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 90.163    val_acc@1 88.088    acc@5 91.531    val_acc@5 89.714
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00063-val_Loss_Classification_2.3507-val_Loss_Distance_0.0000.pth

Epoch 64 learning_rate : 9.779754323328192e-06
[Epoch:64] 1/22	    BatchTime 7.0941    DataTime 5.8139    Loss_Classification 1.8333e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:64] 2/22	    BatchTime 1.1356    DataTime 0.0002    Loss_Classification 2.0834e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.016
[Epoch:64] 3/22	    BatchTime 1.1383    DataTime 0.0002    Loss_Classification 1.9437e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.430
[Epoch:64] 4/22	    BatchTime 1.1646    DataTime 0.0001    Loss_Classification 1.7042e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.383
[Epoch:64] 5/22	    BatchTime 1.1893    DataTime 0.0002    Loss_Classification 1.7702e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.406
[Epoch:64] 6/22	    BatchTime 1.2000    DataTime 0.0001    Loss_Classification 1.8363e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.797
[Epoch:64] 7/22	    BatchTime 1.1743    DataTime 0.0002    Loss_Classification 1.9436e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.625
[Epoch:64] 8/22	    BatchTime 1.4289    DataTime 0.0001    Loss_Classification 1.3915e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 93.164
[Epoch:64] 9/22	    BatchTime 1.2153    DataTime 0.0002    Loss_Classification 1.7602e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:64] 10/22	    BatchTime 1.2088    DataTime 0.0002    Loss_Classification 1.8414e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:64] 11/22	    BatchTime 1.1813    DataTime 0.0002    Loss_Classification 1.4994e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 93.164
[Epoch:64] 12/22	    BatchTime 1.1990    DataTime 0.0002    Loss_Classification 1.7671e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:64] 13/22	    BatchTime 1.2127    DataTime 0.0003    Loss_Classification 2.1494e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.039
[Epoch:64] 14/22	    BatchTime 1.2756    DataTime 0.0001    Loss_Classification 1.9155e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.797
[Epoch:64] 15/22	    BatchTime 1.2451    DataTime 0.0001    Loss_Classification 2.1418e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.039
[Epoch:64] 16/22	    BatchTime 1.2062    DataTime 0.0002    Loss_Classification 2.1671e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.430
[Epoch:64] 17/22	    BatchTime 1.2712    DataTime 0.0001    Loss_Classification 1.9718e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.406
[Epoch:64] 18/22	    BatchTime 1.2530    DataTime 0.0002    Loss_Classification 2.1887e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.430
[Epoch:64] 19/22	    BatchTime 1.2146    DataTime 0.0000    Loss_Classification 2.0822e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 89.648
[Epoch:64] 20/22	    BatchTime 1.2440    DataTime 0.0001    Loss_Classification 2.1858e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:64] 21/22	    BatchTime 1.2159    DataTime 0.0002    Loss_Classification 1.6650e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.188
[Epoch:64] 22/22	    BatchTime 1.2505    DataTime 0.0002    Loss_Classification 2.1204e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:64]  32.72    Loss_Classification 1.9074e+00    val_Loss_Classification 2.0078e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.897    val_acc@1 89.502    acc@5 91.282    val_acc@5 91.198
val_Loss_Classification improve from 2.0726060702127382 to 2.0078077843013102
Save model to ./models/ep00064-val_Loss_Classification_2.0078-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00064-val_Loss_Classification_2.0078-val_Loss_Distance_0.0000.pth

Epoch 65 learning_rate : 9.610954559391704e-06
[Epoch:65] 1/22	    BatchTime 7.4697    DataTime 6.1547    Loss_Classification 1.5539e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.188
[Epoch:65] 2/22	    BatchTime 1.1499    DataTime 0.0001    Loss_Classification 2.0245e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.625
[Epoch:65] 3/22	    BatchTime 1.1474    DataTime 0.0001    Loss_Classification 1.7258e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.383
[Epoch:65] 4/22	    BatchTime 1.1574    DataTime 0.0002    Loss_Classification 2.2076e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 89.648
[Epoch:65] 5/22	    BatchTime 1.1637    DataTime 0.0004    Loss_Classification 1.6644e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.578
[Epoch:65] 6/22	    BatchTime 1.1743    DataTime 0.0002    Loss_Classification 1.8828e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.211
[Epoch:65] 7/22	    BatchTime 1.1833    DataTime 0.0003    Loss_Classification 2.1953e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:65] 8/22	    BatchTime 1.2109    DataTime 0.0002    Loss_Classification 1.9490e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:65] 9/22	    BatchTime 1.2134    DataTime 0.0000    Loss_Classification 2.2266e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.039
[Epoch:65] 10/22	    BatchTime 1.1964    DataTime 0.0002    Loss_Classification 1.9542e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:65] 11/22	    BatchTime 1.2367    DataTime 0.0001    Loss_Classification 2.0878e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:65] 12/22	    BatchTime 1.2258    DataTime 0.0001    Loss_Classification 1.6755e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.383
[Epoch:65] 13/22	    BatchTime 1.2227    DataTime 0.0002    Loss_Classification 1.9735e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:65] 14/22	    BatchTime 1.2064    DataTime 0.0002    Loss_Classification 2.0564e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:65] 15/22	    BatchTime 1.2277    DataTime 0.0002    Loss_Classification 1.9890e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:65] 16/22	    BatchTime 1.2239    DataTime 0.0002    Loss_Classification 2.1068e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 89.453
[Epoch:65] 17/22	    BatchTime 1.2072    DataTime 0.0002    Loss_Classification 1.9057e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:65] 18/22	    BatchTime 1.2336    DataTime 0.0002    Loss_Classification 1.9703e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.625
[Epoch:65] 19/22	    BatchTime 1.2466    DataTime 0.0002    Loss_Classification 1.8484e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:65] 20/22	    BatchTime 1.2484    DataTime 0.0002    Loss_Classification 1.7608e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:65] 21/22	    BatchTime 1.2218    DataTime 0.0002    Loss_Classification 1.3862e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 93.555
[Epoch:65] 22/22	    BatchTime 1.2447    DataTime 0.0002    Loss_Classification 1.6828e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 91.797
[Epoch:65]  32.81    Loss_Classification 1.9012e+00    val_Loss_Classification 2.1529e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.977    val_acc@1 88.830    acc@5 91.326    val_acc@5 90.456
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00065-val_Loss_Classification_2.1529-val_Loss_Distance_0.0000.pth

Epoch 66 learning_rate : 9.397114317029975e-06
[Epoch:66] 1/22	    BatchTime 7.4400    DataTime 6.2586    Loss_Classification 2.0754e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.234
[Epoch:66] 2/22	    BatchTime 1.1341    DataTime 0.0000    Loss_Classification 1.4696e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.164
[Epoch:66] 3/22	    BatchTime 1.1364    DataTime 0.0002    Loss_Classification 2.6401e+00    Loss_Distance 0.0000e+00    acc@1 86.328    acc@5 87.891
[Epoch:66] 4/22	    BatchTime 1.1679    DataTime 0.0002    Loss_Classification 1.5216e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 93.359
[Epoch:66] 5/22	    BatchTime 1.1668    DataTime 0.0001    Loss_Classification 1.3744e+00    Loss_Distance 0.0000e+00    acc@1 92.969    acc@5 93.555
[Epoch:66] 6/22	    BatchTime 1.1922    DataTime 0.0002    Loss_Classification 2.3976e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 89.844
[Epoch:66] 7/22	    BatchTime 1.1840    DataTime 0.0002    Loss_Classification 1.8912e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.406
[Epoch:66] 8/22	    BatchTime 1.2246    DataTime 0.0001    Loss_Classification 1.9498e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.820
[Epoch:66] 9/22	    BatchTime 1.2097    DataTime 0.0002    Loss_Classification 2.5039e+00    Loss_Distance 0.0000e+00    acc@1 87.500    acc@5 88.867
[Epoch:66] 10/22	    BatchTime 1.2240    DataTime 0.0001    Loss_Classification 1.8540e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:66] 11/22	    BatchTime 1.2077    DataTime 0.0002    Loss_Classification 2.0830e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.820
[Epoch:66] 12/22	    BatchTime 1.2231    DataTime 0.0002    Loss_Classification 1.3463e+00    Loss_Distance 0.0000e+00    acc@1 91.992    acc@5 93.359
[Epoch:66] 13/22	    BatchTime 1.2134    DataTime 0.0002    Loss_Classification 1.7512e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.383
[Epoch:66] 14/22	    BatchTime 1.2035    DataTime 0.0001    Loss_Classification 1.8407e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.797
[Epoch:66] 15/22	    BatchTime 1.2309    DataTime 0.0001    Loss_Classification 1.9942e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.820
[Epoch:66] 16/22	    BatchTime 1.2437    DataTime 0.0002    Loss_Classification 1.5555e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.383
[Epoch:66] 17/22	    BatchTime 1.2275    DataTime 0.0003    Loss_Classification 1.3278e+00    Loss_Distance 0.0000e+00    acc@1 92.578    acc@5 93.750
[Epoch:66] 18/22	    BatchTime 1.2528    DataTime 0.0002    Loss_Classification 1.7235e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.992
[Epoch:66] 19/22	    BatchTime 1.2577    DataTime 0.0002    Loss_Classification 1.3565e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.164
[Epoch:66] 20/22	    BatchTime 1.2469    DataTime 0.0002    Loss_Classification 1.7609e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.188
[Epoch:66] 21/22	    BatchTime 1.2332    DataTime 0.0003    Loss_Classification 1.8878e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:66] 22/22	    BatchTime 1.2512    DataTime 0.0002    Loss_Classification 1.6109e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 92.969
[Epoch:66]  32.87    Loss_Classification 1.8144e+00    val_Loss_Classification 2.1300e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 90.385    val_acc@1 88.795    acc@5 91.726    val_acc@5 90.385
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00066-val_Loss_Classification_2.1300-val_Loss_Distance_0.0000.pth

Epoch 67 learning_rate : 9.140576474687265e-06
[Epoch:67] 1/22	    BatchTime 7.0113    DataTime 5.6951    Loss_Classification 1.7538e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:67] 2/22	    BatchTime 1.1350    DataTime 0.0003    Loss_Classification 1.7845e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:67] 3/22	    BatchTime 1.1350    DataTime 0.0002    Loss_Classification 1.2292e+00    Loss_Distance 0.0000e+00    acc@1 92.773    acc@5 93.945
[Epoch:67] 4/22	    BatchTime 1.1676    DataTime 0.0001    Loss_Classification 2.2198e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.844
[Epoch:67] 5/22	    BatchTime 1.1767    DataTime 0.0002    Loss_Classification 2.2384e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:67] 6/22	    BatchTime 1.2011    DataTime 0.0003    Loss_Classification 1.8383e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.406
[Epoch:67] 7/22	    BatchTime 1.1799    DataTime 0.0002    Loss_Classification 1.9357e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 91.016
[Epoch:67] 8/22	    BatchTime 1.1942    DataTime 0.0001    Loss_Classification 1.6438e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 91.992
[Epoch:67] 9/22	    BatchTime 1.2896    DataTime 0.0003    Loss_Classification 2.0231e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.016
[Epoch:67] 10/22	    BatchTime 1.2406    DataTime 0.0000    Loss_Classification 2.0916e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.016
[Epoch:67] 11/22	    BatchTime 1.2151    DataTime 0.0002    Loss_Classification 1.9506e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 90.625
[Epoch:67] 12/22	    BatchTime 1.2193    DataTime 0.0001    Loss_Classification 1.3692e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.555
[Epoch:67] 13/22	    BatchTime 1.2166    DataTime 0.0002    Loss_Classification 1.5649e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.773
[Epoch:67] 14/22	    BatchTime 1.2109    DataTime 0.0001    Loss_Classification 1.6742e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 91.992
[Epoch:67] 15/22	    BatchTime 1.2020    DataTime 0.0002    Loss_Classification 2.2032e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:67] 16/22	    BatchTime 1.3059    DataTime 0.0002    Loss_Classification 2.0193e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.430
[Epoch:67] 17/22	    BatchTime 1.2600    DataTime 0.0002    Loss_Classification 2.0129e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.602
[Epoch:67] 18/22	    BatchTime 1.2447    DataTime 0.0002    Loss_Classification 1.5950e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.383
[Epoch:67] 19/22	    BatchTime 1.2268    DataTime 0.0001    Loss_Classification 2.0469e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:67] 20/22	    BatchTime 1.2054    DataTime 0.0001    Loss_Classification 1.8718e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.016
[Epoch:67] 21/22	    BatchTime 1.2477    DataTime 0.0001    Loss_Classification 1.8335e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.797
[Epoch:67] 22/22	    BatchTime 1.2485    DataTime 0.0002    Loss_Classification 1.8706e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.602
[Epoch:67]  32.53    Loss_Classification 1.8532e+00    val_Loss_Classification 1.9413e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 90.252    val_acc@1 89.784    acc@5 91.504    val_acc@5 91.128
val_Loss_Classification improve from 2.0078077843013102 to 1.9413197939789477
Save model to ./models/ep00067-val_Loss_Classification_1.9413-val_Loss_Distance_0.0000.pth
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00067-val_Loss_Classification_1.9413-val_Loss_Distance_0.0000.pth

Epoch 68 learning_rate : 8.844151714648274e-06
[Epoch:68] 1/22	    BatchTime 7.5793    DataTime 6.1544    Loss_Classification 1.8205e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.992
[Epoch:68] 2/22	    BatchTime 1.1605    DataTime 0.0002    Loss_Classification 1.8753e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 91.016
[Epoch:68] 3/22	    BatchTime 1.1375    DataTime 0.0001    Loss_Classification 2.0884e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 90.820
[Epoch:68] 4/22	    BatchTime 1.1519    DataTime 0.0002    Loss_Classification 1.7846e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 92.188
[Epoch:68] 5/22	    BatchTime 1.1682    DataTime 0.0002    Loss_Classification 2.3788e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.453
[Epoch:68] 6/22	    BatchTime 1.1763    DataTime 0.0001    Loss_Classification 2.4184e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 89.062
[Epoch:68] 7/22	    BatchTime 1.1906    DataTime 0.0001    Loss_Classification 2.1126e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.234
[Epoch:68] 8/22	    BatchTime 1.2123    DataTime 0.0001    Loss_Classification 1.7089e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.578
[Epoch:68] 9/22	    BatchTime 1.1818    DataTime 0.0002    Loss_Classification 2.1765e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:68] 10/22	    BatchTime 1.1900    DataTime 0.0003    Loss_Classification 1.9384e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.430
[Epoch:68] 11/22	    BatchTime 1.1998    DataTime 0.0003    Loss_Classification 1.5284e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 93.164
[Epoch:68] 12/22	    BatchTime 1.2449    DataTime 0.0002    Loss_Classification 2.1361e+00    Loss_Distance 0.0000e+00    acc@1 88.672    acc@5 90.234
[Epoch:68] 13/22	    BatchTime 1.2136    DataTime 0.0004    Loss_Classification 1.5484e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.359
[Epoch:68] 14/22	    BatchTime 1.2170    DataTime 0.0000    Loss_Classification 2.2885e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 90.039
[Epoch:68] 15/22	    BatchTime 1.2861    DataTime 0.0001    Loss_Classification 1.5305e+00    Loss_Distance 0.0000e+00    acc@1 91.211    acc@5 93.164
[Epoch:68] 16/22	    BatchTime 1.2599    DataTime 0.0002    Loss_Classification 1.6901e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.383
[Epoch:68] 17/22	    BatchTime 1.2330    DataTime 0.0002    Loss_Classification 1.2883e+00    Loss_Distance 0.0000e+00    acc@1 92.383    acc@5 93.945
[Epoch:68] 18/22	    BatchTime 1.1998    DataTime 0.0001    Loss_Classification 1.6853e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 92.773
[Epoch:68] 19/22	    BatchTime 1.2572    DataTime 0.0002    Loss_Classification 1.8719e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.797
[Epoch:68] 20/22	    BatchTime 1.2461    DataTime 0.0002    Loss_Classification 2.1188e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.234
[Epoch:68] 21/22	    BatchTime 1.2147    DataTime 0.0001    Loss_Classification 1.8022e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.602
[Epoch:68] 22/22	    BatchTime 1.2302    DataTime 0.0002    Loss_Classification 1.9624e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.406
[Epoch:68]  32.95    Loss_Classification 1.8979e+00    val_Loss_Classification 2.1199e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 89.968    val_acc@1 89.290    acc@5 91.460    val_acc@5 90.633
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00068-val_Loss_Classification_2.1199-val_Loss_Distance_0.0000.pth

Epoch 69 learning_rate : 8.511087728614863e-06
[Epoch:69] 1/22	    BatchTime 7.3571    DataTime 6.0651    Loss_Classification 1.5578e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 93.164
[Epoch:69] 2/22	    BatchTime 1.1387    DataTime 0.0002    Loss_Classification 2.0121e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:69] 3/22	    BatchTime 1.1362    DataTime 0.0002    Loss_Classification 1.6384e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:69] 4/22	    BatchTime 1.1804    DataTime 0.0002    Loss_Classification 1.5527e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.164
[Epoch:69] 5/22	    BatchTime 1.1902    DataTime 0.0002    Loss_Classification 2.2693e+00    Loss_Distance 0.0000e+00    acc@1 87.891    acc@5 90.039
[Epoch:69] 6/22	    BatchTime 1.1897    DataTime 0.0005    Loss_Classification 1.7920e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.797
[Epoch:69] 7/22	    BatchTime 1.1866    DataTime 0.0002    Loss_Classification 1.2355e+00    Loss_Distance 0.0000e+00    acc@1 92.969    acc@5 94.336
[Epoch:69] 8/22	    BatchTime 1.2548    DataTime 0.0002    Loss_Classification 1.6190e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:69] 9/22	    BatchTime 1.2281    DataTime 0.0002    Loss_Classification 2.3753e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 89.648
[Epoch:69] 10/22	    BatchTime 1.2337    DataTime 0.0003    Loss_Classification 1.9123e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.625
[Epoch:69] 11/22	    BatchTime 1.1879    DataTime 0.0001    Loss_Classification 2.4045e+00    Loss_Distance 0.0000e+00    acc@1 87.695    acc@5 89.258
[Epoch:69] 12/22	    BatchTime 1.1883    DataTime 0.0002    Loss_Classification 2.0083e+00    Loss_Distance 0.0000e+00    acc@1 88.477    acc@5 90.234
[Epoch:69] 13/22	    BatchTime 1.2828    DataTime 0.0000    Loss_Classification 1.8847e+00    Loss_Distance 0.0000e+00    acc@1 89.258    acc@5 90.820
[Epoch:69] 14/22	    BatchTime 1.2694    DataTime 0.0001    Loss_Classification 1.7875e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.383
[Epoch:69] 15/22	    BatchTime 1.2448    DataTime 0.0003    Loss_Classification 1.7618e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.188
[Epoch:69] 16/22	    BatchTime 1.2251    DataTime 0.0002    Loss_Classification 1.9124e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.211
[Epoch:69] 17/22	    BatchTime 1.1976    DataTime 0.0001    Loss_Classification 1.6401e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.773
[Epoch:69] 18/22	    BatchTime 1.2152    DataTime 0.0002    Loss_Classification 1.4746e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.969
[Epoch:69] 19/22	    BatchTime 1.2325    DataTime 0.0002    Loss_Classification 1.9754e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 91.016
[Epoch:69] 20/22	    BatchTime 1.2604    DataTime 0.0002    Loss_Classification 1.6024e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.773
[Epoch:69] 21/22	    BatchTime 1.2261    DataTime 0.0002    Loss_Classification 1.6654e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 92.383
[Epoch:69] 22/22	    BatchTime 1.2965    DataTime 0.0001    Loss_Classification 1.3520e+00    Loss_Distance 0.0000e+00    acc@1 92.773    acc@5 93.750
[Epoch:69]  32.92    Loss_Classification 1.7924e+00    val_Loss_Classification 2.1195e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 90.279    val_acc@1 88.830    acc@5 91.806    val_acc@5 90.527
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00069-val_Loss_Classification_2.1195-val_Loss_Distance_0.0000.pth

Epoch 70 learning_rate : 8.14503363531613e-06
[Epoch:70] 1/22	    BatchTime 7.2700    DataTime 5.8048    Loss_Classification 1.8792e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.016
[Epoch:70] 2/22	    BatchTime 1.1223    DataTime 0.0003    Loss_Classification 2.0265e+00    Loss_Distance 0.0000e+00    acc@1 89.648    acc@5 90.430
[Epoch:70] 3/22	    BatchTime 1.1646    DataTime 0.0002    Loss_Classification 1.6325e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 92.578
[Epoch:70] 4/22	    BatchTime 1.1681    DataTime 0.0002    Loss_Classification 1.4198e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.555
[Epoch:70] 5/22	    BatchTime 1.1981    DataTime 0.0002    Loss_Classification 1.5449e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.164
[Epoch:70] 6/22	    BatchTime 1.2028    DataTime 0.0002    Loss_Classification 1.8203e+00    Loss_Distance 0.0000e+00    acc@1 89.844    acc@5 91.016
[Epoch:70] 7/22	    BatchTime 1.2177    DataTime 0.0002    Loss_Classification 1.9396e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 91.602
[Epoch:70] 8/22	    BatchTime 1.2360    DataTime 0.0002    Loss_Classification 1.7792e+00    Loss_Distance 0.0000e+00    acc@1 90.625    acc@5 91.797
[Epoch:70] 9/22	    BatchTime 1.2374    DataTime 0.0002    Loss_Classification 1.6006e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 92.578
[Epoch:70] 10/22	    BatchTime 1.2251    DataTime 0.0003    Loss_Classification 2.4231e+00    Loss_Distance 0.0000e+00    acc@1 86.914    acc@5 88.477
[Epoch:70] 11/22	    BatchTime 1.2144    DataTime 0.0002    Loss_Classification 1.6879e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 91.992
[Epoch:70] 12/22	    BatchTime 1.2682    DataTime 0.0004    Loss_Classification 2.0696e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:70] 13/22	    BatchTime 1.2399    DataTime 0.0002    Loss_Classification 1.2849e+00    Loss_Distance 0.0000e+00    acc@1 92.773    acc@5 93.945
[Epoch:70] 14/22	    BatchTime 1.2132    DataTime 0.0002    Loss_Classification 1.3395e+00    Loss_Distance 0.0000e+00    acc@1 92.773    acc@5 93.555
[Epoch:70] 15/22	    BatchTime 1.2160    DataTime 0.0002    Loss_Classification 1.8222e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:70] 16/22	    BatchTime 1.2301    DataTime 0.0001    Loss_Classification 2.1437e+00    Loss_Distance 0.0000e+00    acc@1 88.281    acc@5 90.234
[Epoch:70] 17/22	    BatchTime 1.2526    DataTime 0.0002    Loss_Classification 1.4932e+00    Loss_Distance 0.0000e+00    acc@1 92.188    acc@5 92.969
[Epoch:70] 18/22	    BatchTime 1.2453    DataTime 0.0001    Loss_Classification 1.6932e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.992
[Epoch:70] 19/22	    BatchTime 1.2191    DataTime 0.0001    Loss_Classification 2.1180e+00    Loss_Distance 0.0000e+00    acc@1 88.867    acc@5 90.625
[Epoch:70] 20/22	    BatchTime 1.2284    DataTime 0.0001    Loss_Classification 1.9140e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:70] 21/22	    BatchTime 1.2755    DataTime 0.0002    Loss_Classification 1.4511e+00    Loss_Distance 0.0000e+00    acc@1 91.602    acc@5 93.555
[Epoch:70] 22/22	    BatchTime 1.2644    DataTime 0.0002    Loss_Classification 1.5249e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 92.969
[Epoch:70]  32.91    Loss_Classification 1.7549e+00    val_Loss_Classification 2.0067e+00    Loss_Distance 0.0000e+00    val_Loss_Distance 0.0000e+00    acc@1 90.554    val_acc@1 89.325    acc@5 91.886    val_acc@5 90.809
val_Loss_Classification did not improve
val_Loss_Distance improve from 0 to 0
Save model to ./models/ep00070-val_Loss_Classification_2.0067-val_Loss_Distance_0.0000.pth

Epoch 71 learning_rate : 7.75e-06
[Epoch:71] 1/22	    BatchTime 7.3607    DataTime 6.0621    Loss_Classification 1.9974e+00    Loss_Distance 0.0000e+00    acc@1 89.062    acc@5 90.625
[Epoch:71] 2/22	    BatchTime 1.1482    DataTime 0.0002    Loss_Classification 1.9599e+00    Loss_Distance 0.0000e+00    acc@1 90.820    acc@5 91.406
[Epoch:71] 3/22	    BatchTime 1.1348    DataTime 0.0002    Loss_Classification 1.6730e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 92.188
[Epoch:71] 4/22	    BatchTime 1.1647    DataTime 0.0002    Loss_Classification 2.0201e+00    Loss_Distance 0.0000e+00    acc@1 89.453    acc@5 90.820
[Epoch:71] 5/22	    BatchTime 1.1740    DataTime 0.0002    Loss_Classification 2.0580e+00    Loss_Distance 0.0000e+00    acc@1 90.039    acc@5 91.211
[Epoch:71] 6/22	    BatchTime 1.2029    DataTime 0.0002    Loss_Classification 1.7759e+00    Loss_Distance 0.0000e+00    acc@1 90.234    acc@5 91.602
[Epoch:71] 7/22	    BatchTime 1.1864    DataTime 0.0001    Loss_Classification 1.4413e+00    Loss_Distance 0.0000e+00    acc@1 92.578    acc@5 93.750
[Epoch:71] 8/22	    BatchTime 1.1895    DataTime 0.0002    Loss_Classification 2.3277e+00    Loss_Distance 0.0000e+00    acc@1 88.086    acc@5 89.453
[Epoch:71] 9/22	    BatchTime 1.2533    DataTime 0.0007    Loss_Classification 1.4869e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.578
[Epoch:71] 10/22	    BatchTime 1.2241    DataTime 0.0001    Loss_Classification 1.9445e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 91.406
[Epoch:71] 11/22	    BatchTime 1.2225    DataTime 0.0002    Loss_Classification 1.5202e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 93.359
[Epoch:71] 12/22	    BatchTime 1.2042    DataTime 0.0002    Loss_Classification 1.5256e+00    Loss_Distance 0.0000e+00    acc@1 92.383    acc@5 92.969
[Epoch:71] 13/22	    BatchTime 1.2029    DataTime 0.0002    Loss_Classification 2.4695e+00    Loss_Distance 0.0000e+00    acc@1 87.305    acc@5 88.867
[Epoch:71] 14/22	    BatchTime 1.2294    DataTime 0.0002    Loss_Classification 1.6595e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 92.383
[Epoch:71] 15/22	    BatchTime 1.2475    DataTime 0.0002    Loss_Classification 1.5119e+00    Loss_Distance 0.0000e+00    acc@1 91.406    acc@5 92.773
[Epoch:71] 16/22	    BatchTime 1.2379    DataTime 0.0002    Loss_Classification 1.6281e+00    Loss_Distance 0.0000e+00    acc@1 91.016    acc@5 92.188
[Epoch:71] 17/22	    BatchTime 1.2182    DataTime 0.0000    Loss_Classification 1.4951e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 93.359
[Epoch:71] 18/22	    BatchTime 1.3040    DataTime 0.0003    Loss_Classification 1.3599e+00    Loss_Distance 0.0000e+00    acc@1 90.430    acc@5 93.555
[Epoch:71] 19/22	    BatchTime 1.2533    DataTime 0.0002    Loss_Classification 1.5884e+00    Loss_Distance 0.0000e+00    acc@1 91.797    acc@5 92.383
